{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model QED\n",
    "This is the base setup for working on QED data.\n",
    "It shows how to import the data and how to convert the expressions into different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:52:03.685003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 15:52:03.829330: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-14 15:52:03.889843: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-14 15:52:04.470806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-11-14 15:52:04.470850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-11-14 15:52:04.470854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "import sympy as sp\n",
    "from itertools import (takewhile,repeat)\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:52:06.033445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:52:06.037215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 15:52:06.037357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocessing.tree.sympy_to_tree as sp2tree\n",
    "from data_preprocessing.sympy_prefix.source.SympyPrefix import prefix_to_sympy, sympy_to_prefix, sympy_to_hybrid_prefix, hybrid_prefix_to_sympy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_i(expr_str):\n",
    "    reg_ex = \"[^a-z]i[^a-z,^\\d]\"\n",
    "    replaced = re.sub(reg_ex, fix_i_match, expr_str)\n",
    "    return replaced\n",
    "    \n",
    "def fix_i_match(matchobj):\n",
    "    \"\"\"\n",
    "    i --> I\n",
    "    \"\"\"\n",
    "    match = matchobj.group(0)\n",
    "    return match.replace(\"i\", \"I\")\n",
    "\n",
    "\n",
    "def rawincount(filename):\n",
    "    \"\"\"count numer of lines in a file. \n",
    "    From https://stackoverflow.com/questions/845058/how-to-get-line-count-of-a-large-file-cheaply-in-python\n",
    "    \"\"\"\n",
    "    f = open(filename, 'rb')\n",
    "    bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))\n",
    "    return sum( buf.count(b'\\n') for buf in bufgen )\n",
    "\n",
    "def load_raw_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading raw amplitudes from filename.\n",
    "    \n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "    \"\"\"\n",
    "    print(\"Loading amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines, leave=False)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        ctr = 0\n",
    "        data[ctr] = line.replace(\"\\n\", \"\")\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                data[ctr] = line.replace(\"\\n\", \"\")\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_squared_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading squared amplitudes from filename and parsing into sympy.\n",
    "    All squared amplitudes should be exportet from sympy and thus be readable\n",
    "    without any preprocessing.\n",
    "\n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "\n",
    "    Returns:\n",
    "        list of squared amplitudes, each as a sympy expression\n",
    "    \"\"\"\n",
    "    print(\"Loading squared amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines, leave=False)\n",
    "    with open(filename) as f:\n",
    "       line = f.readline()\n",
    "       line_sp = sp.sympify(line.strip())\n",
    "       ctr = 0\n",
    "       data[ctr] = line_sp\n",
    "       while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                line = line.strip()\n",
    "                line = fix_i(line)\n",
    "                line_sp = sp.sympify(line.strip())\n",
    "                data[ctr] = line_sp\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../data_unique.nosync/QED_amplitudes_TreeLevel_1to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10565fe77b354982b9bbd30acdc09407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../data_unique.nosync/QED_sqamplitudes_TreeLevel_1to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623cab22b10644ac90f0fa6bae0c84ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../data_unique.nosync/QED_amplitudes_TreeLevel_2to1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc313443cf948d5a7b33a25222e86e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../data_unique.nosync/QED_sqamplitudes_TreeLevel_2to1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc0d1bd5d2447f5ae7ed793676c8f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../data_unique.nosync/QED_amplitudes_TreeLevel_2to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a1aa1c53d14c6e845d2160fe5a3949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../data_unique.nosync/QED_sqamplitudes_TreeLevel_2to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7669ac1d2dc4c34ab7eb6f7fa084dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../data_unique.nosync/QED_amplitudes_TreeLevel_2to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad4aaadca514ae0945bea7c7fe1af75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../data_unique.nosync/QED_sqamplitudes_TreeLevel_2to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e93c02b392a4ae3a1b59c2e089d68ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../data_unique.nosync/QED_amplitudes_TreeLevel_3to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc192447bc944a768d7ce1b4d63540d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../data_unique.nosync/QED_sqamplitudes_TreeLevel_3to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5988c0baf7464d9253687f04ad790e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../data_unique.nosync/QED_amplitudes_TreeLevel_3to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41580d41fabd44ba9a9b6c5d2ba60c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../data_unique.nosync/QED_sqamplitudes_TreeLevel_3to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6912c6077ac04233a6b37c7f2970586b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder = \"../data_unique.nosync/\"\n",
    "amplitudes_filename_start = \"QED_amplitudes_TreeLevel_\"\n",
    "sqamplitudes_filename_start = \"QED_sqamplitudes_TreeLevel_\"\n",
    "processes = [\"1to2\", \"2to1\", \"2to2\", \"2to3\", \"3to2\", \"3to3\"]\n",
    "max_lines = -1\n",
    "\n",
    "amplitudes = []\n",
    "sqamplitudes = []\n",
    "for process in processes:\n",
    "    ampl_f = data_folder + amplitudes_filename_start + process + \".txt\"\n",
    "    sqampl_f = data_folder + sqamplitudes_filename_start + process + \".txt\"\n",
    "    amplitudes_process = load_raw_amplitudes(ampl_f, max_lines=max_lines)\n",
    "    sqamplitudes_process = load_squared_amplitudes(sqampl_f, max_lines=max_lines)\n",
    "    amplitudes.append(amplitudes_process)\n",
    "    sqamplitudes.append(sqamplitudes_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the different amplitudes separated for now, so `amplitudes` has the form\n",
    "`[multiplicity, i]` where `multiplicity = [\"1to2\", \"2to1\", ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "27\n",
      "27\n",
      "127\n",
      "127\n",
      "127\n",
      "127\n",
      "1039\n",
      "1039\n"
     ]
    }
   ],
   "source": [
    "# the amplitudes are in prefix format\n",
    "print(len(amplitudes))\n",
    "print(len(sqamplitudes))\n",
    "print(len(amplitudes[0]))\n",
    "print(len(sqamplitudes[0]))\n",
    "print(len(amplitudes[1]))\n",
    "print(len(sqamplitudes[1]))\n",
    "print(len(amplitudes[2]))\n",
    "print(len(sqamplitudes[2]))\n",
    "print(len(amplitudes[3]))\n",
    "print(len(sqamplitudes[3]))\n",
    "print(len(amplitudes[4]))\n",
    "print(len(sqamplitudes[4]))\n",
    "print(len(amplitudes[5]))\n",
    "print(len(sqamplitudes[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod,-1,Prod,i,Prod,e,Prod,gamma,alpha_2,alpha_0,alpha_1,Prod,A^(*),i_2,alpha_2,(p_3),Prod,ee,i_0,alpha_1,(p_1)_u,ee^(*),i_1,alpha_0,(p_2)_u'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 4 e^{2} \\cdot \\left(2 m_{e}^{2} - s_{12}\\right)$"
      ],
      "text/plain": [
       "-4*e**2*(2*m_e**2 - s_12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqamplitudes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b10ed33aafe49abb7556fc9219d8477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ed41f624804953bc16376389c8fbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5624c7e3d2374361bd3aaadc95cb815d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f12a704c5ac48df8bc0a313d247da2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a708e0ae86a4cd3831663cd5dcbb0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58f5639fa64091bccd752ced8473db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul', 's-', '4', 'mul', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_e', '2'], dtype='<U4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_prefix(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sympy_to_prefix(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_prefix = [[try_sympy_to_prefix(a) for a in tqdm(sq, leave=False)] for sq in sqamplitudes]\n",
    "np.array(sqampl_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb7726f728c47618d60fe0b64e485ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225d2083d54c4d4f94312d8f4288341c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ce5f0bf05c40cda674b099c6fe604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db697c61dc94652883ebe987eb961cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2129b959b04b36aafefea2c6c54b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f234894fceb4836a4e84e2541ad76b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{8 e^{4} \\cdot \\left(2 m_{e}^{4} + m_{e}^{2} \\left(- s_{13} - s_{24}\\right) + s_{12} s_{34} + s_{14} s_{23}\\right)}{\\left(2 m_{e}^{2} + reg_{prop} - 2 s_{13}\\right)^{2}}$"
      ],
      "text/plain": [
       "8*e**4*(2*m_e**4 + m_e**2*(-s_13 - s_24) + s_12*s_34 + s_14*s_23)/(2*m_e**2 + reg_prop - 2*s_13)**2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              mul                                                                              \n",
      " ┌───────┬─────────────┬───────────────────────────────────────┴──────────────────────────────────┐                                             \n",
      " │       │            pow                                                                        add                                           \n",
      " │       │       ┌─────┴──────────────┐                        ┌────────────────┬─────────────┬───┴────────────────┐                            \n",
      " │       │       │                   add                       │                │             │                   mul                          \n",
      " │       │       │     ┌──────────┬───┴────────┐               │                │             │            ┌───────┴────────────┐               \n",
      " │       │       │     │          │           mul             mul               │             │            │                   add             \n",
      " │       │       │     │          │        ┌───┴───┐       ┌───┴───┐            │             │            │           ┌────────┴───────┐       \n",
      " │      pow      │     │         mul       │      pow      │      pow          mul           mul          pow         mul              mul     \n",
      " │   ┌───┴───┐   │     │      ┌───┴───┐    │   ┌───┴───┐   │   ┌───┴───┐   ┌────┴───┐    ┌────┴───┐    ┌───┴───┐   ┌───┴───┐        ┌───┴───┐   \n",
      " 8   e       4   -2 reg_prop  -2     s_13  2  m_e      2   2  m_e      4  s_12     s_34 s_14     s_23 m_e      2   -1     s_13      -1     s_24\n",
      "\n",
      "tree_to_sympy:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{8 e^{4} \\cdot \\left(2 m_{e}^{4} + m_{e}^{2} \\left(- s_{13} - s_{24}\\right) + s_{12} s_{34} + s_{14} s_{23}\\right)}{\\left(2 m_{e}^{2} + reg_{prop} - 2 s_{13}\\right)^{2}}$"
      ],
      "text/plain": [
       "8*e**4*(2*m_e**4 + m_e**2*(-s_13 - s_24) + s_12*s_34 + s_14*s_23)/(2*m_e**2 + reg_prop - 2*s_13)**2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert squared amplitudes to trees:\n",
    "ctr = 0\n",
    "def try_sympy_to_tree(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sp2tree.sympy_to_tree(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_tree = [[try_sympy_to_tree(a) for a in tqdm(sq, leave=False)] for sq in sqamplitudes]\n",
    "display(sqamplitudes[2][0])\n",
    "sqampl_tree[2][0].pretty_print(unicodelines=True)\n",
    "\n",
    "# convert back\n",
    "print(\"tree_to_sympy:\")\n",
    "display(sp2tree.tree_to_sympy(sqampl_tree[2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export everything\n",
    "Loading and converting takes quite long. Let's export everything for easy reloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/2022-11-14/\"\n",
    "with open(export_folder+\"amplitudes.pickle\", \"wb\") as f:\n",
    "    pickle.dump(amplitudes, f)\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"wb\") as f:\n",
    "    pickle.dump(sqamplitudes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"amplitudes.pickle\", \"rb\") as f:\n",
    "    amplitudes = pickle.load(f)\n",
    "    amplitudes = [[a.split(\",\") for a in amps] for amps in amplitudes]\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"rb\") as f:\n",
    "    sqamplitudes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefix Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this base model we will be using prefix notation for the amplitudes and squared amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_tmp = []\n",
    "y_tmp = []\n",
    "for a, s in zip(amplitudes, sqampl_prefix):\n",
    "    X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "        a, s, test_size=0.1, random_state=42\n",
    "    )\n",
    "    X_train = X_train + X_train_i\n",
    "    X_tmp = X_tmp + X_test_i\n",
    "    y_train = y_train + y_train_i\n",
    "    y_tmp = y_tmp + y_test_i\n",
    "\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, random_state=42\n",
    ")\n",
    "X_val = X_val + X_train_i\n",
    "X_test = X_test + X_test_i\n",
    "y_val = y_val + y_train_i\n",
    "y_test = y_test + y_test_i\n",
    "\n",
    "del X_tmp, y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195\n",
      "1195\n",
      "67\n",
      "67\n",
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_val))\n",
    "print(len(y_val))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in X_train], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(y) for y in y_train], bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use those X,y where both are at most `sequence_length` long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X okay: 0.7841004184100419\n",
      "y okay: 0.45523012552301256\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 500\n",
    "sequence_length = 650\n",
    "batch_size = 1\n",
    "\n",
    "X_train_idx_okay = np.where([len(x) < sequence_length for x in X_train])[0]\n",
    "y_train_idx_okay = np.where([len(y) < sequence_length for y in y_train])[0]\n",
    "X_val_idx_okay = np.where([len(x) < sequence_length for x in X_val])[0]\n",
    "y_val_idx_okay = np.where([len(x) < sequence_length for x in y_val])[0]\n",
    "X_test_idx_okay = np.where([len(x) < sequence_length for x in X_test])[0]\n",
    "y_test_idx_okay = np.where([len(x) < sequence_length for x in y_test])[0]\n",
    "\n",
    "\n",
    "train_idx_okay = np.intersect1d(X_train_idx_okay, y_train_idx_okay) \n",
    "val_idx_okay = np.intersect1d(X_val_idx_okay, y_val_idx_okay) \n",
    "test_idx_okay = np.intersect1d(X_test_idx_okay, y_test_idx_okay) \n",
    "print(\"X okay:\", len(X_train_idx_okay) / len(X_train))\n",
    "print(\"y okay:\", len(y_train_idx_okay) / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_short = [X_train[i] for i in train_idx_okay]\n",
    "y_train_short = [y_train[i] for i in train_idx_okay]\n",
    "\n",
    "X_val_short = [X_val[i] for i in val_idx_okay]\n",
    "y_val_short = [y_val[i] for i in val_idx_okay]\n",
    "\n",
    "X_test_short = [X_test[i] for i in test_idx_okay]\n",
    "y_test_short = [y_test[i] for i in test_idx_okay]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices(amps):\n",
    "    amps = [\" \".join(a) for a in amps]\n",
    "    tmp = np.sort(np.unique(amps, return_index=True, axis=0)[1])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(get_unique_indices(X_train_short)): 460\n",
      "ic| len(X_train_short): 460\n"
     ]
    }
   ],
   "source": [
    "ic(len(get_unique_indices(X_train_short)));\n",
    "ic(len(X_train_short));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(get_unique_indices(y_train_short)): 238\n",
      "ic| len(y_train_short): 460\n"
     ]
    }
   ],
   "source": [
    "ic(len(get_unique_indices(y_train_short)));\n",
    "ic(len(y_train_short));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_diagram(x, y, new_electrons = [\"mu\", \"tau\", \"up\", \"down\", \"strange\", \"charm\", \"top\", \"bottom\"]):\n",
    "    \"\"\"\n",
    "    This does some augmentation by switching all electrons to muons etc.\n",
    "    Note that it is not so easy to only switch one electron in a process to say a muon.\n",
    "    \"\"\"\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    for e in new_electrons:\n",
    "        x_new = [xx.replace(\"ee\", e) for xx in x]\n",
    "        y_new = [yy.replace(\"m_e\", \"m_\"+e) for yy in y]\n",
    "        X_aug.append(x_new)\n",
    "        y_aug.append(y_new)\n",
    "    return X_aug, y_aug\n",
    "\n",
    "def augment_data(X, y, new_electrons = [\"mu\", \"tau\", \"up\", \"down\", \"strange\", \"charm\", \"top\", \"bottom\"]):\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    for x, y in zip(X_train_short, y_train_short):\n",
    "        new_data = augment_diagram(x, y, new_electrons=new_electrons)\n",
    "        X_aug = X_aug + new_data[0]\n",
    "        y_aug = y_aug + new_data[1]\n",
    "    return X_aug, y_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_data = augment_data(X_train_short, y_train_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3680"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_short)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3680"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augmentation_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Prod', 'i', 'Prod', 'Pow', 'e', '2', 'Prod', 'Pow', 'Sum', 's_23',\n",
       "       'Prod', '-1/2', 'reg_prop', '-1', 'Sum', 'Prod', 'p_1', 'alpha_7',\n",
       "       'Prod', 'gamma', 'alpha_8', 'alpha_2', 'alpha_0', 'Prod', 'A',\n",
       "       'i_3', 'alpha_8', '(p_3)', 'Prod', 'A', 'i_1', 'alpha_7', '(p_4)',\n",
       "       'Prod', 'ee^(*)', 'i_0', 'alpha_2', '(p_1)_u', 'ee', 'i_2',\n",
       "       'alpha_0', '(p_2)_v', 'Prod', '-1/2', 'Prod', 'p_4', 'alpha_6',\n",
       "       'Prod', 'gamma', 'alpha_6', 'alpha_4', 'alpha_5', 'Prod', 'gamma',\n",
       "       'alpha_7', 'alpha_3', 'alpha_4', 'Prod', 'gamma', 'alpha_8',\n",
       "       'alpha_5', 'alpha_1', 'Prod', 'A', 'i_3', 'alpha_8', '(p_3)',\n",
       "       'Prod', 'A', 'i_1', 'alpha_7', '(p_4)', 'Prod', 'ee^(*)', 'i_0',\n",
       "       'alpha_3', '(p_1)_u', 'ee', 'i_2', 'alpha_1', '(p_2)_v'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_short[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 4 e^{2} \\cdot \\left(2 m_{e}^{2} + s_{12}\\right)$"
      ],
      "text/plain": [
       "4*e**2*(2*m_e**2 + s_12)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_prefix_to_sympy(y_train_short[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 4 e^{2} \\cdot \\left(2 m_{\\mu}^{2} + s_{12}\\right)$"
      ],
      "text/plain": [
       "4*e**2*(2*m_mu**2 + s_12)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_prefix_to_sympy(augmentation_data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = [\" \".join(x) for x in X_train_short+augmentation_data[0]]\n",
    "y_train_text = [\" \".join(yy) for yy in y_train_short+augmentation_data[1]]\n",
    "\n",
    "X_val_text = [\" \".join(x) for x in X_val_short]\n",
    "y_val_text = [\" \".join(yy) for yy in y_val_short]\n",
    "\n",
    "X_test_text = [\" \".join(x) for x in X_test_short]\n",
    "y_test_text = [\" \".join(yy) for yy in y_test_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data.nosync/2022-11-14/'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading to sympy takes quite long.\n",
    "# We're here caching the alreaday converted amplitudes\n",
    "X_train_cache_file = export_folder+\"X_train.pickle\"\n",
    "y_train_cache_file = export_folder+\"y_train.pickle\"\n",
    "X_val_cache_file = export_folder+\"X_val.pickle\"\n",
    "y_val_cache_file = export_folder+\"y_val.pickle\"\n",
    "X_test_cache_file = export_folder+\"X_test.pickle\"\n",
    "y_test_cache_file = export_folder+\"y_test.pickle\"\n",
    "\n",
    "if os.path.exists(X_train_cache_file) & os.path.exists(y_train_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        X_train_text = pickle.load(f)\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        y_train_text = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_train_text, f)\n",
    "    with open(y_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_train_text, f)\n",
    "\n",
    "if os.path.exists(X_val_cache_file) & os.path.exists(y_val_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_val_cache_file, \"rb\") as f:\n",
    "        X_val_text = pickle.load(f)\n",
    "    with open(X_val_cache_file, \"rb\") as f:\n",
    "        y_val_text = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_val_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_val_text, f)\n",
    "    with open(y_val_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_val_text, f)\n",
    "\n",
    "if os.path.exists(X_test_cache_file) & os.path.exists(y_test_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        X_test_text = pickle.load(f)\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        y_test_text = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_test_text, f)\n",
    "    with open(y_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_test_text, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 16:49:12.031985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 16:49:12.032863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 16:49:12.033042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 16:49:12.033118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 16:49:12.516100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 16:49:12.516243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 16:49:12.516313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 16:49:12.516379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 364 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_string):\n",
    "    return input_string\n",
    "\n",
    "X_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=None,\n",
    ")\n",
    "\n",
    "y_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length+1,\n",
    "    standardize=None,\n",
    ")\n",
    "\n",
    "X_vectorization.adapt(X_train_text)\n",
    "y_vectorization.adapt(y_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(X, y):\n",
    "    X_vec = X_vectorization(X)\n",
    "    y_vec = y_vectorization(y)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": X_vec,\n",
    "            \"decoder_inputs\": y_vec[:, :-1],\n",
    "        },\n",
    "        y_vec[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(X_text, y_text):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_text, y_text))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(X_train_text, y_train_text)\n",
    "val_ds = make_dataset(X_val_text, y_val_text)\n",
    "test_ds = make_dataset(X_test_text, y_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (1, 650)\n",
      "inputs[\"decoder_inputs\"].shape: (1, 650)\n",
      "targets.shape: (1, 650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 16:49:15.149374: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "tmp = []\n",
    "for x in train_ds.as_numpy_iterator():\n",
    "    tmp.append(x)\n",
    "    ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4140"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4140"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 128)   147200      ['encoder_inputs[0][0]']         \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, None, 128)   791296      ['positional_embedding[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 500)    1530740     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,469,236\n",
      "Trainable params: 2,469,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128 # 256  # 512\n",
    "latent_dim = 1024 #2048  # 16384\n",
    "num_heads = 8\n",
    "\n",
    "# with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'learning rate')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def learning_rate_cyclic(epoch):\n",
    "    initial_lr = 0.0005\n",
    "    max_lr = 0.002\n",
    "    max_epochs = 5\n",
    "    if epoch <= (max_epochs / 2):\n",
    "        lr = initial_lr + (max_lr-initial_lr) * epoch/(max_epochs/2)\n",
    "        return lr\n",
    "    if (epoch > (max_epochs / 2)) & (epoch < max_epochs):\n",
    "        lr = max_lr - (max_lr-initial_lr) * (epoch-max_epochs/2)/(max_epochs/2)\n",
    "        return lr\n",
    "    else:\n",
    "        lr = initial_lr*np.exp(-(epoch-max_epochs)/10)\n",
    "        return lr\n",
    "\n",
    "xrange = range(0,50)\n",
    "yrange = [learning_rate_cyclic(x) for x in xrange]\n",
    "plt.plot(xrange, yrange)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 128)   147200      ['encoder_inputs[0][0]']         \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, None, 128)   791296      ['positional_embedding[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 500)    1530740     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,469,236\n",
      "Trainable params: 2,469,236\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 69s 17ms/step - loss: 0.0219 - accuracy: 0.9817 - val_loss: 0.1029 - val_accuracy: 0.9524 - lr: 5.0000e-04\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 101s 24ms/step - loss: 0.0424 - accuracy: 0.9680 - val_loss: 0.0972 - val_accuracy: 0.9500 - lr: 0.0011\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 100s 24ms/step - loss: 0.0573 - accuracy: 0.9572 - val_loss: 0.1090 - val_accuracy: 0.9326 - lr: 0.0017\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 85s 20ms/step - loss: 0.0439 - accuracy: 0.9667 - val_loss: 0.1043 - val_accuracy: 0.9399 - lr: 0.0017\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 54s 13ms/step - loss: 0.0261 - accuracy: 0.9790 - val_loss: 0.0959 - val_accuracy: 0.9505 - lr: 0.0011\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 0.0180 - accuracy: 0.9845 - val_loss: 0.1044 - val_accuracy: 0.9577 - lr: 5.0000e-04\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 53s 13ms/step - loss: 0.0177 - accuracy: 0.9848 - val_loss: 0.1114 - val_accuracy: 0.9573 - lr: 4.5242e-04\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 52s 13ms/step - loss: 0.0173 - accuracy: 0.9851 - val_loss: 0.1191 - val_accuracy: 0.9587 - lr: 4.0937e-04\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 52s 13ms/step - loss: 0.0156 - accuracy: 0.9868 - val_loss: 0.1145 - val_accuracy: 0.9582 - lr: 3.7041e-04\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 52s 13ms/step - loss: 0.0056 - accuracy: 0.9958 - val_loss: 0.1142 - val_accuracy: 0.9751 - lr: 3.3516e-04\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 52s 12ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.1129 - val_accuracy: 0.9756 - lr: 3.0327e-04\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 7.2760e-04 - accuracy: 0.9996 - val_loss: 0.1205 - val_accuracy: 0.9744 - lr: 2.7441e-04\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 5.9622e-04 - accuracy: 0.9997 - val_loss: 0.1199 - val_accuracy: 0.9756 - lr: 2.4829e-04\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 2.9722e-04 - accuracy: 0.9999 - val_loss: 0.1215 - val_accuracy: 0.9754 - lr: 2.2466e-04\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 3.5278e-04 - accuracy: 0.9998 - val_loss: 0.1177 - val_accuracy: 0.9768 - lr: 2.0328e-04\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 52s 12ms/step - loss: 2.4685e-04 - accuracy: 0.9999 - val_loss: 0.1222 - val_accuracy: 0.9761 - lr: 1.8394e-04\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 52s 12ms/step - loss: 1.8691e-04 - accuracy: 0.9999 - val_loss: 0.1263 - val_accuracy: 0.9761 - lr: 1.6644e-04\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 52s 12ms/step - loss: 1.1786e-04 - accuracy: 0.9999 - val_loss: 0.1380 - val_accuracy: 0.9744 - lr: 1.5060e-04\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 52s 12ms/step - loss: 7.5638e-05 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9758 - lr: 1.3627e-04\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 8.5548e-05 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9749 - lr: 1.2330e-04\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 6.3225e-05 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9764 - lr: 1.1157e-04\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 4.5650e-05 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9759 - lr: 1.0095e-04\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 2.1910e-05 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9775 - lr: 9.1342e-05\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 4.2115e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9771 - lr: 8.2649e-05\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 1.0426e-05 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9775 - lr: 7.4784e-05\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 7.0926e-06 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9770 - lr: 6.7668e-05\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 8.6936e-06 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9766 - lr: 6.1228e-05\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 2.7200e-06 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9778 - lr: 5.5402e-05\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 50s 12ms/step - loss: 1.9928e-06 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9776 - lr: 5.0129e-05\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 51s 12ms/step - loss: 3.6932e-06 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9768 - lr: 4.5359e-05\n"
     ]
    }
   ],
   "source": [
    "epochs = 30  # This should be at least 30 for convergence\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(learning_rate_cyclic)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/2022-11-14-Transformer_upto3to3_unique_augmented\", save_best_only=True, monitor=\"val_loss\", save_weights_only=True\n",
    ")\n",
    "\n",
    "callbacks = [lr_schedule, checkpoint]\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = transformer.fit(train_ds, epochs=epochs, validation_data=val_ds,\n",
    "                          callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fa49c515e50>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_weights(\"models/2022-11-14-Transformer_upto3to3_unique_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vocab = y_vectorization.get_vocabulary()\n",
    "y_index_lookup = dict(zip(range(len(y_vocab)), y_vocab))\n",
    "max_decoded_sentence_length = 350\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = X_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = y_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = y_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[END]\":\n",
    "            break\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.07 s, sys: 307 ms, total: 8.38 s\n",
      "Wall time: 8.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[start] s- 2 mul pow e 2 add mul s- 1 s_12 mul 2 pow m_down 2  add add add 2 add mul add s_25  s_14 add s_25 s_13 s_14 add add s_14 2 mul mul s_14 mul mul 2   s_13 mul s_15  s_25  mul 2 s_34 s_13 s_25 mul s_24 s_23 2 s_34 s_15 s_15 s_15 s_13 add s_23 add s_14 pow s_14 s_34 s_34 s_34 s_34  s_23 2 4 s_45 add s_14 s- s_12 s_25 add s_34 add add add add 2 add s_35 2 4 add mul mul add s_24 s- s_13 mul 2 mul s_12 s_15 2 s_24 mul mul mul  s_12 s_14 s_14  s_14  mul s_16 mul 2 mul s_12 mul 2  pow s_34 s_24 s_24 pow  s_34 s_13  8 s_45 add 2 add 2 mul s_14 mul s_25 mul  s_45 add  mul add s_14 s_14 2  mul s_34  s_13 s_12 mul s_15 mul  s_35 s_34 2 mul s_25 s_45 s_12 s_12 s_14 s_13 s_34 2 s_34 s_13 mul s_14 s_23 add s_34 s_13 s_45 mul s_15 add s_23 s- mul mul mul s_14 mul s_23 s-  s_34  s_45  mul  s_15 mul s_56 mul mul mul 1 s_45 s_15  s_35 mul mul s_14 s_25 4 s_15 mul mul s_34 2 4 mul s_24 1  add s_34 s_14 mul mul  s_45 add add mul add mul mul pow  mul 2 2 2 s_34 2 mul mul  add 2 mul mul s_23 s_35 mul mul 2 mul mul 2 2 mul mul mul mul  2 mul 2  mul mul mul mul mul 2 mul 4 s_34 mul mul pow s_34 4 mul 2 2 mul s_45 mul 2 mul 2 mul 2 mul s_23 s_45 2 s_14 4 s_45 s_24 s_25 pow s_13 2 add s_13 s_13 s_25 mul 2 2 2  s_34  s_45 s_25 s_12  s- add s_45 mul mul  2 mul 4 s_13 add add mul s_34 4 2 s_45 s_23 m_up add'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "decode_sequence(X_train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mul 4 mul pow e 2 add s_12 mul 2 pow m_e 2'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[start] 8 mul pow e 6 mul pow add mul s- 1 reg_prop mul 2 s_14 s- 2 mul pow add reg_prop add mul s- 2 s_14 add mul s- 2 s_24 mul 2 s_12 s- 2 add mul s- 4 s_14 mul 2 add mul pow m_up 2 add mul s- 2 mul s_14 s_34 add mul s- 2 mul s_14 s_45 mul s- 2 mul 2 mul s_14 s_35 add mul s_15 s_25 add mul 4 mul s_14 s_35 add mul pow m_up 4 add mul s- 4 s_35 add mul s- 2 s_34 add mul s- 2 s_45 add mul 2 s_13 add mul 2 s_15 mul 4 s_14 mul 2 mul s_14 mul s_35 s_45  4 mul mul s_34 s_14 s_34 2 s_35 s_25 s_13 s_14 s_14 pow s_45 add s_13 s_23 mul s_45 mul s_24 s_15 s_45 mul s_14 8 s_25 mul add s_15 mul s_15 s_15 s_34 mul s_45 2 add mul s_25 s_16 s_26 s_45 mul s_56 mul s_35 s_35 s_23 s_25 mul s_23 mul s_12 add add add add mul mul s_15 mul s_15 mul add mul add s_35 add s_25 add s_45 add s_15 mul add s_13 mul s_34 s- s_15 mul  2  mul add mul mul mul s_45 s_14 mul pow mul s-  add mul s_34 s_15 s_35 4 s_35 s_15 mul s- mul mul 1 s_24 s_45 1 add s_34 s_45 s_24 mul add s_35 s_24 s_45 s_45 add mul mul s_45 s_45 mul s_46 s_14 2 mul mul mul add s_23 add mul s- mul s_23 2 mul s_14 mul mul 2 s_13 mul mul mul mul s_15 s_15 2 mul mul add mul s_36 mul mul s_12 mul mul 4 mul mul mul mul s_14 pow mul s_15 mul mul s_45 mul mul mul 2 mul 4 mul s_15 mul 2 s_13 s_12 s_45 s_34 add s_15 4 2 add s_13 s_56 s_15 s_15 s_34 s_15 2 add s_14 s_34 s_35 s_25 s_34 pow s_15 add s_14 add s_35 s_35 4 s_12 4 s_13 add s- s- s_45 s_35 s_23 add add s_15 mul'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(X_val_text[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mul 8 mul pow e 6 mul pow add mul s- 1 reg_prop mul 2 s_14 s- 2 mul pow add reg_prop add mul s- 2 s_14 add mul s- 2 s_24 mul 2 s_12 s- 2 add mul s- 4 pow m_e 6 add mul pow m_e 2 add mul s- 2 mul s_14 s_34 add mul s- 2 mul s_14 s_45 add mul s- 2 mul s_15 s_35 add mul 2 mul s_35 s_45 mul 4 mul s_14 s_35 add mul pow m_e 4 add mul s- 4 s_35 add mul s- 2 s_34 add mul s- 2 s_45 add mul 2 s_13 add mul 2 s_15 mul 4 s_14 mul 2 mul s_14 mul s_35 s_45'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_text[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4adc2ea131058d4ca334736eaf83f8a99f586a60b7e02773f5921bb39d3dbeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model QED\n",
    "This is the base setup for working on QED data.\n",
    "It shows how to import the data and how to convert the expressions into different formats.\n",
    "\n",
    "amplitdues: prefix  \n",
    "squared amplitdues: hybrid prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    # Install the most re version of TensorFlow to use the improved\n",
    "    # masking support for `tf.keras.layers.MultiHeadAttention`.\n",
    "    !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
    "    !pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
    "    !pip install -q tensorflow_datasets\n",
    "    !pip install -q -U tensorflow-text tensorflow\n",
    "    !pip install -q icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/SYMBA/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:40:52.054966: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 15:40:52.228170: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-01 15:40:52.295970: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-01 15:40:52.969483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-12-01 15:40:52.969542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-12-01 15:40:52.969547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "import sympy as sp\n",
    "from itertools import (takewhile,repeat)\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:40:54.244572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 15:40:54.279567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 15:40:54.279757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocessing.tree.sympy_to_tree as sp2tree\n",
    "from data_preprocessing.sympy_prefix.source.SympyPrefix import prefix_to_sympy, sympy_to_prefix, sympy_to_hybrid_prefix, hybrid_prefix_to_sympy\n",
    "from data_preprocessing.ampl_tree.source.ampl_to_tree import ampl_to_tree, raw_ampl_to_tree, expand_tree, contract_tree, subscripts_to_subtree, rename_indices, get_tree, tree_to_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocessing.expressions_shortener.expressions_shortener as es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This only needs to be run once, then the data is cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_i(expr_str):\n",
    "    reg_ex = \"[^a-z]i[^a-z,^\\d]\"\n",
    "    replaced = re.sub(reg_ex, fix_i_match, expr_str)\n",
    "    return replaced\n",
    "    \n",
    "def fix_i_match(matchobj):\n",
    "    \"\"\"\n",
    "    i --> I\n",
    "    \"\"\"\n",
    "    match = matchobj.group(0)\n",
    "    return match.replace(\"i\", \"I\")\n",
    "\n",
    "\n",
    "def rawincount(filename):\n",
    "    \"\"\"count numer of lines in a file. \n",
    "    From https://stackoverflow.com/questions/845058/how-to-get-line-count-of-a-large-file-cheaply-in-python\n",
    "    \"\"\"\n",
    "    f = open(filename, 'rb')\n",
    "    bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))\n",
    "    return sum( buf.count(b'\\n') for buf in bufgen )\n",
    "\n",
    "def load_raw_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading raw amplitudes from filename.\n",
    "    \n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "    \"\"\"\n",
    "    print(\"Loading amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "        ic(number_of_lines)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        ctr = 0\n",
    "        data[ctr] = line.replace(\"\\n\", \"\").split(\";\")\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                data[ctr] = line.replace(\"\\n\", \"\").split(\";\")\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_squared_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading squared amplitudes from filename and parsing into sympy.\n",
    "    All squared amplitudes should be exportet from sympy and thus be readable\n",
    "    without any preprocessing.\n",
    "\n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "\n",
    "    Returns:\n",
    "        list of squared amplitudes, each as a sympy expression\n",
    "    \"\"\"\n",
    "    print(\"Loading squared amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "        ic(number_of_lines)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "       line = f.readline()\n",
    "       line_sp = sp.sympify(line.strip())\n",
    "       ctr = 0\n",
    "       data[ctr] = line_sp\n",
    "       while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                line = line.strip()\n",
    "                line = fix_i(line)\n",
    "                line_sp = sp.sympify(line.strip())\n",
    "                data[ctr] = line_sp\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data.nosync/\"\n",
    "amplitudes_filename_start = \"QED_amplitudes_TreeLevel_\"\n",
    "sqamplitudes_filename_start = \"QED_sqamplitudes_TreeLevel_\"\n",
    "processes = [\"1to2\", \"2to1\", \"2to2\", \"2to3\", \"3to2\"]\n",
    "max_lines = -1\n",
    "\n",
    "amplitudes = []\n",
    "sqamplitudes = []\n",
    "for process in processes:\n",
    "    ampl_f = data_folder + amplitudes_filename_start + process + \"_raw\"+ \".txt\"\n",
    "    sqampl_f = data_folder + sqamplitudes_filename_start + process + \".txt\"\n",
    "    amplitudes_process = load_raw_amplitudes(ampl_f, max_lines=max_lines)\n",
    "    sqamplitudes_process = load_squared_amplitudes(sqampl_f, max_lines=max_lines)\n",
    "    amplitudes.append(amplitudes_process)\n",
    "    sqamplitudes.append(sqamplitudes_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the different amplitudes separated for now, so `amplitudes` has the form\n",
    "`[multiplicity, i]` where `multiplicity = [\"1to2\", \"2to1\", ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prod', '(', '2/3', 'i', 'e', 'gamma_{%\\\\lambda_169,%eta_137,%del_161}', 'A_{l_3,+%\\\\lambda_169}(p_3)', 'c_{i_3,%eta_137}(p_1)_u^(*)', 'c_{k_3,%del_161}(p_2)_u', ')']\n"
     ]
    }
   ],
   "source": [
    "print(amplitudes[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8*e**2*(2*m_c**2 - s_12)/9\n"
     ]
    }
   ],
   "source": [
    "print(sqamplitudes[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, sqa in zip(amplitudes, sqamplitudes):\n",
    "    assert len(a) == len(sqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(a): 431\n",
      "ic| len(sqa): 431\n",
      "ic| len(a): 431\n",
      "ic| len(sqa): 431\n",
      "ic| len(a): 10943\n",
      "ic| len(sqa): 10943\n",
      "ic| len(a): 129023\n",
      "ic| len(sqa): 129023\n",
      "ic| len(a): 129023\n",
      "ic| len(sqa): 129023\n"
     ]
    }
   ],
   "source": [
    "# the amplitudes are in prefix format\n",
    "for a, sqa in zip(amplitudes, sqamplitudes):\n",
    "    ic(len(a))\n",
    "    ic(len(sqa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only unique amplitudes\n",
    "We only want unique amplitudes, others are thrown away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices(amps):\n",
    "    amps = [\" \".join(a) for a in amps]\n",
    "    tmp = np.sort(np.unique(amps, return_index=True, axis=0)[1])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices = [get_unique_indices(a) for a in amplitudes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_unique_a = [[amplitudes[j][ind] for ind in unique_indices[j]] for j in range(len(amplitudes))]\n",
    "sqamplitudes_corresponding_a = [[sqamplitudes[j][ind] for ind in unique_indices[j]] for j in range(len(amplitudes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes.pickle\", \"bw\") as f:\n",
    "    pickle.dump(amplitudes_unique_a, f)\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"bw\") as f:\n",
    "    pickle.dump(sqamplitudes_corresponding_a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Format Conversion\n",
    "We need to convert the squared amplitudes, which are sympy expressions now, into something. In this notebook we will use the prefix notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes.pickle\", \"rb\") as f:\n",
    "    amplitudes_unique = pickle.load(f)\n",
    "    # amplitudes_unique = [[a.split(\",\") for a in amps] for amps in amplitudes_unique]\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"rb\") as f:\n",
    "    sqamplitudes_corresponding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986683db0053428884316d67bb4917a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870e0db07f9d47a1be8681c7d1ab73ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46033fdec8c4bb685a00e7105d5c85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6d4a7597064597bd697a91a1dcb4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783f1de011ba4fa5b69c13240add9fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_mu', '2', ')'], dtype='<U4')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorten expressions with expressions_shortener\n",
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_hybrid_prefix(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sympy_to_hybrid_prefix(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_hybrid_prefix = [[try_sympy_to_hybrid_prefix(a) for a in tqdm(sq)] for sq in sqamplitudes_corresponding]\n",
    "np.array(sqampl_hybrid_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320eed7aeefc411182f25dc24c42ed72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f921f6dfc9045a5afa2faedaa132a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b649cfa200140648a1d14a545abc4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb7ca98604d4d0caad649bcb352e6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210e62557fff496f802a2e334421f3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_mu', '2', ')'], dtype='<U4')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorten expressions with expressions_shortener\n",
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_hybrid_prefix_short(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        expr_shortened = es.shorten_expression(expr)\n",
    "        return sympy_to_hybrid_prefix(expr_shortened)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_hybrid_prefix_short = [[try_sympy_to_hybrid_prefix_short(a) for a in tqdm(sq)] for sq in sqamplitudes_corresponding]\n",
    "np.array(sqampl_hybrid_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqampls_lengths = [[len(a) for a in sqampls] for sqampls in sqampl_hybrid_prefix]\n",
    "sqampls_lengths_short = [[len(a) for a in sqampls] for sqampls in sqampl_hybrid_prefix_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths_short, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791f873be94544fdb8ba13cbe11fec03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31687f3fd13f4024977f769cb093ebb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca795df52e254a2bb065de1c87f59537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00e328e53dd4a35896dff704c499680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82d2344aae14ec993bad4492cc33e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert amplitudes to prefix\n",
    "amplitudes_tree = [[raw_ampl_to_tree(a, needs_split=False) for a in tqdm(aa)] for aa in amplitudes_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Prod                                                 \n",
      " ┌───┬───┬─────────────────┬────────────────────────┼────────────────────┬───────────────────┐           \n",
      " │   │   │               gamma                    A^(*)                 mu_u              mu_u^(*)      \n",
      " │   │   │       ┌─────────┼────────┐      ┌────────┼────────┐    ┌──────┼───────┐    ┌──────┼───────┐   \n",
      " -1  i   e  %lambda_167 %eta_137 %gam_155 %l_3 %lambda_167 (p_3) %i_3 %gam_155 (p_1) %k_3 %eta_137 (p_2)\n",
      "\n",
      "                                               Prod                                                \n",
      " ┌────┬───┬──────────────┬──────────────────────┼───────────────────┬───────────────────┐           \n",
      " │    │   │            gamma                  A^(*)                b_u               b_u^(*)       \n",
      " │    │   │     ┌────────┼────────┐      ┌──────┼───────┐    ┌──────┼───────┐    ┌──────┼───────┐   \n",
      "-1/3  i   e  %tau_111 %del_171 %del_172 %l_3 %tau_111 (p_3) %i_3 %del_172 (p_1) %k_3 %del_171 (p_2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amplitudes_tree[0][0].pretty_print(unicodelines=True)\n",
    "amplitudes_tree[0][-10].pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2f64672de34cda96529aeba060ed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488ea7fc1ed249e7b68651fd9c3b377c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e52d4de14d14a72b836160850630315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39008b536764c519b62fd88dff088d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609b6194286e48fd90e7ea5bf672bb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amplitudes_hybrid_prefix = [[tree_to_prefix(t, hybrid=True) for t in tqdm(tt)] for tt in amplitudes_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Prod(',\n",
       " '-1',\n",
       " 'i',\n",
       " 'e',\n",
       " 'gamma',\n",
       " '%lambda_167',\n",
       " '%eta_137',\n",
       " '%gam_155',\n",
       " 'A^(*)',\n",
       " '%l_3',\n",
       " '%lambda_167',\n",
       " '(p_3)',\n",
       " 'mu_u',\n",
       " '%i_3',\n",
       " '%gam_155',\n",
       " '(p_1)',\n",
       " 'mu_u^(*)',\n",
       " '%k_3',\n",
       " '%eta_137',\n",
       " '(p_2)',\n",
       " ')']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes_hybrid_prefix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"amplitudes_hybrid_prefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(amplitudes_hybrid_prefix, f)\n",
    "# with open(export_folder+\"sqampl_hybrid_prefix_short.pickle\", \"bw\") as f:\n",
    "#     pickle.dump(sqampl_hybrid_prefix_short, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reloading converted amplitudes and squared amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes_hybrid_prefix.pickle\", \"br\") as f:\n",
    "    amplitudes_hybrid_prefix = pickle.load(f)\n",
    "with open(export_folder+\"sqampl_hybrid_prefix_short.pickle\", \"br\") as f:\n",
    "    sqampl_hybrid_prefix_short = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prod(', '-1', 'i', 'e', 'gamma', '%lambda_167', '%eta_137', '%gam_155', 'A^(*)', '%l_3', '%lambda_167', '(p_3)', 'mu_u', '%i_3', '%gam_155', '(p_1)', 'mu_u^(*)', '%k_3', '%eta_137', '(p_2)', ')']\n",
      "['Prod(', '-1/3', 'i', 'e', 'gamma', '%tau_111', '%del_171', '%del_172', 'A^(*)', '%l_3', '%tau_111', '(p_3)', 'b_u', '%i_3', '%del_172', '(p_1)', 'b_u^(*)', '%k_3', '%del_171', '(p_2)', ')']\n"
     ]
    }
   ],
   "source": [
    "print(amplitudes_hybrid_prefix[0][0])\n",
    "print(amplitudes_hybrid_prefix[0][-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1', 's_12', 'mul', '2', 'm2mu', ')']\n",
      "['mul(', 'mul', 's-', '4', 'pow', '9', 's-', '1', 'pow', 'e', '2', 'add', 'mul', 's-', '1', 's_12', 'mul', '2', 'm2b', ')']\n"
     ]
    }
   ],
   "source": [
    "print(sqampl_hybrid_prefix_short[0][0])\n",
    "print(sqampl_hybrid_prefix_short[0][-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampls_lengths = [[len(a) for a in ampls] for ampls in amplitudes_hybrid_prefix]\n",
    "sqampls_lengths_short = [[len(a) for a in sqampls] for sqampls in sqampl_hybrid_prefix_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ampls_lengths, bins=100,);\n",
    "plt.xlabel(\"amplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths_short, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have a maximal sequence length of 350.\n",
    "Let's do a train-test split and then filter out the too long amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(len(amplitudes_hybrid_prefix)):\n",
    "    X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(amplitudes_hybrid_prefix[i], sqampl_hybrid_prefix_short[i],\n",
    "        test_size=0.1, random_state=42)\n",
    "    X_train.append(X_train_tmp)\n",
    "    y_train.append(y_train_tmp)\n",
    "    X_test.append(X_test_tmp)\n",
    "    y_test.append(y_test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"X_train_a_hprefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(export_folder+\"y_train_a_hprefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open(export_folder+\"X_test_a_hprefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open(export_folder+\"y_test_a_hprefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"X_train_a_hprefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(export_folder+\"y_train_a_hprefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(export_folder+\"X_test_a_hprefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(export_folder+\"y_test_a_hprefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use those X,y where both are at most `sequence_length` long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_long(X, y, idxs_okay_export, max_seq_len=350, idxs_okay=None):\n",
    "    \"\"\"\n",
    "    find indices where X and y are less than `max_seq_len` long.\n",
    "    Append to `idxs_okay_export`.\n",
    "    \"\"\"\n",
    "    if idxs_okay is None:\n",
    "        X_idxs_ok = np.where([len(x) < max_seq_len for x in X])[0]\n",
    "        y_idxs_ok = np.where([len(y) < max_seq_len for y in y])[0]\n",
    "        idxs_okay = np.intersect1d(X_idxs_ok, y_idxs_ok) \n",
    "    idxs_okay_export.append(idxs_okay)\n",
    "    X_new = [X[i] for i in idxs_okay]\n",
    "    y_new = [y[i] for i in idxs_okay]\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "max_seq_len = 350\n",
    "batch_size = 1\n",
    "\n",
    "idxs_train_okay_export = []\n",
    "X_train_filtered, y_train_filtered = [], []\n",
    "for i in range(len(X_train)):\n",
    "    X_train_filtered_tmp, y_train_filtered_tmp = remove_too_long(\n",
    "        X_train[i], y_train[i], idxs_train_okay_export, max_seq_len=max_seq_len)\n",
    "    X_train_filtered.append(X_train_filtered_tmp)\n",
    "    y_train_filtered.append(y_train_filtered_tmp)\n",
    "\n",
    "idxs_test_okay_export = []\n",
    "X_test_filtered, y_test_filtered = [], []\n",
    "for i in range(len(X_test)):\n",
    "    X_test_filtered_tmp, y_test_filtered_tmp = remove_too_long(\n",
    "        X_test[i], y_test[i], idxs_test_okay_export, max_seq_len=max_seq_len)\n",
    "    X_test_filtered.append(X_test_filtered_tmp)\n",
    "    y_test_filtered.append(y_test_filtered_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.93889093, 0.93845448])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of amplitudes kept depending on process (1to1, 1to2, ...)\n",
    "np.array([len(idx) for idx in idxs_train_okay_export]) / np.array([len(idx) for idx in X_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9403531214208154"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of all amplitudes that are kept (not too long)\n",
    "np.sum([len(idx) for idx in idxs_train_okay_export]) / np.sum([len(idx) for idx in X_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_filtered)):\n",
    "    assert len(X_train_filtered[i]) == len(y_train_filtered[i])\n",
    "\n",
    "for i in range(len(X_test_filtered)):\n",
    "    assert len(X_test_filtered[i]) == len(y_test_filtered[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = [[\" \".join(x) for x in X] for X in X_train_filtered]\n",
    "y_train_final = [[\" \".join(yy) for yy in y] for y in y_train_filtered]\n",
    "\n",
    "X_test_final = [[\" \".join(x) for x in X] for X in X_test_filtered]\n",
    "y_test_final = [[\" \".join(yy) for yy in y] for y in y_test_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prod(', '-1', 'i', 'e', 'gamma', '%lambda_167', '%eta_137', '%del_155', 'A', '%l_3', '%lambda_167', '(p_3)', 'mu_u^(*)', '%i_3', '%eta_137', '(p_1)', 'mu_u', '%k_3', '%del_155', '(p_2)', ')']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mul(', 's-', '2', 'pow', 'e', '2', 'add', 'mul', 's-', '1', 's_12', 'mul', '2', 'm2mu', ')']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset, Data Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "vocab_size = 500\n",
    "max_seq_len = 350\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "# reading to sympy takes quite long.\n",
    "# We're here caching the alreaday converted amplitudes\n",
    "X_train_cache_file = export_folder+\"X_train_final_Xhp_yhp.pickle\"\n",
    "y_train_cache_file = export_folder+\"y_train_final_Xhp_yhp.pickle\"\n",
    "X_test_cache_file = export_folder+\"X_test_final_Xhp_yhp.pickle\"\n",
    "y_test_cache_file = export_folder+\"y_test_final_Xhp_yhp.pickle\"\n",
    "\n",
    "if os.path.exists(X_train_cache_file) & os.path.exists(y_train_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        X_train_final = pickle.load(f)\n",
    "    with open(y_train_cache_file, \"rb\") as f:\n",
    "        y_train_final = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_train_final, f)\n",
    "    with open(y_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_train_final, f)\n",
    "\n",
    "if os.path.exists(X_test_cache_file) & os.path.exists(y_test_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        X_test_final = pickle.load(f)\n",
    "    with open(y_test_cache_file, \"rb\") as f:\n",
    "        y_test_final = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_test_final, f)\n",
    "    with open(y_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_test_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod( -1/3 i e gamma %nu_92 %gam_161 %del_167 A %l_3 %nu_92 (p_3) d_u^(*) %i_3 %gam_161 (p_1) d_v %k_3 %del_167 (p_2) )'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mul( mul 4 pow 9 s- 1 pow e 2 add s_12 mul 2 m2d )'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "X_train_all = flatten(X_train_final)\n",
    "y_train_all = flatten(y_train_final) \n",
    "\n",
    "X_test_all = flatten(X_test_final)\n",
    "y_test_all = flatten(y_test_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ds, ds_size, train_split=0.9, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split>=0) & (train_split<=1)\n",
    "    # test_split = 1 - train_split\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    train_ds = ds.take(train_size)    \n",
    "    test_ds = ds.skip(train_size)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 17:29:34.696898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 17:29:34.698403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 17:29:34.698595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 17:29:34.698672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 17:29:35.218499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 17:29:35.218662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 17:29:35.218738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 17:29:35.218807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6019 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "df_train = tf.data.Dataset.from_tensor_slices((X_train_all, y_train_all)).prefetch(2)\n",
    "df_test = tf.data.Dataset.from_tensor_slices((X_test_all, y_test_all)).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train, df_train.cardinality().numpy(), train_split=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| df_val.cardinality().numpy(): 2529\n",
      "ic| df_train.cardinality().numpy(): 123909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9795898603007045>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(df_val.cardinality().numpy())\n",
    "ic(df_train.cardinality().numpy())\n",
    "1 - df_val.cardinality() / df_train.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplitudes:\n",
      "b'Prod( 1/27 i Pow e 3 Pow Sum( s_11 Prod 2 s_13 Prod -2 s_14 Prod -2 s_34 s_44 reg_prop ) -1 Pow Sum( Pow m_s 2 Prod 2 s_34 Prod -1 s_44 Prod -1 reg_prop ) -1 gamma %lambda_184 %eta_211 %eps_41 gamma %tau_161 %del_216 %eta_212 Sum( Prod m_s gamma %tau_161 %eta_210 %eta_211 Prod( p_1 %tau_164 gamma %tau_161 %eta_210 %eta_273 gamma %tau_164 %eta_273 %eta_211 ) Prod( p_2 %tau_164 gamma %tau_161 %eta_210 %eta_274 gamma %tau_164 %eta_274 %eta_211 ) Prod( -1 p_5 %tau_164 gamma %tau_161 %eta_210 %eta_275 gamma %tau_164 %eta_275 %eta_211 ) ) A^(*) %i_5 %lambda_184 (p_3) b_u^(*) %k_3 %del_216 (p_2) b_u %l_5 %eta_212 (p_5) s_u^(*) %i_3 %eta_210 (p_1) s_u %k_5 %eps_41 (p_4) )'\n",
      "b'Prod( 8/27 i Pow e 3 Pow Sum( Pow m_s 2 Prod 2 s_34 s_44 reg_prop ) -1 Pow Sum( Pow m_s 2 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 s_44 reg_prop ) -1 Sum( Prod( p_1 %lambda_388 gamma %lambda_386 %eta_650 %eta_651 gamma %lambda_388 %eta_652 %eps_136 A %k_3 %lambda_386 (p_2) c_v^(*) %i_3 %eta_650 (p_1) c_v %l_5 %eta_651 (p_5) s_u^(*) %i_5 %eta_652 (p_3) s_v %k_5 %eps_136 (p_4) ) Prod( -1/2 p_3 %sigma_172 gamma %sigma_172 %eta_708 %eta_709 gamma %lambda_386 %eta_709 %eta_658 gamma %lambda_388 %eta_657 %eta_708 gamma %lambda_388 %eta_661 %eps_138 A %k_3 %lambda_386 (p_2) c_v^(*) %i_3 %eta_657 (p_1) c_v %l_5 %eta_658 (p_5) s_u^(*) %i_5 %eta_661 (p_3) s_v %k_5 %eps_138 (p_4) ) Prod( -1/2 p_4 %sigma_172 gamma %sigma_172 %eta_710 %eta_711 gamma %lambda_386 %eta_711 %eta_663 gamma %lambda_388 %eta_662 %eta_710 gamma %lambda_388 %eta_666 %eps_139 A %k_3 %lambda_386 (p_2) c_v^(*) %i_3 %eta_662 (p_1) c_v %l_5 %eta_663 (p_5) s_u^(*) %i_5 %eta_666 (p_3) s_v %k_5 %eps_139 (p_4) ) ) )'\n",
      "b'Prod( -1/27 i Pow e 3 Pow Sum( Pow m_b 2 Prod 2 s_13 Prod -2 s_14 s_33 Prod -2 s_34 s_44 reg_prop ) -1 Pow Sum( s_13 Prod 1/2 s_33 Prod 1/2 reg_prop ) -1 Sum Prod( p_1 %tau_546 gamma %tau_549 %gam_746 %eps_43 gamma %tau_549 %del_738 %eta_379 A^(*) %l_3 %tau_546 (p_3) b_u^(*) %i_3 %gam_746 (p_1) b_u^(*) %k_3 %del_738 (p_2) b_u %j_5 %eps_43 (p_4) b_u %k_5 %eta_379 (p_5) ) Prod( 1/2 p_3 %nu_200 gamma %nu_200 %gam_772 %gam_773 gamma %tau_546 %gam_749 %gam_772 gamma %tau_549 %gam_773 %eps_45 gamma %tau_549 %del_740 %eta_381 A^(*) %l_3 %tau_546 (p_3) b_u^(*) %i_3 %gam_749 (p_1) b_u^(*) %k_3 %del_740 (p_2) b_u %j_5 %eps_45 (p_4) b_u %k_5 %eta_381 (p_5) ) )'\n",
      "squared amplitudes:\n",
      "b'mul( mul 16 pow 729 s- 1 pow e 6 pow add( m2s mul s- 1 reg_prop mul s- 1 s_44 mul 2 s_34 ) s- 2 pow add( reg_prop s_11 s_44 mul s- 2 s_14 mul s- 2 s_34 mul 2 s_13 ) s- 2 add( mul 2 m4bxs_14 mul 2 m4sxs_25 mul m2b add( mul( s- 1 s_11 s_14 ) mul( s- 4 s_12 s_24 ) mul( s- 4 s_15 s_45 ) mul( s- 2 s_11 s_24 ) mul( s- 2 s_12 s_14 ) mul( s- 2 s_14 s_25 ) mul( 2 s_11 s_45 ) mul( 2 s_12 s_45 ) mul( 2 s_14 s_15 ) mul( 2 s_15 s_24 ) ) mul m2s add( mul s- 4 pow s_25 2 mul s_12 s_45 mul s_15 s_24 mul( s- 8 s_12 s_15 ) mul( s- 2 s_14 s_25 ) mul( s- 2 s_24 s_25 ) mul( 2 s_11 s_25 ) mul( 2 s_25 s_45 ) ) mul( s- 8 m2s m4b ) mul( s- 4 m2b m4s ) mul( s- 2 s_45 pow s_12 2 ) mul( 2 s_24 pow s_15 2 ) mul( m2b m2s add( mul s- 4 s_45 mul 3 s_14 mul 4 s_24 mul 12 s_25 ) ) mul( s- 1 s_11 s_12 s_45 ) mul( s- 1 s_11 s_15 s_24 ) mul( s- 2 s_12 s_15 s_45 ) mul( s- 2 s_14 s_15 s_25 ) mul( 2 s_12 s_14 s_25 ) mul( 2 s_12 s_15 s_24 ) mul( 2 s_12 s_24 s_25 ) mul( 2 s_15 s_25 s_45 ) mul( 4 s_12 s_14 s_15 ) ) )'\n",
      "b'mul( mul 256 pow 729 s- 1 pow e 6 pow add( m2s reg_prop s_44 mul 2 s_34 ) s- 2 pow add( m2s reg_prop s_44 mul s- 2 s_13 mul s- 2 s_14 mul 2 s_34 ) s- 2 add( mul s- 1 m4sxs_15 mul 4 m4cxs_34 mul m2c add( mul 4 pow s_34 2 mul( s- 8 s_13 s_14 ) mul( s- 2 s_15 s_34 ) mul( 2 s_34 s_35 ) mul( 2 s_34 s_44 ) mul( 2 s_34 s_45 ) mul( 4 s_13 s_44 ) ) mul m2s add( mul s_13 s_45 mul( s- 1 s_15 s_44 ) mul( s- 2 s_14 s_15 ) mul( s- 2 s_15 s_34 ) mul( 2 s_13 s_35 ) mul( 3 s_14 s_35 ) mul( 4 s_14 s_45 ) ) mul( 2 s_35 pow s_14 2 ) mul( 2 s_45 pow s_13 2 ) mul( 4 m2c m4s ) mul( 4 m2s m4c ) mul( m2c m2s add( mul s- 4 s_13 mul s- 2 s_15 mul 2 s_35 mul 2 s_45 mul 4 s_44 mul 10 s_34 ) ) mul( s_13 s_44 s_45 ) mul( s- 1 s_14 s_35 s_44 ) mul( s- 2 s_13 s_14 s_35 ) mul( s- 2 s_13 s_14 s_45 ) mul( s- 2 s_13 s_15 s_34 ) mul( s- 2 s_13 s_15 s_44 ) mul( s- 2 s_14 s_15 s_34 ) mul( 2 s_13 s_34 s_35 ) mul( 2 s_13 s_35 s_44 ) mul( 2 s_14 s_34 s_45 ) mul( 4 s_13 s_14 s_15 ) ) )'\n",
      "b'mul( mul s- 8 pow 729 s- 1 pow e 6 pow add( reg_prop s_33 mul 2 s_13 ) s- 2 pow add( m2b reg_prop s_33 s_44 mul s- 2 s_14 mul s- 2 s_34 mul 2 s_13 ) s- 2 add( mul 4 m6b mul m2b add( mul( s- 1 s_14 s_33 ) mul( s- 2 s_13 s_25 ) mul( s- 2 s_25 s_33 ) mul( 2 s_12 s_45 ) mul( 2 s_13 s_34 ) mul( 2 s_15 s_24 ) mul( 2 s_23 s_45 ) mul( 2 s_24 s_35 ) ) mul m4b add( mul s- 2 s_14 mul s- 2 s_25 mul s- 2 s_34 mul 4 s_13 mul 4 s_33 ) mul( s_12 s_33 s_45 ) mul( s_15 s_24 s_33 ) mul( s- 2 s_13 s_23 s_45 ) mul( s- 2 s_13 s_24 s_35 ) ) )'\n"
     ]
    }
   ],
   "source": [
    "for x_examples, y_examples in df_train.batch(3).take(1):\n",
    "    print(\"amplitudes:\")\n",
    "    for xx in x_examples.numpy():\n",
    "        print(xx)\n",
    "    print(\"squared amplitudes:\")\n",
    "    for yy in y_examples.numpy():\n",
    "        print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| bogoTokenizer.tokenize([\"hello world\", \"this is a test\"]): <tf.RaggedTensor [[2, 8, 4, 3], [2, 5, 7, 9, 6, 3]]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup\n",
      "<tf.RaggedTensor [[b'[START]', b'hello', b'world', b'[END]'],\n",
      " [b'[START]', b'this', b'is', b'a', b'test', b'[END]']]>\n",
      "detokenize\n",
      "tf.Tensor([b'hello world' b'this is a test'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "class BogoTokenizer(tf_text.Tokenizer, tf_text.Detokenizer):\n",
    "    \"\"\"\n",
    "    My implementation of a tf_text.Tokenizer.\n",
    "    It's actually just a wrapper around TextVectorization,\n",
    "    but so that it works for my case.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=None,\n",
    "            standardize=None, ragged=False,):\n",
    "        super(BogoTokenizer, self).__init__()\n",
    "        self.vectorizer = TextVectorization(max_tokens=max_tokens, output_mode=output_mode,\n",
    "            output_sequence_length=output_sequence_length, ragged=ragged, standardize=None)\n",
    "        self.start = \"[START]\"\n",
    "        self.end = \"[END]\"\n",
    "\n",
    "    def tokenize(self, input):\n",
    "        input_with_start_end = [self.start+\" \"+inp+\" \"+self.end for inp in input]\n",
    "        return self.vectorizer(input_with_start_end)\n",
    "\n",
    "    def encode(self, input):\n",
    "        return self.vectorizer(input)\n",
    "\n",
    "    def adapt(self, input):\n",
    "        input_with_start_end = [self.start+\" \"+inp+\" \"+self.end for inp in input]\n",
    "        self.vectorizer.adapt(input_with_start_end)\n",
    "\n",
    "    def detokenize(self, tokens):\n",
    "        vocab = tf.constant(self.vectorizer.get_vocabulary())\n",
    "        sentences = tf.gather(vocab, tokens)\n",
    "        sentences = sentences[:, 1:-1]\n",
    "        signature = tf.type_spec_from_value(tf.strings.join(sentences[0]))\n",
    "        sentences = tf.map_fn(fn=lambda s: tf.strings.join(s, separator=\" \"), elems=sentences,\n",
    "            fn_output_signature=signature)\n",
    "        return sentences\n",
    "\n",
    "    def lookup(self, tokens):\n",
    "        vocab = tf.constant(self.vectorizer.get_vocabulary())\n",
    "        return tf.gather(vocab, tokens)\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vectorizer.get_vocabulary()\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vectorizer.get_vocabulary())\n",
    "\n",
    "bogoTokenizer = BogoTokenizer(output_sequence_length=None, ragged=True)\n",
    "bogoTokenizer.adapt([\"hello world\", \"this is a test\"])\n",
    "tokens = ic(bogoTokenizer.tokenize([\"hello world\", \"this is a test\"]))\n",
    "print(\"lookup\")\n",
    "print(bogoTokenizer.lookup(tokens))\n",
    "print(\"detokenize\")\n",
    "print(bogoTokenizer.detokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod( -1/3 i e gamma %nu_92 %gam_161 %del_167 A %l_3 %nu_92 (p_3) d_u^(*) %i_3 %gam_161 (p_1) d_v %k_3 %del_167 (p_2) )'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_X = BogoTokenizer(ragged=True)\n",
    "tokenizer_y = BogoTokenizer(ragged=True)\n",
    "\n",
    "tokenizer_X.adapt(X_train_all)\n",
    "tokenizer_y.adapt(y_train_all)\n",
    "\n",
    "tokenizers = {\"X\": tokenizer_X, \"y\": tokenizer_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[28, 1, 4, 2, 1, 29]]>\n",
      "tf.Tensor([b'[UNK] Prod gamma [UNK]'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer_X.tokenize([\"banana Prod gamma banananana\"])\n",
    "print(enc)\n",
    "round_trip = tokenizer_X.detokenize(enc)\n",
    "print(round_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=array([b's_12 [UNK] gamma )'], dtype=object)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_X.detokenize([[45, 42, 1, 2, 3, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=string, numpy=\n",
       "array([[b's_24', b's_12', b'[UNK]', b'gamma', b')', b'-1/2']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_X.lookup([[45, 42, 1, 2, 3, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Prod( 1/27 i Pow e 3 Pow Sum( s_11 Prod 2 s_13 Prod -2 s_14 Prod -2 s_34 s_44 reg_prop ) -1 Pow Sum( Pow m_s 2 Prod 2 s_34 Prod -1 s_44 Prod -1 reg_prop ) -1 gamma %lambda_184 %eta_211 %eps_41 gamma %tau_161 %del_216 %eta_212 Sum( Prod m_s gamma %tau_161 %eta_210 %eta_211 Prod( p_1 %tau_164 gamma %tau_161 %eta_210 %eta_273 gamma %tau_164 %eta_273 %eta_211 ) Prod( p_2 %tau_164 gamma %tau_161 %eta_210 %eta_274 gamma %tau_164 %eta_274 %eta_211 ) Prod( -1 p_5 %tau_164 gamma %tau_161 %eta_210 %eta_275 gamma %tau_164 %eta_275 %eta_211 ) ) A^(*) %i_5 %lambda_184 (p_3) b_u^(*) %k_3 %del_216 (p_2) b_u %l_5 %eta_212 (p_5) s_u^(*) %i_3 %eta_210 (p_1) s_u %k_5 %eps_41 (p_4) )'\n",
      " b'Prod( 8/27 i Pow e 3 Pow Sum( Pow m_s 2 Prod 2 s_34 s_44 reg_prop ) -1 Pow Sum( Pow m_s 2 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 s_44 reg_prop ) -1 Sum( Prod( p_1 %lambda_388 gamma %lambda_386 %eta_650 %eta_651 gamma %lambda_388 %eta_652 %eps_136 A %k_3 %lambda_386 (p_2) c_v^(*) %i_3 %eta_650 (p_1) c_v %l_5 %eta_651 (p_5) s_u^(*) %i_5 %eta_652 (p_3) s_v %k_5 %eps_136 (p_4) ) Prod( -1/2 p_3 %sigma_172 gamma %sigma_172 %eta_708 %eta_709 gamma %lambda_386 %eta_709 %eta_658 gamma %lambda_388 %eta_657 %eta_708 gamma %lambda_388 %eta_661 %eps_138 A %k_3 %lambda_386 (p_2) c_v^(*) %i_3 %eta_657 (p_1) c_v %l_5 %eta_658 (p_5) s_u^(*) %i_5 %eta_661 (p_3) s_v %k_5 %eps_138 (p_4) ) Prod( -1/2 p_4 %sigma_172 gamma %sigma_172 %eta_710 %eta_711 gamma %lambda_386 %eta_711 %eta_663 gamma %lambda_388 %eta_662 %eta_710 gamma %lambda_388 %eta_666 %eps_139 A %k_3 %lambda_386 (p_2) c_v^(*) %i_3 %eta_662 (p_1) c_v %l_5 %eta_663 (p_5) s_u^(*) %i_5 %eta_666 (p_3) s_v %k_5 %eps_139 (p_4) ) ) )'\n",
      " b'Prod( -1/27 i Pow e 3 Pow Sum( Pow m_b 2 Prod 2 s_13 Prod -2 s_14 s_33 Prod -2 s_34 s_44 reg_prop ) -1 Pow Sum( s_13 Prod 1/2 s_33 Prod 1/2 reg_prop ) -1 Sum Prod( p_1 %tau_546 gamma %tau_549 %gam_746 %eps_43 gamma %tau_549 %del_738 %eta_379 A^(*) %l_3 %tau_546 (p_3) b_u^(*) %i_3 %gam_746 (p_1) b_u^(*) %k_3 %del_738 (p_2) b_u %j_5 %eps_43 (p_4) b_u %k_5 %eta_379 (p_5) ) Prod( 1/2 p_3 %nu_200 gamma %nu_200 %gam_772 %gam_773 gamma %tau_546 %gam_749 %gam_772 gamma %tau_549 %gam_773 %eps_45 gamma %tau_549 %del_740 %eta_381 A^(*) %l_3 %tau_546 (p_3) b_u^(*) %i_3 %gam_749 (p_1) b_u^(*) %k_3 %del_740 (p_2) b_u %j_5 %eps_45 (p_4) b_u %k_5 %eta_381 (p_5) ) )'], shape=(3,), dtype=string)\n",
      "encoded batch:\n",
      "[28, 7, 127, 26, 5, 27, 30, 5, 16, 38, 4, 15, 34, 4, 23, 41, 4, 23, 39, 43, 20, 3, 6, 5, 16, 5, 91, 15, 4, 15, 39, 4, 6, 43, 4, 6, 20, 3, 6, 2, 95, 362, 103, 2, 282, 381, 482, 16, 4, 91, 2, 282, 1, 362, 7, 33, 326, 2, 282, 1, 443, 2, 326, 443, 362, 3, 7, 35, 326, 2, 282, 1, 409, 2, 326, 409, 362, 3, 7, 6, 83, 326, 2, 282, 1, 254, 2, 326, 254, 362, 3, 3, 22, 19, 95, 8, 58, 11, 381, 9, 71, 25, 482, 14, 66, 12, 1, 10, 67, 18, 103, 13, 3, 29]\n",
      "[28, 7, 200, 26, 5, 27, 30, 5, 16, 5, 91, 15, 4, 15, 39, 43, 20, 3, 6, 5, 16, 5, 91, 15, 4, 23, 34, 4, 23, 41, 4, 15, 39, 43, 20, 3, 6, 16, 7, 33, 1, 2, 1, 1, 1, 2, 1, 1, 1, 21, 11, 1, 9, 70, 12, 1, 10, 60, 25, 1, 14, 66, 19, 1, 8, 80, 18, 1, 13, 3, 7, 46, 36, 278, 2, 278, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 253, 21, 11, 1, 9, 70, 12, 1, 10, 60, 25, 1, 14, 66, 19, 1, 8, 80, 18, 253, 13, 3, 7, 46, 32, 278, 2, 278, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 187, 21, 11, 1, 9, 70, 12, 1, 10, 60, 25, 1, 14, 66, 19, 1, 8, 80, 18, 187, 13, 3, 3, 3, 29]\n",
      "[28, 7, 131, 26, 5, 27, 30, 5, 16, 5, 94, 15, 4, 15, 34, 4, 23, 41, 37, 4, 23, 39, 43, 20, 3, 6, 5, 16, 34, 4, 31, 37, 4, 31, 20, 3, 6, 84, 7, 33, 1, 2, 1, 1, 110, 2, 1, 1, 1, 22, 24, 1, 8, 58, 12, 1, 10, 58, 11, 1, 9, 71, 17, 110, 13, 71, 18, 1, 14, 3, 7, 31, 36, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 104, 2, 1, 1, 1, 22, 24, 1, 8, 58, 12, 1, 10, 58, 11, 1, 9, 71, 17, 104, 13, 71, 18, 1, 14, 3, 3, 29]\n",
      "tf.Tensor(\n",
      "[b'Prod( 1/27 i Pow e 3 Pow Sum( s_11 Prod 2 s_13 Prod -2 s_14 Prod -2 s_34 s_44 reg_prop ) -1 Pow Sum( Pow m_s 2 Prod 2 s_34 Prod -1 s_44 Prod -1 reg_prop ) -1 gamma %lambda_184 %eta_211 %eps_41 gamma %tau_161 %del_216 %eta_212 Sum( Prod m_s gamma %tau_161 [UNK] %eta_211 Prod( p_1 %tau_164 gamma %tau_161 [UNK] %eta_273 gamma %tau_164 %eta_273 %eta_211 ) Prod( p_2 %tau_164 gamma %tau_161 [UNK] %eta_274 gamma %tau_164 %eta_274 %eta_211 ) Prod( -1 p_5 %tau_164 gamma %tau_161 [UNK] %eta_275 gamma %tau_164 %eta_275 %eta_211 ) ) A^(*) %i_5 %lambda_184 (p_3) b_u^(*) %k_3 %del_216 (p_2) b_u %l_5 %eta_212 (p_5) s_u^(*) %i_3 [UNK] (p_1) s_u %k_5 %eps_41 (p_4) )'\n",
      " b'Prod( 8/27 i Pow e 3 Pow Sum( Pow m_s 2 Prod 2 s_34 s_44 reg_prop ) -1 Pow Sum( Pow m_s 2 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 s_44 reg_prop ) -1 Sum( Prod( p_1 [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] [UNK] A %k_3 [UNK] (p_2) c_v^(*) %i_3 [UNK] (p_1) c_v %l_5 [UNK] (p_5) s_u^(*) %i_5 [UNK] (p_3) s_v %k_5 [UNK] (p_4) ) Prod( -1/2 p_3 %sigma_172 gamma %sigma_172 [UNK] [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] %eps_138 A %k_3 [UNK] (p_2) c_v^(*) %i_3 [UNK] (p_1) c_v %l_5 [UNK] (p_5) s_u^(*) %i_5 [UNK] (p_3) s_v %k_5 %eps_138 (p_4) ) Prod( -1/2 p_4 %sigma_172 gamma %sigma_172 [UNK] [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] %eps_139 A %k_3 [UNK] (p_2) c_v^(*) %i_3 [UNK] (p_1) c_v %l_5 [UNK] (p_5) s_u^(*) %i_5 [UNK] (p_3) s_v %k_5 %eps_139 (p_4) ) ) )'\n",
      " b'Prod( -1/27 i Pow e 3 Pow Sum( Pow m_b 2 Prod 2 s_13 Prod -2 s_14 s_33 Prod -2 s_34 s_44 reg_prop ) -1 Pow Sum( s_13 Prod 1/2 s_33 Prod 1/2 reg_prop ) -1 Sum Prod( p_1 [UNK] gamma [UNK] [UNK] %eps_43 gamma [UNK] [UNK] [UNK] A^(*) %l_3 [UNK] (p_3) b_u^(*) %i_3 [UNK] (p_1) b_u^(*) %k_3 [UNK] (p_2) b_u %j_5 %eps_43 (p_4) b_u %k_5 [UNK] (p_5) ) Prod( 1/2 p_3 [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] [UNK] gamma [UNK] [UNK] %eps_45 gamma [UNK] [UNK] [UNK] A^(*) %l_3 [UNK] (p_3) b_u^(*) %i_3 [UNK] (p_1) b_u^(*) %k_3 [UNK] (p_2) b_u %j_5 %eps_45 (p_4) b_u %k_5 [UNK] (p_5) ) )'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(x_examples)\n",
    "encoded = tokenizer_X.tokenize(x_examples)\n",
    "print(\"encoded batch:\")\n",
    "for row in encoded.to_list():\n",
    "    print(row)\n",
    "\n",
    "round_trip = tokenizer_X.detokenize(encoded)\n",
    "print(round_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=350\n",
    "def prepare_batch(X, y):\n",
    "    X = tokenizers[\"X\"].encode(X)      # Output is ragged.\n",
    "    X = X[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    X = X.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    y = tokenizers[\"y\"].encode(y)\n",
    "    y = y[:, :(MAX_TOKENS+1)]\n",
    "    y_inputs = y[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    y_labels = y[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (X, y_inputs), y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches(df_train)\n",
    "val_batches = make_batches(df_val)\n",
    "test_batches = make_batches(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None)), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 281)\n",
      "(32, 345)\n",
      "(32, 345)\n"
     ]
    }
   ],
   "source": [
    "for (xx, yy), yy_labels in train_batches.take(1):\n",
    "    print(xx.shape)\n",
    "    print(yy.shape)\n",
    "    print(yy_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 7 26  5 27 30  5 16 37  4 23], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 3 51 13 29 28 13 16 25 22 19], shape=(10,), dtype=int64)\n",
      "tf.Tensor([51 13 29 28 13 16 25 22 19  6], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(xx[0][:10])\n",
    "print(yy[0][:10])\n",
    "print(yy_labels[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  \"\"\"embedding + positional encoding\"\"\"\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_X = PositionalEmbedding(vocab_size=tokenizers[\"X\"].get_vocab_size(), d_model=512)\n",
    "embed_y = PositionalEmbedding(vocab_size=tokenizers[\"y\"].get_vocab_size(), d_model=512)\n",
    "\n",
    "X_emb = embed_X(xx)\n",
    "y_emb = embed_X(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 281), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 7, 26,  5, 27, 30])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 512), dtype=float32, numpy=\n",
       "array([[-0.13546064,  0.69598347, -0.28972754, ...,  1.1727179 ,\n",
       "         1.0892569 ,  0.6714809 ],\n",
       "       [ 1.7553012 ,  0.77115774,  1.9187546 , ...,  0.8091723 ,\n",
       "         0.01575792,  1.4015987 ],\n",
       "       [ 0.5122517 ,  1.6046032 ,  1.6691855 , ...,  1.4501709 ,\n",
       "         0.8326774 ,  2.0348377 ],\n",
       "       [ 0.68419015,  0.61280715, -0.753955  , ...,  1.3192405 ,\n",
       "         1.3271487 ,  0.04875952],\n",
       "       [ 0.2567833 , -0.5721197 , -0.5291657 , ...,  0.985366  ,\n",
       "         0.4667887 ,  0.9598986 ]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.015757918>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0][1][-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the actual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 281, 512)\n",
      "(32, 345, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 17:34:52.061197: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 281, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 17:34:52.626417: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    }
   ],
   "source": [
    "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(X_emb.shape)\n",
    "print(y_emb.shape)\n",
    "print(sample_ca(X_emb, y_emb).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 281, 512)\n",
      "(32, 281, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(X_emb.shape)\n",
    "print(sample_gsa(X_emb).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers[\"X\"].get_vocab_size(),\n",
    "    target_vocab_size=tokenizers[\"y\"].get_vocab_size(),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512, 230)\n"
     ]
    }
   ],
   "source": [
    "print(transformer((X_emb[0][0:10], y_emb[0][0:10]), training=False).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 281, 512])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  2702848   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  4779264   \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  29670     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,511,782\n",
      "Trainable params: 7,511,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='saved_models/2022-12-01-ahp-sqahp-checkpoint.h5',\n",
    "        save_weights_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        ),\n",
    "    tf.keras.callbacks.CSVLogger('csv_logs/2022-12-01-ahp-sqahp.csv', separator=\",\", append=False),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='tensorboard_logs/2022-12-01-ahp-sqahp/'),\n",
    "    tf.keras.callbacks.BackupAndRestore(\n",
    "        'training_backup/2022-12-01-ahp-sqahp_backup/', save_freq=\"epoch\", delete_checkpoint=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=10,\n",
    "                validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-11-09-Transformer_2to2.index',\n",
       " '2022-11-09-Transformer_2to2.data-00000-of-00001',\n",
       " '2022-11-14-Transformer_upto3to3_unique_augmented.index',\n",
       " '2022-11-09-Transformer_all_except_3to3.data-00000-of-00001',\n",
       " '2022-11-09-Transformer_all_except_3to3.index',\n",
       " '2022-11-14-Transformer_upto3to3_unique_augmented.data-00000-of-00001',\n",
       " 'checkpoint']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"models/2022-12-01-ahp-sqahp_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers[\"X\"].tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = self.tokenizers[\"y\"].tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    text = tokenizers[\"y\"].detokenize(output)[0]  # Shape: `()`.\n",
    "\n",
    "    tokens = tokenizers[\"y\"].lookup(output)[0]\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(tokenizers, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod 2/3 Prod i Prod e Prod gamma alpha_2 alpha_0 alpha_1 Prod A^(*) i_2 alpha_2 (p_3) Prod tt i_0 alpha_1 (p_1)_u tt^(*) i_1 alpha_0 (p_2)_u'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = X_test_final[0][0]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = tf.constant(sentence)[tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 2, 133, 2, 43, 2, 44, 2, 3, 18, 20, 19, 2, 34, 10, 18, 40, 2, 90,\n",
       "  12, 19, 31, 89, 11, 20, 72, 46]]>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers[\"X\"].tokenize(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 46]]>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers[\"X\"].tokenize([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'e 4 e e 4 s_23 e 4 s_23 s_23 e 4 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s- 2 s_23 s_24 s- 2 s_23 pow m_tt 2 mul s- 2 pow m_tt 2 mul s- 2 pow s_23 2 mul 2 pow m_tt 2 mul 2 mul s_13 pow m_tt 2 add mul s- 1 mul s_23 pow m_tt 2 mul s- 2 mul s_24 pow m_tt 2 add mul s- 2 mul s_34 pow m_tt 2 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_14 mul s_24 s_34 add mul s- 2 mul s_12 mul 2 mul s_13 mul s_23 pow m_tt 2 add mul s- 2 mul s_14 mul s_23 pow m_tt 2 add mul s- 2 mul s_24 mul s_34 pow m_tt 2 add mul 2 mul s_12 mul s_13 pow m_tt 2 add mul 4 mul s_13 mul s_24 pow m_tt 2 add mul 4 mul s_23 mul s_24 pow m_tt 2 mul s- 2 mul s_12 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s- 2 mul s_23 mul pow m_tt 2 pow m_tt 2 mul s- 2 mul s_14 mul s_24 s_34 mul 2 mul s_13 mul s_23 pow m_tt 2 add mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul 2 mul s_23 mul s_24 pow m_tt 2 add mul 4 mul s_24 mul pow m_tt 2 mul 8 mul s_13 mul s_24 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 add mul s- 2 mul s_23 mul s_24 pow m_tt 2 mul mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul mul mul s_24 mul pow m_tt 2 mul mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul mul'>,\n",
       " <tf.Tensor: shape=(351,), dtype=string, numpy=\n",
       " array([b'[START]', b'e', b'4', b'e', b'e', b'4', b's_23', b'e', b'4',\n",
       "        b's_23', b's_23', b'e', b'4', b's_23', b's_23', b's_23', b's_23',\n",
       "        b's_23', b's_23', b's_23', b's_23', b's_23', b's-', b'2', b's_23',\n",
       "        b's_24', b's-', b'2', b's_23', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'pow', b'm_tt', b'2', b'mul', b's-', b'2', b'pow',\n",
       "        b's_23', b'2', b'mul', b'2', b'pow', b'm_tt', b'2', b'mul', b'2',\n",
       "        b'mul', b's_13', b'pow', b'm_tt', b'2', b'add', b'mul', b's-',\n",
       "        b'1', b'mul', b's_23', b'pow', b'm_tt', b'2', b'mul', b's-', b'2',\n",
       "        b'mul', b's_24', b'pow', b'm_tt', b'2', b'add', b'mul', b's-',\n",
       "        b'2', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add', b'mul',\n",
       "        b's-', b'2', b'mul', b's_12', b'pow', b'm_tt', b'4', b'add',\n",
       "        b'mul', b's-', b'2', b'mul', b's_12', b'pow', b'm_tt', b'4',\n",
       "        b'add', b'mul', b's-', b'2', b'mul', b's_12', b'pow', b'm_tt',\n",
       "        b'4', b'add', b'mul', b's-', b'2', b'mul', b's_14', b'mul',\n",
       "        b's_24', b's_34', b'add', b'mul', b's-', b'2', b'mul', b's_12',\n",
       "        b'mul', b'2', b'mul', b's_13', b'mul', b's_23', b'pow', b'm_tt',\n",
       "        b'2', b'add', b'mul', b's-', b'2', b'mul', b's_14', b'mul',\n",
       "        b's_23', b'pow', b'm_tt', b'2', b'add', b'mul', b's-', b'2',\n",
       "        b'mul', b's_24', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add',\n",
       "        b'mul', b'2', b'mul', b's_12', b'mul', b's_13', b'pow', b'm_tt',\n",
       "        b'2', b'add', b'mul', b'4', b'mul', b's_13', b'mul', b's_24',\n",
       "        b'pow', b'm_tt', b'2', b'add', b'mul', b'4', b'mul', b's_23',\n",
       "        b'mul', b's_24', b'pow', b'm_tt', b'2', b'mul', b's-', b'2',\n",
       "        b'mul', b's_12', b'mul', b's_34', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'mul', b's_23', b'mul', b's-', b'2', b'mul', b's_23',\n",
       "        b'mul', b'pow', b'm_tt', b'2', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'mul', b's_14', b'mul', b's_24', b's_34', b'mul',\n",
       "        b'2', b'mul', b's_13', b'mul', b's_23', b'pow', b'm_tt', b'2',\n",
       "        b'add', b'mul', b's-', b'2', b'mul', b's_23', b'mul', b's_34',\n",
       "        b'pow', b'm_tt', b'2', b'mul', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_24', b'pow', b'm_tt', b'2', b'add', b'mul', b'4', b'mul',\n",
       "        b's_24', b'mul', b'pow', b'm_tt', b'2', b'mul', b'8', b'mul',\n",
       "        b's_13', b'mul', b's_24', b'pow', b'm_tt', b'2', b'mul', b's-',\n",
       "        b'2', b'mul', b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2',\n",
       "        b'mul', b's-', b'2', b'mul', b's_23', b'mul', b's_34', b'pow',\n",
       "        b'm_tt', b'2', b'mul', b's-', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_34', b'pow', b'm_tt', b'2', b'mul', b's-', b'2', b'mul',\n",
       "        b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add', b'mul',\n",
       "        b's-', b'2', b'mul', b's_23', b'mul', b's_24', b'pow', b'm_tt',\n",
       "        b'2', b'mul', b'mul', b's-', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_34', b'pow', b'm_tt', b'2', b'mul', b'mul', b'mul', b's_24',\n",
       "        b'mul', b'pow', b'm_tt', b'2', b'mul', b'mul', b's-', b'2', b'mul',\n",
       "        b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2', b'mul', b'mul',\n",
       "        b'mul'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1, 8, 350, 27), dtype=float32, numpy=\n",
       " array([[[[0.00609642, 0.15153041, 0.00274909, ..., 0.00150047,\n",
       "           0.00264707, 0.00269867],\n",
       "          [0.0052967 , 0.15357839, 0.00263177, ..., 0.00150018,\n",
       "           0.0025359 , 0.00258117],\n",
       "          [0.00583117, 0.15227929, 0.00294052, ..., 0.00172064,\n",
       "           0.00283237, 0.00288254],\n",
       "          ...,\n",
       "          [0.00071198, 0.16413519, 0.0008504 , ..., 0.00032842,\n",
       "           0.0008713 , 0.00086429],\n",
       "          [0.00367211, 0.15637067, 0.00249051, ..., 0.00096584,\n",
       "           0.00251631, 0.00252367],\n",
       "          [0.00371149, 0.15633078, 0.00247816, ..., 0.00087514,\n",
       "           0.00250369, 0.00251316]],\n",
       " \n",
       "         [[0.01689322, 0.04564391, 0.01104816, ..., 0.01507656,\n",
       "           0.01080301, 0.01081656],\n",
       "          [0.01653329, 0.0433283 , 0.01073942, ..., 0.01477481,\n",
       "           0.01052687, 0.01050784],\n",
       "          [0.01472505, 0.04195366, 0.00932383, ..., 0.01332293,\n",
       "           0.00910951, 0.00910464],\n",
       "          ...,\n",
       "          [0.02407413, 0.07379293, 0.02735358, ..., 0.02006663,\n",
       "           0.02821435, 0.02769257],\n",
       "          [0.03513052, 0.06600828, 0.02997538, ..., 0.02389245,\n",
       "           0.03023542, 0.03009939],\n",
       "          [0.03540717, 0.0706565 , 0.02732649, ..., 0.02055297,\n",
       "           0.02740923, 0.02735479]],\n",
       " \n",
       "         [[0.03156018, 0.03908681, 0.04538356, ..., 0.02548607,\n",
       "           0.04657719, 0.04594937],\n",
       "          [0.03203427, 0.04030607, 0.04423797, ..., 0.02376057,\n",
       "           0.04535729, 0.04479996],\n",
       "          [0.03138492, 0.04089653, 0.04405596, ..., 0.02368526,\n",
       "           0.04533069, 0.04470651],\n",
       "          ...,\n",
       "          [0.00200637, 0.15030089, 0.00340025, ..., 0.00345178,\n",
       "           0.00361168, 0.00348481],\n",
       "          [0.00241347, 0.14895354, 0.00466538, ..., 0.00517503,\n",
       "           0.00494219, 0.00476482],\n",
       "          [0.00305121, 0.14478232, 0.0066317 , ..., 0.00660914,\n",
       "           0.0070062 , 0.00676694]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.02800317, 0.06161228, 0.03855311, ..., 0.00879904,\n",
       "           0.04001163, 0.03925679],\n",
       "          [0.02902667, 0.0549776 , 0.04152768, ..., 0.00959343,\n",
       "           0.04312503, 0.04227211],\n",
       "          [0.02846494, 0.05563181, 0.04138827, ..., 0.00941592,\n",
       "           0.04301919, 0.04215685],\n",
       "          ...,\n",
       "          [0.0305258 , 0.10159979, 0.0169348 , ..., 0.01563822,\n",
       "           0.01658178, 0.01664403],\n",
       "          [0.03337456, 0.08090247, 0.02553204, ..., 0.01159193,\n",
       "           0.02564672, 0.02551835],\n",
       "          [0.03171662, 0.08374719, 0.02504459, ..., 0.01158537,\n",
       "           0.02522526, 0.02504516]],\n",
       " \n",
       "         [[0.0065423 , 0.12380715, 0.01084948, ..., 0.00715502,\n",
       "           0.0112474 , 0.01110107],\n",
       "          [0.00600183, 0.12429012, 0.01007851, ..., 0.00755378,\n",
       "           0.01041984, 0.0102808 ],\n",
       "          [0.00637528, 0.12283031, 0.0103468 , ..., 0.00792537,\n",
       "           0.01067144, 0.01053841],\n",
       "          ...,\n",
       "          [0.01100498, 0.11200484, 0.01588698, ..., 0.0079219 ,\n",
       "           0.01651807, 0.01633325],\n",
       "          [0.01936618, 0.04839056, 0.04065802, ..., 0.01538224,\n",
       "           0.04371664, 0.04267323],\n",
       "          [0.01987411, 0.0563297 , 0.03739638, ..., 0.01594159,\n",
       "           0.03978336, 0.03898437]],\n",
       " \n",
       "         [[0.00026868, 0.16225778, 0.00019936, ..., 0.0004288 ,\n",
       "           0.00019345, 0.00019469],\n",
       "          [0.00026069, 0.1609932 , 0.00018337, ..., 0.00043292,\n",
       "           0.00017718, 0.00017845],\n",
       "          [0.00032167, 0.16078234, 0.00022718, ..., 0.00052802,\n",
       "           0.00021978, 0.00022131],\n",
       "          ...,\n",
       "          [0.0003283 , 0.15093873, 0.00021811, ..., 0.00044357,\n",
       "           0.00021063, 0.00021226],\n",
       "          [0.00031746, 0.16498904, 0.00025356, ..., 0.00054208,\n",
       "           0.0002442 , 0.00024628],\n",
       "          [0.00041486, 0.16426212, 0.00035574, ..., 0.00073811,\n",
       "           0.00034445, 0.00034644]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(tf.constant(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod 2/3 Prod i Prod e Prod gamma alpha_2 alpha_0 alpha_1 Prod A^(*) i_2 alpha_2 (p_3) Prod tt i_0 alpha_1 (p_1)_u tt^(*) i_1 alpha_0 (p_2)_u'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4adc2ea131058d4ca334736eaf83f8a99f586a60b7e02773f5921bb39d3dbeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

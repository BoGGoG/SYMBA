{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model QED\n",
    "This is the base setup for working on QED data.\n",
    "It shows how to import the data and how to convert the expressions into different formats.\n",
    "\n",
    "amplitdues: prefix  \n",
    "squared amplitdues: hybrid prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:17:39.002076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 12:17:39.085240: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-22 12:17:39.103028: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-22 12:17:39.500383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-11-22 12:17:39.500427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-11-22 12:17:39.500430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "import sympy as sp\n",
    "from itertools import (takewhile,repeat)\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:17:40.195810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:17:40.199292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:17:40.199400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocessing.tree.sympy_to_tree as sp2tree\n",
    "from data_preprocessing.sympy_prefix.source.SympyPrefix import prefix_to_sympy, sympy_to_prefix, sympy_to_hybrid_prefix, hybrid_prefix_to_sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This only needs to be run unce, then the data is cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_i(expr_str):\n",
    "    reg_ex = \"[^a-z]i[^a-z,^\\d]\"\n",
    "    replaced = re.sub(reg_ex, fix_i_match, expr_str)\n",
    "    return replaced\n",
    "    \n",
    "def fix_i_match(matchobj):\n",
    "    \"\"\"\n",
    "    i --> I\n",
    "    \"\"\"\n",
    "    match = matchobj.group(0)\n",
    "    return match.replace(\"i\", \"I\")\n",
    "\n",
    "\n",
    "def rawincount(filename):\n",
    "    \"\"\"count numer of lines in a file. \n",
    "    From https://stackoverflow.com/questions/845058/how-to-get-line-count-of-a-large-file-cheaply-in-python\n",
    "    \"\"\"\n",
    "    f = open(filename, 'rb')\n",
    "    bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))\n",
    "    return sum( buf.count(b'\\n') for buf in bufgen )\n",
    "\n",
    "def load_raw_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading raw amplitudes from filename.\n",
    "    \n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "    \"\"\"\n",
    "    print(\"Loading amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        ctr = 0\n",
    "        data[ctr] = line.replace(\"\\n\", \"\")\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                data[ctr] = line.replace(\"\\n\", \"\")\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_squared_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading squared amplitudes from filename and parsing into sympy.\n",
    "    All squared amplitudes should be exportet from sympy and thus be readable\n",
    "    without any preprocessing.\n",
    "\n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "\n",
    "    Returns:\n",
    "        list of squared amplitudes, each as a sympy expression\n",
    "    \"\"\"\n",
    "    print(\"Loading squared amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "       line = f.readline()\n",
    "       line_sp = sp.sympify(line.strip())\n",
    "       ctr = 0\n",
    "       data[ctr] = line_sp\n",
    "       while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                line = line.strip()\n",
    "                line = fix_i(line)\n",
    "                line_sp = sp.sympify(line.strip())\n",
    "                data[ctr] = line_sp\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_1to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9905d8df3275426f9a2b010dd97fd5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_1to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f5d440077e47d989b33737a16d6194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_2to1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f761364f7b4f4ecaa68e90f493bd4161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_2to1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc4384a0b25413db0b581634edaf59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_2to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fd67fd3eea40f7b25518b482cf3aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_2to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd86b2cc8624756a0701dc8fd04e3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_2to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2348c0ca7f434b9b6a15e078f6a94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_2to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5925aec46594a06b67b5b4d967d0542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_3to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d223f3e1490b49d5af79685af178c60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_3to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794ec43c5de4440a95ec6fbeb4cb3836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_folder = \"../raw_data.nosync/\"\n",
    "amplitudes_filename_start = \"QED_amplitudes_TreeLevel_\"\n",
    "sqamplitudes_filename_start = \"QED_sqamplitudes_TreeLevel_\"\n",
    "processes = [\"1to2\", \"2to1\", \"2to2\", \"2to3\", \"3to2\"]\n",
    "max_lines = -1\n",
    "\n",
    "amplitudes = []\n",
    "sqamplitudes = []\n",
    "for process in processes:\n",
    "    ampl_f = data_folder + amplitudes_filename_start + process + \".txt\"\n",
    "    sqampl_f = data_folder + sqamplitudes_filename_start + process + \".txt\"\n",
    "    amplitudes_process = load_raw_amplitudes(ampl_f, max_lines=max_lines)\n",
    "    sqamplitudes_process = load_squared_amplitudes(sqampl_f, max_lines=max_lines)\n",
    "    amplitudes.append(amplitudes_process)\n",
    "    sqamplitudes.append(sqamplitudes_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the different amplitudes separated for now, so `amplitudes` has the form\n",
    "`[multiplicity, i]` where `multiplicity = [\"1to2\", \"2to1\", ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "431\n",
      "431\n",
      "431\n",
      "431\n",
      "10943\n",
      "10943\n",
      "129023\n",
      "129023\n",
      "129023\n",
      "129023\n"
     ]
    }
   ],
   "source": [
    "# the amplitudes are in prefix format\n",
    "print(len(amplitudes))\n",
    "print(len(sqamplitudes))\n",
    "print(len(amplitudes[0]))\n",
    "print(len(sqamplitudes[0]))\n",
    "print(len(amplitudes[1]))\n",
    "print(len(sqamplitudes[1]))\n",
    "print(len(amplitudes[2]))\n",
    "print(len(sqamplitudes[2]))\n",
    "print(len(amplitudes[3]))\n",
    "print(len(sqamplitudes[3]))\n",
    "print(len(amplitudes[4]))\n",
    "print(len(sqamplitudes[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod,-1,Prod,i,Prod,e,Prod,gamma,alpha_2,alpha_0,alpha_1,Prod,A^(*),i_2,alpha_2,(p_3),Prod,mu,i_0,alpha_1,(p_1)_u,mu^(*),i_1,alpha_0,(p_2)_u'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 4 e^{2} \\cdot \\left(2 m_{\\mu}^{2} - s_{12}\\right)$"
      ],
      "text/plain": [
       "-4*e**2*(2*m_mu**2 - s_12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqamplitudes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only unique amplitudes\n",
    "We only want unique amplitudes, others are thrown away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices(amps):\n",
    "    amps = [\" \".join(a) for a in amps]\n",
    "    tmp = np.sort(np.unique(amps, return_index=True, axis=0)[1])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices = [get_unique_indices(a) for a in amplitudes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_unique_a = [[amplitudes[j][ind] for ind in unique_indices[j]] for j in range(len(amplitudes))]\n",
    "sqamplitudes_corresponding_a = [[sqamplitudes[j][ind] for ind in unique_indices[j]] for j in range(len(amplitudes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes.pickle\", \"bw\") as f:\n",
    "    pickle.dump(amplitudes_unique_a, f)\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"bw\") as f:\n",
    "    pickle.dump(sqamplitudes_corresponding_a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Format Conversion\n",
    "We need to convert the squared amplitudes, which are sympy expressions now, into something. In this notebook we will use the prefix notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes.pickle\", \"rb\") as f:\n",
    "    amplitudes_unique = pickle.load(f)\n",
    "    amplitudes_unique = [[a.split(\",\") for a in amps] for amps in amplitudes_unique]\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"rb\") as f:\n",
    "    sqamplitudes_corresponding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba4f1b8dae04a82a43554b1654d3bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f70e6d3248e4129b342600e37df8720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d3bdf177584da7879eaca6ceb5cd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d605a551e1e483398181de1a05ccd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137d80342485422295eb7f3061c44cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_mu', '2', ')'], dtype='<U4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_hybrid_prefix(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sympy_to_hybrid_prefix(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_prefix = [[try_sympy_to_hybrid_prefix(a) for a in tqdm(sq)] for sq in sqamplitudes_corresponding]\n",
    "np.array(sqampl_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"sqamplitudes_hybrid_prefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(sqampl_prefix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"sqamplitudes_prefix.pickle\", \"br\") as f:\n",
    "    sqampl_prefix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mul(',\n",
       " 's-',\n",
       " '4',\n",
       " 'pow',\n",
       " 'e',\n",
       " '2',\n",
       " 'add',\n",
       " 'mul',\n",
       " 's-',\n",
       " '1',\n",
       " 's_12',\n",
       " 'mul',\n",
       " '2',\n",
       " 'pow',\n",
       " 'm_mu',\n",
       " '2',\n",
       " ')']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqampl_prefix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "54\n",
      "54\n",
      "54\n",
      "2988\n",
      "2988\n",
      "58332\n",
      "58332\n",
      "58361\n",
      "58361\n"
     ]
    }
   ],
   "source": [
    "print(len(amplitudes_unique[0]))\n",
    "print(len(sqampl_prefix[0]))\n",
    "print(len(amplitudes_unique[1]))\n",
    "print(len(sqampl_prefix[1]))\n",
    "print(len(amplitudes_unique[2]))\n",
    "print(len(sqampl_prefix[2]))\n",
    "print(len(amplitudes_unique[3]))\n",
    "print(len(sqampl_prefix[3]))\n",
    "print(len(amplitudes_unique[4]))\n",
    "print(len(sqampl_prefix[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampls_lengths = [[len(a) for a in ampls] for ampls in amplitudes_unique]\n",
    "sqampls_lengths = [[len(a) for a in sqampls] for sqampls in sqampl_prefix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ampls_lengths, bins=100,);\n",
    "plt.xlabel(\"amplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAglklEQVR4nO3df7hVdZn38fdH8AdqGOSBCwEFexgBbTI5EY1llpXYL2zKCZsCZ5xIo8x8Zp7gca4Z63m4HrMf01CBUTYeS2Xoh0k2lgzpWInikVBAJEgUTzDAOKmoSYL388f67lgcNuesszj77L3h87qude217r3W2vdeHM591vqu9f0qIjAzMyvjsHonYGZmzctFxMzMSnMRMTOz0lxEzMysNBcRMzMrrX+9E6iV448/PkaNGlXvNMzMmsoDDzzwXxHRUnT9g7aIjBo1ivb29nqnYWbWVCQ93pP1fTnLzMxKcxExM7PSXETMzKy0mhYRSZ+StEbSakk3SzpK0mBJSyStT6+DcuvPlrRB0jpJ5+biEyStSu/NlaRa5m1mZsXUrIhIGg5cBrRGxGlAP2AqMAtYGhFjgKVpGUnj0/unApOBeZL6pd3NB2YAY9I0uVZ5m5lZcbW+nNUfGCCpP3A0sBmYArSl99uA89P8FGBhROyMiI3ABmCipGHAwIhYFllvkTfktjEzszqqWRGJiN8CXwA2AVuApyPiDmBoRGxJ62wBhqRNhgNP5HbRkWLD03zn+D4kzZDULql9+/btvfl1zMysilpezhpEdnYxGjgBOEbSh7rapEosuojvG4xYEBGtEdHa0lL4WRkzMyuplpez3gpsjIjtEfEi8APgz4Ct6RIV6XVbWr8DGJnbfgTZ5a+ONN85bmZmdVbLIrIJmCTp6HQ31TnAWmAxMD2tMx24Nc0vBqZKOlLSaLIG9OXpktcOSZPSfqbltrGC1o4dV+8UzOwgVLNuTyLiPknfA1YAu4BfAQuAY4FFki4mKzQXpPXXSFoEPJzWnxkRu9PuLgWuBwYAt6fJzMzqTAfr8Litra3hvrP2WDt2HOMeWVvvNMyswUl6ICJai67vJ9bNzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrLSaFRFJp0hamZuekXS5pMGSlkhan14H5baZLWmDpHWSzs3FJ0hald6bm8Zat254XHUzq7WaFZGIWBcRp0fE6cAE4HngFmAWsDQixgBL0zKSxgNTgVOBycA8Sf3S7uYDM4AxaZpcq7zNzKy4vrqcdQ7wm4h4HJgCtKV4G3B+mp8CLIyInRGxEdgATJQ0DBgYEcsiGxD+htw2ZmZWR31VRKYCN6f5oRGxBSC9Dknx4cATuW06Umx4mu8c34ekGZLaJbVv3769F9M3M7Nqal5EJB0BvAf4bnerVolFF/F9gxELIqI1IlpbWlp6lqiZmfVYX5yJnAesiIitaXlrukRFet2W4h3AyNx2I4DNKT6iStzMzOqsL4rIhey5lAWwGJie5qcDt+biUyUdKWk0WQP68nTJa4ekSemurGm5bczMrI7613Lnko4G3gZ8NBe+Glgk6WJgE3ABQESskbQIeBjYBcyMiN1pm0uB64EBwO1pMjOzOqtpEYmI54FXdIo9SXa3VrX15wBzqsTbgdNqkaOZmZXnJ9bNzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzErrURGRdJikgbVKxszMmku3RUTSTZIGSjqGbNTBdZL+rvapmZlZoytyJjI+Ip4Bzgf+DTgR+HCRnUt6uaTvSXpE0lpJr5c0WNISSevT66Dc+rMlbZC0TtK5ufgESavSe3PTWOtmZlZnRYrI4ZIOJysit0bEi0AU3P8/Az+JiLHAq4G1wCxgaUSMAZamZSSNB6YCpwKTgXmS+qX9zAdmAGPSNLng55uZWQ0VKSJfBx4DjgHulnQS8Ex3G6W2k7OA6wAi4g8R8RQwBWhLq7WRFSdSfGFE7IyIjcAGYKKkYcDAiFgWEQHckNvGzMzqqNsiEhFzI2J4RLwjMo8Dby6w75OB7cC/SPqVpG+mdpWhEbEl7XsLMCStPxx4Ird9R4oNT/Od42ZmVmdFGtaHSrpO0u1peTwwvcC++wNnAPMj4jXAc6RLV/v7qCqx6CJeLdcZktoltW/fvr1AimZmdiCKXM66HvgpcEJa/jVweYHtOoCOiLgvLX+PrKhsTZeoSK/bcuuPzG0/Atic4iOqxPcREQsiojUiWltaWgqkaGZmB6JIETk+IhYBLwFExC5gd3cbRcR/Ak9IOiWFziG7RXgxe85kpgO3pvnFwFRJR0oaTdaAvjxd8tohaVK6K2tabhszM6uj/gXWeU7SK0iXkCRNAp4uuP9PADdKOgJ4FPgrssK1SNLFwCbgAoCIWCNpEVmh2QXMjIhKsbqU7IxoAHB7mszMrM6KFJEryM4SXinpl0AL8P4iO4+IlUBrlbfO2c/6c4A5VeLtwGlFPtPMzPpOt0UkIlZIehNwClkj97r0rIiZmR3iitydNRM4NiLWRMRq4FhJH6t9amZm1uiKNKx/JD0kCEBE/A74SM0yMjOzplGkiByW76sqdUVyRO1SMjOzZlGkYf2nZHdTXUt2h9YlwE9qmpWZmTWFIkXk08BHyW6zFXAH8M1aJmVmZs2hyN1ZL5H1oju/9umYmVkz6baISDoTuAo4Ka0vICLi5NqmZmZmja7I5azrgE8BD1CguxMzMzt0FCkiT0eEuxkxM7N9FCkid0r6PPADYGclGBErapaVmZk1hSJF5HXpNd8HVgBv6f10zMysmRS5O6vIKIZmZnYIKnImgqR3AqcCR1ViEfHZWiVlZmbNoUgHjNcCHyAbG0Rk43+cVOO8zMysCRTpO+vPImIa8LuI+AzwevYextbMzA5RRYrIC+n1eUknAC8Co2uXkpmZNYsibSI/kvRy4PPACrI7s75Ry6TMzKw5dHkmIukwYGlEPBUR3ydrCxkbEf9QZOeSHpO0StJKSe0pNljSEknr0+ug3PqzJW2QtE7Subn4hLSfDZLm5rumNzOz+umyiKTOF7+YW94ZEU/38DPeHBGnR0TlOZNZZIVpDLA0LSNpPDCV7C6wycC8NHYJZJ0/zgDGpGlyD3MwM7MaKNImcoek9/XiX/9TgLY03wacn4svTIVqI7ABmChpGDAwIpZFRAA35LYxM7M6KtImcgVwDLBL0gvs6cV3YIFtg6wIBfD1iFgADI2ILWQ72SJpSFp3OHBvbtuOFHsxzXeO70PSDLIzFk488cQC6ZmZ2YEo8sT6yw5g/2dGxOZUKJZIeqSLdaud6UQX8X2DWZFaANDa2lp1HTMz6z1FxhM5q1o8Iu7ubtuI2Jxet0m6BZgIbJU0LJ2FDAO2pdU72Pv5kxHA5hQfUSVuZmZ1VuRy1t/l5o8iKwQP0E0HjJKOAQ6LiB1p/u3AZ4HFwHTg6vR6a9pkMXCTpC8BJ5A1oC+PiN2SdkiaBNwHTAO+UvD7mZlZDRW5nPXu/LKkkcA1BfY9FLgltcf3B26KiJ9Iuh9YJOliYBNZNypExBpJi4CHgV3AzIioDIJ1KXA9MAC4PU3WC9aOHce4R9bWOw0za1KFOmDspAM4rbuVIuJR4NVV4k8C5+xnmznAnCrx9iKfaWZmfatIm8hX2NOQfRhwOvBgDXMyM7MmUeRMpD03vwu4OSJ+WaN8zMysiRQpIt8DXqi0T0jqJ+noiHi+tqmZmVmjK/LE+lKyBu2KAcC/1yYdMzNrJkWKyFER8WxlIc0fXbuUzMysWRQpIs9JOqOyIGkC8PvapWRmZs2iSJvI5cB3JVWeEh9GNlyumZkd4oo8bHi/pLHAKWT9WD0SES/WPDMzM2t43V7OkjQTOCYiVkfEKuBYSR+rfWpmZtboirSJfCQinqosRMTvgI/ULCOrubVjx9U7BTM7SBQpIoflB6RKow0eUbuUzMysWRRpWP8pWYeJ15J1f3IJ8JOaZmVmZk2hSBH5NPBRsp50BdwBfLOWSZmZWXMocnfWS5KuA35BdiayLtdFu5mZHcKK3J11NrAe+CowD/j1/kY7tPpzo7mZ9aUil7O+CLw9ItYBSPoT4GZgQi0TMzOzxlfk7qzDKwUEICJ+DRxeu5TMzKxZFCki7ZKuk3R2mr5BNsZ6Ianr+F9Jui0tD5a0RNL69Doot+5sSRskrZN0bi4+QdKq9N7c/C3HZmZWP0WKyKXAGuAy4JNkY6Bf0oPP+CSQH8R7FrA0IsaQdTM/C0DSeGAqcCowGZiXnkkBmA/MAMakaXIPPt/MzGqk2yISETsj4ksR8ecR8d6I+KeI2Flk55JGAO9k71uCpwBtab4NOD8XX5g+byOwAZgoaRgwMCKWRUQAN+S2MTOzOipyJnIgvgz8L+ClXGxoRGwBSK9DUnw48ERuvY4UG57mO8f3IWmGpHZJ7du3b++VL2BmZvtXsyIi6V3Atogo2n5SrZ0juojvG4xYEBGtEdHa0tJS8GPNzKys/RYRSd9Or58sue8zgfdIegxYCLxF0neArekSFel1W1q/AxiZ234EsDnFR1SJm5lZnXV1JjJB0knAX0salO6q+uPU3Y4jYnZEjIiIUWQN5j+LiA8Bi4HpabXpwK1pfjEwVdKRkkaTNaAvT5e8dkialO7Kmpbb5qDxtUt+Vu8UzMx6rKuHDa8l62jxZLJbevOXlSLFy7iarEPHi4FNwAUAEbFG0iKyu792ATNz3atcClwPDABuT5OZmdXZfotIRMwF5kqaHxGXHsiHRMRdwF1p/kngnP2sNweYUyXeDpx2IDmYmVnvK9IB46WSXg28MYXujoiHapuWmZk1gyIdMF4G3Eh2K+4Q4EZJn6h1YmZm1viKdMD4N8DrIuI5AEmfA5YBX6llYmZm1viKPCciID9+yG6qP7thZmaHmCJnIv8C3CfplrR8PnBdzTIyM7OmUaRh/UuS7gLeQHYG8lcR8ataJ2ZmZo2vyJkIEbECWFHjXMzMrMnUugNGMzM7iLmImJlZaV0WkTQq4b/3VTJmZtZcuiwiqe+q5yUd10f5mJlZEynSsP4CsErSEuC5SjAiLqtZVmZm1hSKFJEfp8nMzGwvRZ4TaZM0ADgxItb1QU5WJ2vHjmPcI2vrnYaZNZEiHTC+G1hJNrYIkk6XtLjGeZmZWRMocovvVcBE4CmAiFgJjK5ZRlbI2rHj6p2CmVmhIrIrIp7uFItaJGNmZs2lSBFZLemDQD9JYyR9Bbinu40kHSVpuaQHJa2R9JkUHyxpiaT16XVQbpvZkjZIWifp3Fx8gqRV6b25aax1MzOrsyJF5BPAqcBO4GbgGeDyAtvtBN4SEa8GTgcmS5oEzAKWRsQYYGlaRtJ4YGr6rMnAPEn90r7mAzOAMWmaXODzzcysxrotIhHxfERcSTYu+psj4sqIeKHAdhERz6bFw9MUwBSgLcXbyLqWJ8UXRsTOiNgIbAAmShoGDIyIZRERwA25bczMrI6K3J31WkmrgIfIHjp8UNKEIjtP3aasBLYBSyLiPmBoRGwBSK9D0urDgSdym3ek2PA03zle7fNmSGqX1L59+/YiKTakr13ys3qnYGZWSJHLWdcBH4uIURExCphJNlBVtyJid0ScDowgO6s4rYvVq7VzRBfxap+3ICJaI6K1paWlSIpmZnYAihSRHRHx88pCRPwC2NGTD4mIp4C7yNoytqZLVKTXbWm1DmBkbrMRwOYUH1ElbmZmdbbfIiLpDElnAMslfV3S2ZLeJGkeWUHokqQWSS9P8wOAtwKPAIuB6Wm16cCtaX4xMFXSkZJGkzWgL0+XvHZImpTuypqW28bMzOqoq25Pvthp+R9z80WeExkGtKU7rA4DFkXEbZKWAYskXQxsAi4AiIg1khYBDwO7gJmpF2GAS4HrgQHA7WkyM7M6228RiYg3H8iOI+Ih4DVV4k+S3elVbZs5wJwq8Xagq/YUMzOrg247YEyXpKYBo/Lruyt4MzMr0hX8vwH3AquAl2qbjpmZNZMiReSoiLii5pmYmVnTKXKL77clfUTSsNTv1WBJg2uemZmZNbwiZyJ/AD4PXMmeu7ICOLlWSZmZWXMociZyBfA/0hPro9PkAlIH7g7FzBpNkSKyBni+1omYmVnzKXI5azewUtKdZN27A77F18zMihWRH6bJzMxsL90WkYho624dMzM7NBV5Yn0jVfrKcuO6mZkVaVhvBV6bpjcCc4Hv1DKpg43vqjKzg1WR4XGfzE2/jYgvA2+pfWoHPxcXM2t2RS5nnZFbPIzszORlNcvIzMyaRpG7s/LjiuwCHgP+oibZmJlZUylyd9YBjStiZmYHryKXs44E3se+44l8tnZpmZlZMyhyd9atwBSyS1nP5aYuSRop6U5JayWtkfTJFB8saYmk9el1UG6b2ZI2SFon6dxcfIKkVem9uWmsdTMzq7MiRWRERHwgIq6JiC9WpgLb7QL+Z0SMAyYBMyWNB2YBSyNiDLA0LZPemwqcCkwG5qXx2QHmAzOAMWmaXPwrNjffwWVmjaxIEblH0qt6uuOI2BIRK9L8DmAtMJzsrKbyFHwbcH6anwIsjIidEbER2ABMlDQMGBgRyyIigBty25iZWR0VuTvrDcBF6cn1nYCAiIg/LfohkkYBrwHuA4ZGxBaynWyRNCStNpxsGN6KjhR7Mc13jlf7nBlkZyyceOKJRdMzM7OSihSR8w7kAyQdC3wfuDwinumiOaPaG9FFfN9gxAJgAUBra2vVdczMrPcUeWL98WpTkZ1LOpysgNwYET9I4a3pEhXpdVuKdwAjc5uPADan+Igq8abkNg4zO5gUaRMpJd1BdR2wNiK+lHtrMTA9zU8nu/urEp8q6UhJo8ka0JenS187JE1K+5yW28bMzOqoyOWsss4EPgyskrQyxf43cDWwSNLFwCbgAoCIWCNpEfAw2Z1dMyNid9ruUuB6YABwe5rMzKzOalZEIuIXVG/PADhnP9vMAeZUibcDp/VedmZm1htqdjnLzMwOfi4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iFhVa8eOq3cKZtYEXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0mo5xvq3JG2TtDoXGyxpiaT16XVQ7r3ZkjZIWifp3Fx8gqRV6b25aZx1y/GDgWZWL7U8E7kemNwpNgtYGhFjgKVpGUnjganAqWmbeZL6pW3mAzOAMWnqvE8zM6uTmhWRiLgb+O9O4SlAW5pvA87PxRdGxM6I2AhsACZKGgYMjIhlERHADbltzMyszvq6TWRoRGwBSK9DUnw48ERuvY4UG57mO8etjr52yc/qnYKZNYhGaViv1s4RXcSr70SaIaldUvv27dt7LTkzM6uur4vI1nSJivS6LcU7gJG59UYAm1N8RJV4VRGxICJaI6K1paWlVxM3M7N99XURWQxMT/PTgVtz8amSjpQ0mqwBfXm65LVD0qR0V9a03DYNzZd8zOxQ0L9WO5Z0M3A2cLykDuAfgauBRZIuBjYBFwBExBpJi4CHgV3AzIjYnXZ1KdmdXgOA29NkZmYNoGZFJCIu3M9b5+xn/TnAnCrxduC0XkzNzMx6SaM0rJuZWRNyETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRKxba8eO2+97HnzL7NDmInIAXtX2qnqnYGZWVy4iZmZWmouImZmV1jRFRNJkSeskbZA0q975dOZLW2Z2KGqKIiKpH/A14DxgPHChpPE1+8CrjqvZrg9mPW1kd6O8WfNriiICTAQ2RMSjEfEHYCEwpc457cO/FPfIHwsfF7ODlyKi3jl0S9L7gckR8Tdp+cPA6yLi453WmwHMSIunAOt68DHHA//VC+n2JefcN5oxZ2jOvJ1z3+gq55MioqXojvr3Tj41pyqxfapfRCwAFpT6AKk9IlrLbFsvzrlvNGPO0Jx5O+e+0Zs5N8vlrA5gZG55BLC5TrmYmVnSLEXkfmCMpNGSjgCmAovrnJOZ2SGvKS5nRcQuSR8Hfgr0A74VEWt6+WNKXQarM+fcN5oxZ2jOvJ1z3+i1nJuiYd3MzBpTs1zOMjOzBuQiYmZmpbmI0LhdqkgaKelOSWslrZH0yRS/StJvJa1M0zty28xO32OdpHPrlPdjklal3NpTbLCkJZLWp9dBjZKzpFNyx3KlpGckXd5ox1nStyRtk7Q6F+vxcZU0If37bJA0V1K1W+hrmfPnJT0i6SFJt0h6eYqPkvT73PG+toFy7vHPQgPk/K+5fB+TtDLFe/c4R8QhPZE11P8GOBk4AngQGF/vvFJuw4Az0vzLgF+TdftyFfC3VdYfn/I/Ehidvle/OuT9GHB8p9g1wKw0Pwv4XCPl3Onn4T+BkxrtOANnAWcAqw/kuALLgdeTPX91O3BeH+f8dqB/mv9cLudR+fU67afeOff4Z6HeOXd6/4vAP9TiOPtMpIG7VImILRGxIs3vANYCw7vYZAqwMCJ2RsRGYAPZ92sEU4C2NN8GnJ+LN1LO5wC/iYjHu1inLjlHxN3Af1fJpfBxlTQMGBgRyyL7rXFDbps+yTki7oiIXWnxXrLnvvarEXLuQsMe54p0NvEXwM1d7aNszi4i2S/lJ3LLHXT9i7ouJI0CXgPcl0IfT5cDvpW7hNEo3yWAOyQ9oKwrGoChEbEFsuIIDEnxRsm5Yip7/2dr5OMMPT+uw9N853i9/DXZX7wVoyX9StJ/SHpjijVKzj35WWiUnAHeCGyNiPW5WK8dZxeRgl2q1JOkY4HvA5dHxDPAfOCVwOnAFrJTVWic73JmRJxB1uvyTElndbFuo+SMsgdZ3wN8N4Ua/Th3ZX85Nkzukq4EdgE3ptAW4MSIeA1wBXCTpIE0Rs49/VlohJwrLmTvP4x69Ti7iDR4lyqSDicrIDdGxA8AImJrROyOiJeAb7DnUkpDfJeI2JxetwG3kOW3NZ0uV06bt6XVGyLn5DxgRURshcY/zklPj2sHe18+qkvukqYD7wL+Ml06IV0SejLNP0DWvvAnNEDOJX4W6p4zgKT+wJ8D/1qJ9fZxdhFp4C5V0rXM64C1EfGlXHxYbrX3ApU7MhYDUyUdKWk0MIasoazPSDpG0ssq82SNqKtTbtPTatOBWxsl55y9/mJr5OOc06Pjmi557ZA0Kf18Tctt0yckTQY+DbwnIp7PxVuUjR2EpJNTzo82SM49+llohJyTtwKPRMQfL1P1+nGu1d0CzTQB7yC78+k3wJX1zieX1xvITicfAlam6R3At4FVKb4YGJbb5sr0PdZRw7tBusj5ZLK7VR4E1lSOJ/AKYCmwPr0ObpScUw5HA08Cx+ViDXWcyQrcFuBFsr8aLy5zXIFWsl+CvwG+Suq5og9z3kDWjlD5mb42rfu+9DPzILACeHcD5dzjn4V655zi1wOXdFq3V4+zuz0xM7PSfDnLzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzEbFDlqSLJH01zV8iaVoufkKJ/T0m6fgerH+5pKMLrPdsT3MpsM8e5Vpwn6MkfTC3/MfjawcvFxEzICKujYgb0uJFQI+LSAmXkz2fcrAYBXywu5Xs4OIiYn0uPdX+Y0kPSlot6QMpPlnZOBO/SGMZ3JbiEyXdkzqMu0fSKSl+kaQfSvqRpI2SPi7pirTevZIGp/XukvTltO1qSfv0uKtsvIi/lfR+sgeublQ21sKA/F/tklol3ZXmXyHpjvR5XyfX95CkD0lanvbx9coTwrn3LyMrVHdKujPFLlQ2lsNqSZ+rkuPxkpZJemd66vj7ku5P05m57/Gt9J0fTZ/T3b9H1VwlPStpTvp3ulfS0BR/ZVq+X9Jnc2dKVwNvTPv5VIqdIOknysY7uaa7XKwJ9cWTtp485SeyJ2a/kVs+DjiK7CnmMWS/jBcBt6X3B7Jn/Im3At9P8xeRPf38MqAFeJr0dC7wT2QdVgLcVfk8snEXVue2/2qav4o0XkRavzWX32Ok8VHICsxdaX4ue8ZoeCdZ7wLHA+OAHwGHp/fmAdOqHIf8fk8ANqXv0R/4GXB+eu9ZYChZD85vS7GbgDek+RPJusapfI97yMa3OJ7sKfzD9/fZXeWavs+70/w1wN+n+duAC9P8JcCzaf7syr9Z7vg+mvv3fRwYWe+fP0+9O/XHrO+tAr6Q/tq+LSJ+Lul0YGOk7qolfQeodCN/HNAmaQzZL7bDc/u6M7KxVnZIeprsF2LlM/40t97NkI27IGmg0mh6B+gsss7tiIgfS/pdip8DTADuz7ogYgB7Okbcn9eSFaftAJJuTPv/Idn3XQrMjIj/SOu/FRivPQPPDVTqswz4cUTsBHZK2kZWgPJdfOd1lesfyAoGwAPA29L869kzzsRNwBe6+F5LI+Lp9J0eJhvs64ku1rcm4yJifS4ifi1pAlk/YP9P0h1k/RHtrw+e/0NWLN6rbFyVu3Lv7czNv5Rbfom9f74777sn/f3sYs+l36MK7EdAW0TM7sFndDUM6S6yX+LnApUichjw+oj4/V47yQpB/pjspuv/513l+mJEVL5fd/vZn57kYk3IbSLW59KdT89HxHfI/oo9A3iEbKCcV6bVLsxtchzw2zR/UcmPrbS7vAF4uvLX8X7sILtEVvEY2V/rkF2Kq7gb+Mu03/OAykBFS4H3SxqS3hss6aRuPuc+4E2p3aMf2fevFIwgG7xprKRZKXYH8PHKjtKZXBlFc827lz3HYWou3vm42SHARcTq4VXAckkryXpA/b8R8QLZ5asfS/oF2fXzimvIzlh+STYGehm/k3QPcC1Zr6xduR64ttKwDnwG+GdJPyf7a7riM8BZklaQdXm/CSAiHgb+nmx0x4eAJUC+K/GKBcDtku6MrBvu2cCdpN5VI+KP3XBHxG6yX9hvlvQx4DKgVdlIew+TtU30WA9yzbscuELS8rRupSA/BOxKDfGf2t/GdnBxL77WkCSdTdbQ/a5e2NddaV/tB7ovA2XPtvw+IkLSVLJG9in1zsvqw9cnzaynJgBfVdYA8xTZpTY7RPlMxMzMSnObiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV9v8BL2GHE7DZulMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have a maximal sequence length of 350.\n",
    "Let's do a train-test split and then filter out the too long amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(len(amplitudes_unique)):\n",
    "    X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(amplitudes_unique[i], sqampl_prefix[i],\n",
    "        test_size=0.1)\n",
    "    X_train.append(X_train_tmp)\n",
    "    y_train.append(y_train_tmp)\n",
    "    X_test.append(X_test_tmp)\n",
    "    y_test.append(y_test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"X_train_prefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(export_folder+\"y_train_hybrid_prefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open(export_folder+\"X_test_prefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open(export_folder+\"y_test_hybrid_prefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"X_train_prefix.pickle\", \"br\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(export_folder+\"y_train_hybrid_prefix.pickle\", \"br\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(export_folder+\"X_test_prefix.pickle\", \"br\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(export_folder+\"y_test_hybrid_prefix.pickle\", \"br\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use those X,y where both are at most `sequence_length` long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_long(X, y, max_seq_len=350):\n",
    "    X_idxs_ok = np.where([len(x) < max_seq_len for x in X])[0]\n",
    "    y_idxs_ok = np.where([len(y) < max_seq_len for y in y])[0]\n",
    "    idxs_okay = np.intersect1d(X_idxs_ok, y_idxs_ok) \n",
    "    X_new = [X[i] for i in idxs_okay]\n",
    "    y_new = [y[i] for i in idxs_okay]\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "max_seq_len = 350\n",
    "batch_size = 1\n",
    "\n",
    "X_train_filtered, y_train_filtered = [], []\n",
    "for i in range(len(X_train)):\n",
    "    X_train_filtered_tmp, y_train_filtered_tmp = remove_too_long(X_train[i], y_train[i], max_seq_len=max_seq_len)\n",
    "    X_train_filtered.append(X_train_filtered_tmp)\n",
    "    y_train_filtered.append(y_train_filtered_tmp)\n",
    "\n",
    "\n",
    "X_test_filtered, y_test_filtered = [], []\n",
    "for i in range(len(X_test)):\n",
    "    X_test_filtered_tmp, y_test_filtered_tmp = remove_too_long(X_test[i], y_test[i], max_seq_len=max_seq_len)\n",
    "    X_test_filtered.append(X_test_filtered_tmp)\n",
    "    y_test_filtered.append(y_test_filtered_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(X_train_filtered[i]): 48\n",
      "ic| len(y_train_filtered[i]): 48\n",
      "ic| len(X_train_filtered[i]): 48\n",
      "ic| len(y_train_filtered[i]): 48\n",
      "ic| len(X_train_filtered[i]): 2689\n",
      "ic| len(y_train_filtered[i]): 2689\n",
      "ic| len(X_train_filtered[i]): 42993\n",
      "ic| len(y_train_filtered[i]): 42993\n",
      "ic| len(X_train_filtered[i]): 43090\n",
      "ic| len(y_train_filtered[i]): 43090\n",
      "ic| len(X_test_filtered[i]): 6\n",
      "ic| len(y_test_filtered[i]): 6\n",
      "ic| len(X_test_filtered[i]): 6\n",
      "ic| len(y_test_filtered[i]): 6\n",
      "ic| len(X_test_filtered[i]): 299\n",
      "ic| len(y_test_filtered[i]): 299\n",
      "ic| len(X_test_filtered[i]): 4790\n",
      "ic| len(y_test_filtered[i]): 4790\n",
      "ic| len(X_test_filtered[i]): 4745\n",
      "ic| len(y_test_filtered[i]): 4745\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_train_filtered)):\n",
    "    ic(len(X_train_filtered[i]))\n",
    "    ic(len(y_train_filtered[i]))\n",
    "\n",
    "for i in range(len(X_test_filtered)):\n",
    "    ic(len(X_test_filtered[i]))\n",
    "    ic(len(y_test_filtered[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = [[\" \".join(x) for x in X] for X in X_train_filtered]\n",
    "y_train_final = [[\" \".join(yy) for yy in y] for y in y_train_filtered]\n",
    "\n",
    "X_test_final = [[\" \".join(x) for x in X] for X in X_test_filtered]\n",
    "y_test_final = [[\" \".join(yy) for yy in y] for y in y_test_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, Data Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "vocab_size = 500\n",
    "max_seq_len = 350\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "# reading to sympy takes quite long.\n",
    "# We're here caching the alreaday converted amplitudes\n",
    "X_train_cache_file = export_folder+\"X_train_final_Xp_yhp.pickle\"\n",
    "y_train_cache_file = export_folder+\"y_train_final_Xp_yhp.pickle\"\n",
    "X_test_cache_file = export_folder+\"X_test_final_Xp_yhp.pickle\"\n",
    "y_test_cache_file = export_folder+\"y_test_final_Xp_yhp.pickle\"\n",
    "\n",
    "if os.path.exists(X_train_cache_file) & os.path.exists(y_train_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        X_train_final = pickle.load(f)\n",
    "    with open(y_train_cache_file, \"rb\") as f:\n",
    "        y_train_final = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_train_final, f)\n",
    "    with open(y_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_train_final, f)\n",
    "\n",
    "if os.path.exists(X_test_cache_file) & os.path.exists(y_test_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        X_test_final = pickle.load(f)\n",
    "    with open(y_test_cache_file, \"rb\") as f:\n",
    "        y_test_final = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_test_final, f)\n",
    "    with open(y_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_test_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod -1 Prod i Prod e Prod gamma alpha_2 alpha_1 alpha_0 Prod A^(*) i_2 alpha_2 (p_2) Prod ee^(*) i_0 alpha_1 (p_1)_u ee i_1 alpha_0 (p_3)_u'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mul( s- 4 pow e 2 add mul s- 1 s_13 mul 2 pow m_e 2 )'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "X_train_all = flatten(X_train_final)\n",
    "y_train_all = flatten(y_train_final) \n",
    "\n",
    "X_test_all = flatten(X_test_final)\n",
    "y_test_all = flatten(y_test_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ds, ds_size, train_split=0.9, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split>=0) & (train_split<=1)\n",
    "    # test_split = 1 - train_split\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    train_ds = ds.take(train_size)    \n",
    "    test_ds = ds.skip(train_size)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:29:27.922017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 12:29:27.922738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:29:27.922908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:29:27.922999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:29:28.416575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:29:28.416727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:29:28.416800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:29:28.416867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6019 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "df_train = tf.data.Dataset.from_tensor_slices((X_train_all, y_train_all)).prefetch(2)\n",
    "df_test = tf.data.Dataset.from_tensor_slices((X_test_all, y_test_all)).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train, df_train.cardinality().numpy(), train_split=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| df_val.cardinality().numpy(): 1778\n",
      "ic| df_train.cardinality().numpy(): 87090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9795843380411069>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(df_val.cardinality().numpy())\n",
    "ic(df_train.cardinality().numpy())\n",
    "1 - df_val.cardinality() / df_train.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplitudes:\n",
      "b'Prod 1/2 Prod i Prod Pow e 3 Prod Pow Sum Pow m_mu 2 Sum Prod 2 s_23 Prod -2 s_24 s_33 Prod -2 s_34 s_44 reg_prop -1 Prod Pow Sum s_23 Sum Prod 1/2 s_33 Prod 1/2 reg_prop -1 Sum Prod m_mu Prod gamma alpha_23 alpha_18 alpha_0 Prod gamma alpha_24 alpha_10 alpha_18 Prod gamma alpha_24 alpha_11 alpha_19 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_19 (p_1)_v Prod mu i_2 alpha_0 (p_2)_v Prod mu^(*) i_1 alpha_10 (p_4)_v mu^(*) i_3 alpha_11 (p_5)_v Sum Prod p_1 alpha_25 Prod gamma alpha_25 alpha_4 alpha_5 Prod gamma alpha_23 alpha_5 alpha_1 Prod gamma alpha_24 alpha_12 alpha_4 Prod gamma alpha_24 alpha_13 alpha_20 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_20 (p_1)_v Prod mu i_2 alpha_1 (p_2)_v Prod mu^(*) i_1 alpha_12 (p_4)_v mu^(*) i_3 alpha_13 (p_5)_v Prod -1 Prod p_4 alpha_25 Prod gamma alpha_25 alpha_6 alpha_7 Prod gamma alpha_23 alpha_7 alpha_2 Prod gamma alpha_24 alpha_14 alpha_6 Prod gamma alpha_24 alpha_15 alpha_21 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_21 (p_1)_v Prod mu i_2 alpha_2 (p_2)_v Prod mu^(*) i_1 alpha_14 (p_4)_v mu^(*) i_3 alpha_15 (p_5)_v Prod -1 Prod p_5 alpha_25 Prod gamma alpha_25 alpha_8 alpha_9 Prod gamma alpha_23 alpha_9 alpha_3 Prod gamma alpha_24 alpha_16 alpha_8 Prod gamma alpha_24 alpha_17 alpha_22 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_22 (p_1)_v Prod mu i_2 alpha_3 (p_2)_v Prod mu^(*) i_1 alpha_16 (p_4)_v mu^(*) i_3 alpha_17 (p_5)_v'\n",
      "b'Prod -1/9 Prod i Prod Pow e 3 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 reg_prop -1 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 reg_prop -1 Sum Prod p_1 alpha_16 Prod gamma alpha_16 alpha_3 alpha_4 Prod gamma alpha_17 alpha_0 alpha_3 Prod gamma alpha_18 alpha_13 alpha_7 Prod gamma alpha_18 alpha_4 alpha_10 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_0 (p_2)_v Prod b i_2 alpha_10 (p_4)_v Prod t^(*) i_0 alpha_13 (p_1)_v t i_1 alpha_7 (p_3)_v Sum Prod -1 Prod p_3 alpha_16 Prod gamma alpha_16 alpha_5 alpha_6 Prod gamma alpha_17 alpha_1 alpha_5 Prod gamma alpha_18 alpha_14 alpha_8 Prod gamma alpha_18 alpha_6 alpha_11 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_1 (p_2)_v Prod b i_2 alpha_11 (p_4)_v Prod t^(*) i_0 alpha_14 (p_1)_v t i_1 alpha_8 (p_3)_v Prod -2 Prod p_4 alpha_18 Prod gamma alpha_17 alpha_2 alpha_12 Prod gamma alpha_18 alpha_15 alpha_9 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_2 (p_2)_v Prod b i_2 alpha_12 (p_4)_v Prod t^(*) i_0 alpha_15 (p_1)_v t i_1 alpha_9 (p_3)_v'\n",
      "b'Prod -8/27 Prod i Prod Pow e 3 Prod Pow Sum s_11 Sum Prod 2 s_12 Prod 2 s_13 s_22 Prod 2 s_23 s_33 reg_prop -1 Prod Pow Sum Pow m_u 2 Sum Prod -1 s_22 Prod -2 s_23 Prod -1 s_33 Prod -1 reg_prop -1 Sum Prod m_u Prod gamma alpha_18 alpha_6 alpha_12 Prod gamma alpha_18 alpha_7 alpha_3 Prod gamma alpha_17 alpha_12 alpha_0 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_6 (p_1)_u Prod u i_2 alpha_0 (p_2)_v Prod tt i_1 alpha_3 (p_4)_u tt^(*) i_4 alpha_7 (p_5)_v Sum Prod -1 Prod p_2 alpha_19 Prod gamma alpha_18 alpha_8 alpha_13 Prod gamma alpha_18 alpha_9 alpha_4 Prod gamma alpha_17 alpha_14 alpha_1 Prod gamma alpha_19 alpha_13 alpha_14 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_8 (p_1)_u Prod u i_2 alpha_1 (p_2)_v Prod tt i_1 alpha_4 (p_4)_u tt^(*) i_4 alpha_9 (p_5)_v Prod -1 Prod p_3 alpha_19 Prod gamma alpha_18 alpha_10 alpha_15 Prod gamma alpha_18 alpha_11 alpha_5 Prod gamma alpha_17 alpha_16 alpha_2 Prod gamma alpha_19 alpha_15 alpha_16 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_10 (p_1)_u Prod u i_2 alpha_2 (p_2)_v Prod tt i_1 alpha_5 (p_4)_u tt^(*) i_4 alpha_11 (p_5)_v'\n",
      "squared amplitudes:\n",
      "b'mul( s- 8 pow e 6 pow add( reg_prop s_33 mul 2 s_23 ) s- 2 pow add( reg_prop s_33 s_44 pow m_mu 2 mul s- 2 s_24 mul s- 2 s_34 mul 2 s_23 ) s- 2 add( mul 8 pow m_mu 6 mul( s- 12 s_15 pow m_mu 4 ) mul( s- 4 s_24 pow m_mu 4 ) mul( s- 4 s_25 pow m_mu 4 ) mul( s- 2 s_25 pow s_14 2 ) mul( 2 s_12 pow s_45 2 ) mul( 4 s_11 pow m_mu 4 ) mul( 4 s_12 pow m_mu 4 ) mul( 4 s_45 pow m_mu 4 ) mul( 4 pow m_mu 2 pow s_15 2 ) mul( s_11 s_14 s_25 ) mul( s_12 s_44 s_45 ) mul( s_14 s_25 s_44 ) mul( s_24 s_44 pow m_mu 2 ) mul( s- 1 s_11 s_12 s_45 ) mul( s- 1 s_11 s_24 pow m_mu 2 ) mul( s- 4 s_11 s_45 pow m_mu 2 ) mul( s- 4 s_14 s_24 s_45 ) mul( s- 4 s_14 s_25 pow m_mu 2 ) mul( s- 2 s_11 s_15 pow m_mu 2 ) mul( s- 2 s_12 s_14 s_15 ) mul( s- 2 s_12 s_15 pow m_mu 2 ) mul( s- 2 s_12 s_44 pow m_mu 2 ) mul( s- 2 s_12 s_45 pow m_mu 2 ) mul( s- 2 s_14 s_24 pow m_mu 2 ) mul( s- 2 s_14 s_25 s_45 ) mul( s- 2 s_15 s_24 s_45 ) mul( s- 2 s_15 s_25 s_45 ) mul( s- 2 s_15 s_44 pow m_mu 2 ) mul( 2 s_11 s_24 s_45 ) mul( 2 s_11 s_25 s_45 ) mul( 2 s_12 s_14 s_45 ) mul( 2 s_14 s_15 s_24 ) mul( 2 s_15 s_25 pow m_mu 2 ) mul( 2 s_25 s_44 pow m_mu 2 ) mul( 2 s_25 s_45 pow m_mu 2 ) mul( 4 s_12 s_14 pow m_mu 2 ) mul( 4 s_15 s_24 pow m_mu 2 ) mul( 8 s_14 s_45 pow m_mu 2 ) ) )'\n",
      "b'mul( mul s- 16 pow 81 s- 1 pow e 6 pow add( reg_prop s_11 pow m_t 2 mul s- 2 s_13 ) s- 2 pow add( reg_prop s_11 pow m_t 2 mul s- 2 s_13 mul s- 2 s_14 mul 2 s_34 ) s- 2 add( mul pow m_b 2 add( mul 4 pow s_13 2 mul( s- 4 s_11 s_34 ) mul( s- 2 s_11 s_13 ) mul( s- 2 s_12 s_13 ) mul( 2 s_13 s_23 ) mul( 2 s_13 s_24 ) mul( 8 s_14 s_34 ) ) mul pow m_t 2 add( mul( s- 1 s_11 s_24 ) mul( s- 1 s_12 s_34 ) mul( s- 3 s_14 s_23 ) mul( s- 2 s_14 s_24 ) mul( 2 s_13 s_24 ) mul( 2 s_23 s_34 ) mul( 4 s_12 s_14 ) ) mul( s- 1 s_24 pow m_t 4 ) mul( s- 4 s_13 pow m_b 4 ) mul( s- 2 s_23 pow s_14 2 ) mul( 2 s_12 pow s_34 2 ) mul( 4 pow m_b 2 pow m_t 4 ) mul( 4 pow m_b 4 pow m_t 2 ) mul( s_11 s_14 s_23 ) mul( pow m_b 2 pow m_t 2 add( mul s- 10 s_13 mul s- 2 s_23 mul s- 2 s_24 mul 2 s_12 mul 4 s_11 mul 4 s_34 ) ) mul( s- 1 s_11 s_12 s_34 ) mul( s- 4 s_14 s_24 s_34 ) mul( s- 2 s_12 s_13 s_14 ) mul( s- 2 s_13 s_23 s_34 ) mul( s- 2 s_13 s_24 s_34 ) mul( s- 2 s_14 s_23 s_34 ) mul( 2 s_11 s_23 s_34 ) mul( 2 s_11 s_24 s_34 ) mul( 2 s_12 s_14 s_34 ) mul( 2 s_13 s_14 s_24 ) ) )'\n",
      "b'mul( mul s- 1024 pow 729 s- 1 pow e 6 pow add( pow m_u 2 mul s- 1 reg_prop mul s- 1 s_22 mul s- 1 s_33 mul s- 2 s_23 ) s- 2 pow add( reg_prop s_11 s_22 s_33 mul 2 s_12 mul 2 s_13 mul 2 s_23 ) s- 2 add( mul pow m_u 2 add( mul( 2 s_23 s_45 ) mul( 2 s_33 s_45 ) mul( 3 s_12 pow m_tt 2 ) mul( 3 s_14 s_25 ) mul( 3 s_15 s_24 ) mul( 4 s_13 pow m_tt 2 ) mul( 4 s_14 s_35 ) mul( 4 s_15 s_34 ) mul( 4 s_23 pow m_tt 2 ) mul( 4 s_33 pow m_tt 2 ) ) mul pow m_u 4 add mul 2 s_45 mul 4 pow m_tt 2 mul( s_12 s_33 pow m_tt 2 ) mul( s_14 s_25 s_33 ) mul( s_15 s_24 s_33 ) mul( s- 1 s_12 s_22 pow m_tt 2 ) mul( s- 1 s_14 s_22 s_25 ) mul( s- 1 s_15 s_22 s_24 ) mul( s- 2 s_13 s_22 pow m_tt 2 ) mul( s- 2 s_13 s_23 pow m_tt 2 ) mul( s- 2 s_14 s_22 s_35 ) mul( s- 2 s_14 s_23 s_35 ) mul( s- 2 s_15 s_22 s_34 ) mul( s- 2 s_15 s_23 s_34 ) ) )'\n"
     ]
    }
   ],
   "source": [
    "for x_examples, y_examples in df_train.batch(3).take(1):\n",
    "    print(\"amplitudes:\")\n",
    "    for xx in x_examples.numpy():\n",
    "        print(xx)\n",
    "    print(\"squared amplitudes:\")\n",
    "    for yy in y_examples.numpy():\n",
    "        print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| bogoTokenizer.tokenize([\"hello world\", \"this is a test\"]): <tf.RaggedTensor [[2, 8, 4, 3], [2, 5, 7, 9, 6, 3]]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup\n",
      "<tf.RaggedTensor [[b'[START]', b'hello', b'world', b'[END]'],\n",
      " [b'[START]', b'this', b'is', b'a', b'test', b'[END]']]>\n",
      "detokenize\n",
      "tf.Tensor([b'hello world' b'this is a test'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "class BogoTokenizer(tf_text.Tokenizer, tf_text.Detokenizer):\n",
    "    \"\"\"\n",
    "    My implementation of a tf_text.Tokenizer.\n",
    "    It's actually just a wrapper around TextVectorization,\n",
    "    but so that it works for my case.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=None,\n",
    "            standardize=None, ragged=False,):\n",
    "        super(BogoTokenizer, self).__init__()\n",
    "        self.vectorizer = TextVectorization(max_tokens=max_tokens, output_mode=output_mode,\n",
    "            output_sequence_length=output_sequence_length, ragged=ragged, standardize=None)\n",
    "        self.start = \"[START]\"\n",
    "        self.end = \"[END]\"\n",
    "\n",
    "    def tokenize(self, input):\n",
    "        input_with_start_end = [self.start+\" \"+inp+\" \"+self.end for inp in input]\n",
    "        return self.vectorizer(input_with_start_end)\n",
    "\n",
    "    def encode(self, input):\n",
    "        return self.vectorizer(input)\n",
    "\n",
    "    def adapt(self, input):\n",
    "        input_with_start_end = [self.start+\" \"+inp+\" \"+self.end for inp in input]\n",
    "        self.vectorizer.adapt(input_with_start_end)\n",
    "\n",
    "    def detokenize(self, tokens):\n",
    "        vocab = tf.constant(self.vectorizer.get_vocabulary())\n",
    "        sentences = tf.gather(vocab, tokens)\n",
    "        sentences = sentences[:, 1:-1]\n",
    "        signature = tf.type_spec_from_value(tf.strings.join(sentences[0]))\n",
    "        sentences = tf.map_fn(fn=lambda s: tf.strings.join(s, separator=\" \"), elems=sentences,\n",
    "            fn_output_signature=signature)\n",
    "        return sentences\n",
    "\n",
    "    def lookup(self, tokens):\n",
    "        vocab = tf.constant(self.vectorizer.get_vocabulary())\n",
    "        return tf.gather(vocab, tokens)\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vectorizer.get_vocabulary()\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vectorizer.get_vocabulary())\n",
    "\n",
    "bogoTokenizer = BogoTokenizer(output_sequence_length=None, ragged=True)\n",
    "bogoTokenizer.adapt([\"hello world\", \"this is a test\"])\n",
    "tokens = ic(bogoTokenizer.tokenize([\"hello world\", \"this is a test\"]))\n",
    "print(\"lookup\")\n",
    "print(bogoTokenizer.lookup(tokens))\n",
    "print(\"detokenize\")\n",
    "print(bogoTokenizer.detokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod -1 Prod i Prod e Prod gamma alpha_2 alpha_1 alpha_0 Prod A^(*) i_2 alpha_2 (p_2) Prod ee^(*) i_0 alpha_1 (p_1)_u ee i_1 alpha_0 (p_3)_u'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_X = BogoTokenizer(ragged=True)\n",
    "tokenizer_y = BogoTokenizer(ragged=True)\n",
    "\n",
    "tokenizer_X.adapt(X_train_all)\n",
    "tokenizer_y.adapt(y_train_all)\n",
    "\n",
    "tokenizers = {\"X\": tokenizer_X, \"y\": tokenizer_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[50, 1, 2, 3, 1, 51]]>\n",
      "tf.Tensor([b'[UNK] Prod gamma [UNK]'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer_X.tokenize([\"banana Prod gamma banananana\"])\n",
    "print(enc)\n",
    "round_trip = tokenizer_X.detokenize(enc)\n",
    "print(round_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'(p_5)_v [UNK] Prod gamma'], dtype=object)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_X.detokenize([[45, 42, 1, 2, 3, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=string, numpy=\n",
       "array([[b'(p_3)', b'(p_5)_v', b'[UNK]', b'Prod', b'gamma', b'(p_5)']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_X.lookup([[45, 42, 1, 2, 3, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Prod 1/2 Prod i Prod Pow e 3 Prod Pow Sum Pow m_mu 2 Sum Prod 2 s_23 Prod -2 s_24 s_33 Prod -2 s_34 s_44 reg_prop -1 Prod Pow Sum s_23 Sum Prod 1/2 s_33 Prod 1/2 reg_prop -1 Sum Prod m_mu Prod gamma alpha_23 alpha_18 alpha_0 Prod gamma alpha_24 alpha_10 alpha_18 Prod gamma alpha_24 alpha_11 alpha_19 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_19 (p_1)_v Prod mu i_2 alpha_0 (p_2)_v Prod mu^(*) i_1 alpha_10 (p_4)_v mu^(*) i_3 alpha_11 (p_5)_v Sum Prod p_1 alpha_25 Prod gamma alpha_25 alpha_4 alpha_5 Prod gamma alpha_23 alpha_5 alpha_1 Prod gamma alpha_24 alpha_12 alpha_4 Prod gamma alpha_24 alpha_13 alpha_20 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_20 (p_1)_v Prod mu i_2 alpha_1 (p_2)_v Prod mu^(*) i_1 alpha_12 (p_4)_v mu^(*) i_3 alpha_13 (p_5)_v Prod -1 Prod p_4 alpha_25 Prod gamma alpha_25 alpha_6 alpha_7 Prod gamma alpha_23 alpha_7 alpha_2 Prod gamma alpha_24 alpha_14 alpha_6 Prod gamma alpha_24 alpha_15 alpha_21 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_21 (p_1)_v Prod mu i_2 alpha_2 (p_2)_v Prod mu^(*) i_1 alpha_14 (p_4)_v mu^(*) i_3 alpha_15 (p_5)_v Prod -1 Prod p_5 alpha_25 Prod gamma alpha_25 alpha_8 alpha_9 Prod gamma alpha_23 alpha_9 alpha_3 Prod gamma alpha_24 alpha_16 alpha_8 Prod gamma alpha_24 alpha_17 alpha_22 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_22 (p_1)_v Prod mu i_2 alpha_3 (p_2)_v Prod mu^(*) i_1 alpha_16 (p_4)_v mu^(*) i_3 alpha_17 (p_5)_v'\n",
      " b'Prod -1/9 Prod i Prod Pow e 3 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 reg_prop -1 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 reg_prop -1 Sum Prod p_1 alpha_16 Prod gamma alpha_16 alpha_3 alpha_4 Prod gamma alpha_17 alpha_0 alpha_3 Prod gamma alpha_18 alpha_13 alpha_7 Prod gamma alpha_18 alpha_4 alpha_10 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_0 (p_2)_v Prod b i_2 alpha_10 (p_4)_v Prod t^(*) i_0 alpha_13 (p_1)_v t i_1 alpha_7 (p_3)_v Sum Prod -1 Prod p_3 alpha_16 Prod gamma alpha_16 alpha_5 alpha_6 Prod gamma alpha_17 alpha_1 alpha_5 Prod gamma alpha_18 alpha_14 alpha_8 Prod gamma alpha_18 alpha_6 alpha_11 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_1 (p_2)_v Prod b i_2 alpha_11 (p_4)_v Prod t^(*) i_0 alpha_14 (p_1)_v t i_1 alpha_8 (p_3)_v Prod -2 Prod p_4 alpha_18 Prod gamma alpha_17 alpha_2 alpha_12 Prod gamma alpha_18 alpha_15 alpha_9 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_2 (p_2)_v Prod b i_2 alpha_12 (p_4)_v Prod t^(*) i_0 alpha_15 (p_1)_v t i_1 alpha_9 (p_3)_v'\n",
      " b'Prod -8/27 Prod i Prod Pow e 3 Prod Pow Sum s_11 Sum Prod 2 s_12 Prod 2 s_13 s_22 Prod 2 s_23 s_33 reg_prop -1 Prod Pow Sum Pow m_u 2 Sum Prod -1 s_22 Prod -2 s_23 Prod -1 s_33 Prod -1 reg_prop -1 Sum Prod m_u Prod gamma alpha_18 alpha_6 alpha_12 Prod gamma alpha_18 alpha_7 alpha_3 Prod gamma alpha_17 alpha_12 alpha_0 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_6 (p_1)_u Prod u i_2 alpha_0 (p_2)_v Prod tt i_1 alpha_3 (p_4)_u tt^(*) i_4 alpha_7 (p_5)_v Sum Prod -1 Prod p_2 alpha_19 Prod gamma alpha_18 alpha_8 alpha_13 Prod gamma alpha_18 alpha_9 alpha_4 Prod gamma alpha_17 alpha_14 alpha_1 Prod gamma alpha_19 alpha_13 alpha_14 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_8 (p_1)_u Prod u i_2 alpha_1 (p_2)_v Prod tt i_1 alpha_4 (p_4)_u tt^(*) i_4 alpha_9 (p_5)_v Prod -1 Prod p_3 alpha_19 Prod gamma alpha_18 alpha_10 alpha_15 Prod gamma alpha_18 alpha_11 alpha_5 Prod gamma alpha_17 alpha_16 alpha_2 Prod gamma alpha_19 alpha_15 alpha_16 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_10 (p_1)_u Prod u i_2 alpha_2 (p_2)_v Prod tt i_1 alpha_5 (p_4)_u tt^(*) i_4 alpha_11 (p_5)_v'], shape=(3,), dtype=string)\n",
      "encoded batch:\n",
      "[50, 2, 54, 2, 48, 2, 5, 49, 53, 2, 5, 4, 5, 104, 15, 4, 2, 15, 81, 2, 32, 91, 77, 2, 32, 78, 84, 28, 6, 2, 5, 4, 81, 4, 2, 54, 77, 2, 54, 28, 6, 4, 2, 104, 2, 3, 38, 8, 20, 2, 3, 39, 16, 8, 2, 3, 39, 17, 44, 2, 34, 14, 38, 45, 2, 86, 11, 44, 52, 2, 86, 9, 20, 40, 2, 85, 10, 16, 41, 85, 12, 17, 42, 4, 2, 58, 43, 2, 3, 43, 24, 29, 2, 3, 38, 29, 18, 2, 3, 39, 22, 24, 2, 3, 39, 30, 90, 2, 34, 14, 38, 45, 2, 86, 11, 90, 52, 2, 86, 9, 18, 40, 2, 85, 10, 22, 41, 85, 12, 30, 42, 2, 6, 2, 59, 43, 2, 3, 43, 27, 26, 2, 3, 38, 26, 19, 2, 3, 39, 37, 27, 2, 3, 39, 36, 94, 2, 34, 14, 38, 45, 2, 86, 11, 94, 52, 2, 86, 9, 19, 40, 2, 85, 10, 37, 41, 85, 12, 36, 42, 2, 6, 2, 96, 43, 2, 3, 43, 25, 23, 2, 3, 38, 23, 21, 2, 3, 39, 13, 25, 2, 3, 39, 7, 93, 2, 34, 14, 38, 45, 2, 86, 11, 93, 52, 2, 86, 9, 21, 40, 2, 85, 10, 13, 41, 85, 12, 7, 42, 51]\n",
      "[50, 2, 125, 2, 48, 2, 5, 49, 53, 2, 5, 4, 5, 97, 15, 4, 79, 2, 32, 57, 28, 6, 2, 5, 4, 5, 97, 15, 4, 79, 2, 32, 57, 2, 32, 80, 2, 15, 78, 28, 6, 4, 2, 58, 13, 2, 3, 13, 21, 24, 2, 3, 7, 20, 21, 2, 3, 8, 30, 26, 2, 3, 8, 24, 16, 2, 34, 14, 7, 46, 2, 60, 12, 20, 40, 2, 61, 9, 16, 41, 2, 73, 11, 30, 52, 74, 10, 26, 64, 4, 2, 6, 2, 76, 13, 2, 3, 13, 29, 27, 2, 3, 7, 18, 29, 2, 3, 8, 37, 25, 2, 3, 8, 27, 17, 2, 34, 14, 7, 46, 2, 60, 12, 18, 40, 2, 61, 9, 17, 41, 2, 73, 11, 37, 52, 74, 10, 25, 64, 2, 32, 2, 59, 8, 2, 3, 7, 19, 22, 2, 3, 8, 36, 23, 2, 34, 14, 7, 46, 2, 60, 12, 19, 40, 2, 61, 9, 22, 41, 2, 73, 11, 36, 52, 74, 10, 23, 64, 51]\n",
      "[50, 2, 115, 2, 48, 2, 5, 49, 53, 2, 5, 4, 79, 4, 2, 15, 82, 2, 15, 57, 83, 2, 15, 81, 77, 28, 6, 2, 5, 4, 5, 98, 15, 4, 2, 6, 83, 2, 32, 81, 2, 6, 77, 2, 6, 28, 6, 4, 2, 98, 2, 3, 8, 27, 22, 2, 3, 8, 26, 21, 2, 3, 7, 22, 20, 2, 34, 12, 7, 45, 2, 71, 11, 27, 31, 2, 72, 9, 20, 40, 2, 88, 10, 21, 35, 87, 14, 26, 42, 4, 2, 6, 2, 75, 44, 2, 3, 8, 25, 30, 2, 3, 8, 23, 24, 2, 3, 7, 37, 18, 2, 3, 44, 30, 37, 2, 34, 12, 7, 45, 2, 71, 11, 25, 31, 2, 72, 9, 18, 40, 2, 88, 10, 24, 35, 87, 14, 23, 42, 2, 6, 2, 76, 44, 2, 3, 8, 16, 36, 2, 3, 8, 17, 29, 2, 3, 7, 13, 19, 2, 3, 44, 36, 13, 2, 34, 12, 7, 45, 2, 71, 11, 16, 31, 2, 72, 9, 19, 40, 2, 88, 10, 29, 35, 87, 14, 17, 42, 51]\n",
      "tf.Tensor(\n",
      "[b'Prod 1/2 Prod i Prod Pow e 3 Prod Pow Sum Pow m_mu 2 Sum Prod 2 s_23 Prod -2 s_24 s_33 Prod -2 s_34 s_44 reg_prop -1 Prod Pow Sum s_23 Sum Prod 1/2 s_33 Prod 1/2 reg_prop -1 Sum Prod m_mu Prod gamma alpha_23 alpha_18 alpha_0 Prod gamma alpha_24 alpha_10 alpha_18 Prod gamma alpha_24 alpha_11 alpha_19 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_19 (p_1)_v Prod mu i_2 alpha_0 (p_2)_v Prod mu^(*) i_1 alpha_10 (p_4)_v mu^(*) i_3 alpha_11 (p_5)_v Sum Prod p_1 alpha_25 Prod gamma alpha_25 alpha_4 alpha_5 Prod gamma alpha_23 alpha_5 alpha_1 Prod gamma alpha_24 alpha_12 alpha_4 Prod gamma alpha_24 alpha_13 alpha_20 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_20 (p_1)_v Prod mu i_2 alpha_1 (p_2)_v Prod mu^(*) i_1 alpha_12 (p_4)_v mu^(*) i_3 alpha_13 (p_5)_v Prod -1 Prod p_4 alpha_25 Prod gamma alpha_25 alpha_6 alpha_7 Prod gamma alpha_23 alpha_7 alpha_2 Prod gamma alpha_24 alpha_14 alpha_6 Prod gamma alpha_24 alpha_15 alpha_21 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_21 (p_1)_v Prod mu i_2 alpha_2 (p_2)_v Prod mu^(*) i_1 alpha_14 (p_4)_v mu^(*) i_3 alpha_15 (p_5)_v Prod -1 Prod p_5 alpha_25 Prod gamma alpha_25 alpha_8 alpha_9 Prod gamma alpha_23 alpha_9 alpha_3 Prod gamma alpha_24 alpha_16 alpha_8 Prod gamma alpha_24 alpha_17 alpha_22 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_22 (p_1)_v Prod mu i_2 alpha_3 (p_2)_v Prod mu^(*) i_1 alpha_16 (p_4)_v mu^(*) i_3 alpha_17 (p_5)_v'\n",
      " b'Prod -1/9 Prod i Prod Pow e 3 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 reg_prop -1 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 reg_prop -1 Sum Prod p_1 alpha_16 Prod gamma alpha_16 alpha_3 alpha_4 Prod gamma alpha_17 alpha_0 alpha_3 Prod gamma alpha_18 alpha_13 alpha_7 Prod gamma alpha_18 alpha_4 alpha_10 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_0 (p_2)_v Prod b i_2 alpha_10 (p_4)_v Prod t^(*) i_0 alpha_13 (p_1)_v t i_1 alpha_7 (p_3)_v Sum Prod -1 Prod p_3 alpha_16 Prod gamma alpha_16 alpha_5 alpha_6 Prod gamma alpha_17 alpha_1 alpha_5 Prod gamma alpha_18 alpha_14 alpha_8 Prod gamma alpha_18 alpha_6 alpha_11 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_1 (p_2)_v Prod b i_2 alpha_11 (p_4)_v Prod t^(*) i_0 alpha_14 (p_1)_v t i_1 alpha_8 (p_3)_v Prod -2 Prod p_4 alpha_18 Prod gamma alpha_17 alpha_2 alpha_12 Prod gamma alpha_18 alpha_15 alpha_9 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_2 (p_2)_v Prod b i_2 alpha_12 (p_4)_v Prod t^(*) i_0 alpha_15 (p_1)_v t i_1 alpha_9 (p_3)_v'\n",
      " b'Prod -8/27 Prod i Prod Pow e 3 Prod Pow Sum s_11 Sum Prod 2 s_12 Prod 2 s_13 s_22 Prod 2 s_23 s_33 reg_prop -1 Prod Pow Sum Pow m_u 2 Sum Prod -1 s_22 Prod -2 s_23 Prod -1 s_33 Prod -1 reg_prop -1 Sum Prod m_u Prod gamma alpha_18 alpha_6 alpha_12 Prod gamma alpha_18 alpha_7 alpha_3 Prod gamma alpha_17 alpha_12 alpha_0 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_6 (p_1)_u Prod u i_2 alpha_0 (p_2)_v Prod tt i_1 alpha_3 (p_4)_u tt^(*) i_4 alpha_7 (p_5)_v Sum Prod -1 Prod p_2 alpha_19 Prod gamma alpha_18 alpha_8 alpha_13 Prod gamma alpha_18 alpha_9 alpha_4 Prod gamma alpha_17 alpha_14 alpha_1 Prod gamma alpha_19 alpha_13 alpha_14 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_8 (p_1)_u Prod u i_2 alpha_1 (p_2)_v Prod tt i_1 alpha_4 (p_4)_u tt^(*) i_4 alpha_9 (p_5)_v Prod -1 Prod p_3 alpha_19 Prod gamma alpha_18 alpha_10 alpha_15 Prod gamma alpha_18 alpha_11 alpha_5 Prod gamma alpha_17 alpha_16 alpha_2 Prod gamma alpha_19 alpha_15 alpha_16 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_10 (p_1)_u Prod u i_2 alpha_2 (p_2)_v Prod tt i_1 alpha_5 (p_4)_u tt^(*) i_4 alpha_11 (p_5)_v'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(x_examples)\n",
    "encoded = tokenizer_X.tokenize(x_examples)\n",
    "print(\"encoded batch:\")\n",
    "for row in encoded.to_list():\n",
    "    print(row)\n",
    "\n",
    "round_trip = tokenizer_X.detokenize(encoded)\n",
    "print(round_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=350\n",
    "def prepare_batch(X, y):\n",
    "    X = tokenizers[\"X\"].encode(X)      # Output is ragged.\n",
    "    X = X[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    X = X.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    y = tokenizers[\"y\"].encode(y)\n",
    "    y = y[:, :(MAX_TOKENS+1)]\n",
    "    y_inputs = y[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    y_labels = y[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (X, y_inputs), y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches(df_train)\n",
    "val_batches = make_batches(df_val)\n",
    "test_batches = make_batches(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None)), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215)\n",
      "(8, 343)\n",
      "(8, 343)\n"
     ]
    }
   ],
   "source": [
    "for (xx, yy), yy_labels in train_batches.take(1):\n",
    "    print(xx.shape)\n",
    "    print(yy.shape)\n",
    "    print(yy_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  2 134   2  48   2   5  49  15   2   5], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 4  7 29  6 48  5 14  6 31  8], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 7 29  6 48  5 14  6 31  8  6], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(xx[0][:10])\n",
    "print(yy[0][:10])\n",
    "print(yy_labels[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  \"\"\"embedding + positional encoding\"\"\"\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_X = PositionalEmbedding(vocab_size=tokenizers[\"X\"].get_vocab_size(), d_model=512)\n",
    "embed_y = PositionalEmbedding(vocab_size=tokenizers[\"y\"].get_vocab_size(), d_model=512)\n",
    "\n",
    "X_emb = embed_X(xx)\n",
    "y_emb = embed_X(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 215), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([  2, 134,   2,  48,   2])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 512), dtype=float32, numpy=\n",
       "array([[ 0.52374196, -0.12326486,  0.55464196, ...,  0.8183378 ,\n",
       "         1.4762123 ,  1.9976285 ],\n",
       "       [-0.26832962, -0.08011383,  1.1411189 , ...,  1.6695035 ,\n",
       "         1.2573043 ,  1.7414477 ],\n",
       "       [ 1.4330394 ,  0.81314987,  1.5127864 , ...,  0.8183378 ,\n",
       "         1.4762123 ,  1.9976285 ],\n",
       "       [-0.06931508,  0.8698441 , -0.78390396, ...,  0.54399264,\n",
       "         0.5348301 ,  0.50692177],\n",
       "       [-0.23306054, -0.7804317 ,  0.0060364 , ...,  0.8183377 ,\n",
       "         1.4762121 ,  1.9976285 ]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.2573043>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0][1][-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the actual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215, 512)\n",
      "(8, 343, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:29:41.285816: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:29:41.808376: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    }
   ],
   "source": [
    "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(X_emb.shape)\n",
    "print(y_emb.shape)\n",
    "print(sample_ca(X_emb, y_emb).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215, 512)\n",
      "(8, 215, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(X_emb.shape)\n",
    "print(sample_gsa(X_emb).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers[\"X\"].get_vocab_size(),\n",
    "    target_vocab_size=tokenizers[\"y\"].get_vocab_size(),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512, 59)\n"
     ]
    }
   ],
   "source": [
    "print(transformer((X_emb[0][0:10], y_emb[0][0:10]), training=False).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 215, 512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  2658432   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  4757376   \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  7611      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,423,419\n",
      "Trainable params: 7,423,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  167/10887 [..............................] - ETA: 15:46 - loss: 3.1921 - masked_accuracy: 0.2187"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb Cell 90\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# actually second epoch start, had one epoch where I then restarted\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m transformer\u001b[39m.\u001b[39;49mfit(train_batches,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 validation_data\u001b[39m=\u001b[39;49mval_batches)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# actually second epoch start, had one epoch where I then restarted\n",
    "transformer.fit(train_batches,\n",
    "                epochs=10,\n",
    "                validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-11-09-Transformer_2to2.index',\n",
       " '2022-11-09-Transformer_2to2.data-00000-of-00001',\n",
       " '2022-11-14-Transformer_upto3to3_unique_augmented.index',\n",
       " '2022-11-09-Transformer_all_except_3to3.data-00000-of-00001',\n",
       " '2022-11-09-Transformer_all_except_3to3.index',\n",
       " '2022-11-14-Transformer_upto3to3_unique_augmented.data-00000-of-00001',\n",
       " 'checkpoint']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"models/2022-11-16-BaseModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers[\"X\"].tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = self.tokenizers[\"y\"].tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    text = tokenizers[\"y\"].detokenize(output)[0]  # Shape: `()`.\n",
    "\n",
    "    tokens = tokenizers[\"y\"].lookup(output)[0]\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(tokenizers, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod 2/3 Prod i Prod e Prod gamma alpha_2 alpha_0 alpha_1 Prod A^(*) i_2 alpha_2 (p_3) Prod tt i_0 alpha_1 (p_1)_u tt^(*) i_1 alpha_0 (p_2)_u'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = X_test_final[0][0]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = tf.constant(sentence)[tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 2, 133, 2, 43, 2, 44, 2, 3, 18, 20, 19, 2, 34, 10, 18, 40, 2, 90,\n",
       "  12, 19, 31, 89, 11, 20, 72, 46]]>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers[\"X\"].tokenize(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 46]]>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers[\"X\"].tokenize([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'e 4 e e 4 s_23 e 4 s_23 s_23 e 4 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s- 2 s_23 s_24 s- 2 s_23 pow m_tt 2 mul s- 2 pow m_tt 2 mul s- 2 pow s_23 2 mul 2 pow m_tt 2 mul 2 mul s_13 pow m_tt 2 add mul s- 1 mul s_23 pow m_tt 2 mul s- 2 mul s_24 pow m_tt 2 add mul s- 2 mul s_34 pow m_tt 2 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_14 mul s_24 s_34 add mul s- 2 mul s_12 mul 2 mul s_13 mul s_23 pow m_tt 2 add mul s- 2 mul s_14 mul s_23 pow m_tt 2 add mul s- 2 mul s_24 mul s_34 pow m_tt 2 add mul 2 mul s_12 mul s_13 pow m_tt 2 add mul 4 mul s_13 mul s_24 pow m_tt 2 add mul 4 mul s_23 mul s_24 pow m_tt 2 mul s- 2 mul s_12 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s- 2 mul s_23 mul pow m_tt 2 pow m_tt 2 mul s- 2 mul s_14 mul s_24 s_34 mul 2 mul s_13 mul s_23 pow m_tt 2 add mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul 2 mul s_23 mul s_24 pow m_tt 2 add mul 4 mul s_24 mul pow m_tt 2 mul 8 mul s_13 mul s_24 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 add mul s- 2 mul s_23 mul s_24 pow m_tt 2 mul mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul mul mul s_24 mul pow m_tt 2 mul mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul mul'>,\n",
       " <tf.Tensor: shape=(351,), dtype=string, numpy=\n",
       " array([b'[START]', b'e', b'4', b'e', b'e', b'4', b's_23', b'e', b'4',\n",
       "        b's_23', b's_23', b'e', b'4', b's_23', b's_23', b's_23', b's_23',\n",
       "        b's_23', b's_23', b's_23', b's_23', b's_23', b's-', b'2', b's_23',\n",
       "        b's_24', b's-', b'2', b's_23', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'pow', b'm_tt', b'2', b'mul', b's-', b'2', b'pow',\n",
       "        b's_23', b'2', b'mul', b'2', b'pow', b'm_tt', b'2', b'mul', b'2',\n",
       "        b'mul', b's_13', b'pow', b'm_tt', b'2', b'add', b'mul', b's-',\n",
       "        b'1', b'mul', b's_23', b'pow', b'm_tt', b'2', b'mul', b's-', b'2',\n",
       "        b'mul', b's_24', b'pow', b'm_tt', b'2', b'add', b'mul', b's-',\n",
       "        b'2', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add', b'mul',\n",
       "        b's-', b'2', b'mul', b's_12', b'pow', b'm_tt', b'4', b'add',\n",
       "        b'mul', b's-', b'2', b'mul', b's_12', b'pow', b'm_tt', b'4',\n",
       "        b'add', b'mul', b's-', b'2', b'mul', b's_12', b'pow', b'm_tt',\n",
       "        b'4', b'add', b'mul', b's-', b'2', b'mul', b's_14', b'mul',\n",
       "        b's_24', b's_34', b'add', b'mul', b's-', b'2', b'mul', b's_12',\n",
       "        b'mul', b'2', b'mul', b's_13', b'mul', b's_23', b'pow', b'm_tt',\n",
       "        b'2', b'add', b'mul', b's-', b'2', b'mul', b's_14', b'mul',\n",
       "        b's_23', b'pow', b'm_tt', b'2', b'add', b'mul', b's-', b'2',\n",
       "        b'mul', b's_24', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add',\n",
       "        b'mul', b'2', b'mul', b's_12', b'mul', b's_13', b'pow', b'm_tt',\n",
       "        b'2', b'add', b'mul', b'4', b'mul', b's_13', b'mul', b's_24',\n",
       "        b'pow', b'm_tt', b'2', b'add', b'mul', b'4', b'mul', b's_23',\n",
       "        b'mul', b's_24', b'pow', b'm_tt', b'2', b'mul', b's-', b'2',\n",
       "        b'mul', b's_12', b'mul', b's_34', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'mul', b's_23', b'mul', b's-', b'2', b'mul', b's_23',\n",
       "        b'mul', b'pow', b'm_tt', b'2', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'mul', b's_14', b'mul', b's_24', b's_34', b'mul',\n",
       "        b'2', b'mul', b's_13', b'mul', b's_23', b'pow', b'm_tt', b'2',\n",
       "        b'add', b'mul', b's-', b'2', b'mul', b's_23', b'mul', b's_34',\n",
       "        b'pow', b'm_tt', b'2', b'mul', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_24', b'pow', b'm_tt', b'2', b'add', b'mul', b'4', b'mul',\n",
       "        b's_24', b'mul', b'pow', b'm_tt', b'2', b'mul', b'8', b'mul',\n",
       "        b's_13', b'mul', b's_24', b'pow', b'm_tt', b'2', b'mul', b's-',\n",
       "        b'2', b'mul', b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2',\n",
       "        b'mul', b's-', b'2', b'mul', b's_23', b'mul', b's_34', b'pow',\n",
       "        b'm_tt', b'2', b'mul', b's-', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_34', b'pow', b'm_tt', b'2', b'mul', b's-', b'2', b'mul',\n",
       "        b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add', b'mul',\n",
       "        b's-', b'2', b'mul', b's_23', b'mul', b's_24', b'pow', b'm_tt',\n",
       "        b'2', b'mul', b'mul', b's-', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_34', b'pow', b'm_tt', b'2', b'mul', b'mul', b'mul', b's_24',\n",
       "        b'mul', b'pow', b'm_tt', b'2', b'mul', b'mul', b's-', b'2', b'mul',\n",
       "        b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2', b'mul', b'mul',\n",
       "        b'mul'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1, 8, 350, 27), dtype=float32, numpy=\n",
       " array([[[[0.00609642, 0.15153041, 0.00274909, ..., 0.00150047,\n",
       "           0.00264707, 0.00269867],\n",
       "          [0.0052967 , 0.15357839, 0.00263177, ..., 0.00150018,\n",
       "           0.0025359 , 0.00258117],\n",
       "          [0.00583117, 0.15227929, 0.00294052, ..., 0.00172064,\n",
       "           0.00283237, 0.00288254],\n",
       "          ...,\n",
       "          [0.00071198, 0.16413519, 0.0008504 , ..., 0.00032842,\n",
       "           0.0008713 , 0.00086429],\n",
       "          [0.00367211, 0.15637067, 0.00249051, ..., 0.00096584,\n",
       "           0.00251631, 0.00252367],\n",
       "          [0.00371149, 0.15633078, 0.00247816, ..., 0.00087514,\n",
       "           0.00250369, 0.00251316]],\n",
       " \n",
       "         [[0.01689322, 0.04564391, 0.01104816, ..., 0.01507656,\n",
       "           0.01080301, 0.01081656],\n",
       "          [0.01653329, 0.0433283 , 0.01073942, ..., 0.01477481,\n",
       "           0.01052687, 0.01050784],\n",
       "          [0.01472505, 0.04195366, 0.00932383, ..., 0.01332293,\n",
       "           0.00910951, 0.00910464],\n",
       "          ...,\n",
       "          [0.02407413, 0.07379293, 0.02735358, ..., 0.02006663,\n",
       "           0.02821435, 0.02769257],\n",
       "          [0.03513052, 0.06600828, 0.02997538, ..., 0.02389245,\n",
       "           0.03023542, 0.03009939],\n",
       "          [0.03540717, 0.0706565 , 0.02732649, ..., 0.02055297,\n",
       "           0.02740923, 0.02735479]],\n",
       " \n",
       "         [[0.03156018, 0.03908681, 0.04538356, ..., 0.02548607,\n",
       "           0.04657719, 0.04594937],\n",
       "          [0.03203427, 0.04030607, 0.04423797, ..., 0.02376057,\n",
       "           0.04535729, 0.04479996],\n",
       "          [0.03138492, 0.04089653, 0.04405596, ..., 0.02368526,\n",
       "           0.04533069, 0.04470651],\n",
       "          ...,\n",
       "          [0.00200637, 0.15030089, 0.00340025, ..., 0.00345178,\n",
       "           0.00361168, 0.00348481],\n",
       "          [0.00241347, 0.14895354, 0.00466538, ..., 0.00517503,\n",
       "           0.00494219, 0.00476482],\n",
       "          [0.00305121, 0.14478232, 0.0066317 , ..., 0.00660914,\n",
       "           0.0070062 , 0.00676694]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.02800317, 0.06161228, 0.03855311, ..., 0.00879904,\n",
       "           0.04001163, 0.03925679],\n",
       "          [0.02902667, 0.0549776 , 0.04152768, ..., 0.00959343,\n",
       "           0.04312503, 0.04227211],\n",
       "          [0.02846494, 0.05563181, 0.04138827, ..., 0.00941592,\n",
       "           0.04301919, 0.04215685],\n",
       "          ...,\n",
       "          [0.0305258 , 0.10159979, 0.0169348 , ..., 0.01563822,\n",
       "           0.01658178, 0.01664403],\n",
       "          [0.03337456, 0.08090247, 0.02553204, ..., 0.01159193,\n",
       "           0.02564672, 0.02551835],\n",
       "          [0.03171662, 0.08374719, 0.02504459, ..., 0.01158537,\n",
       "           0.02522526, 0.02504516]],\n",
       " \n",
       "         [[0.0065423 , 0.12380715, 0.01084948, ..., 0.00715502,\n",
       "           0.0112474 , 0.01110107],\n",
       "          [0.00600183, 0.12429012, 0.01007851, ..., 0.00755378,\n",
       "           0.01041984, 0.0102808 ],\n",
       "          [0.00637528, 0.12283031, 0.0103468 , ..., 0.00792537,\n",
       "           0.01067144, 0.01053841],\n",
       "          ...,\n",
       "          [0.01100498, 0.11200484, 0.01588698, ..., 0.0079219 ,\n",
       "           0.01651807, 0.01633325],\n",
       "          [0.01936618, 0.04839056, 0.04065802, ..., 0.01538224,\n",
       "           0.04371664, 0.04267323],\n",
       "          [0.01987411, 0.0563297 , 0.03739638, ..., 0.01594159,\n",
       "           0.03978336, 0.03898437]],\n",
       " \n",
       "         [[0.00026868, 0.16225778, 0.00019936, ..., 0.0004288 ,\n",
       "           0.00019345, 0.00019469],\n",
       "          [0.00026069, 0.1609932 , 0.00018337, ..., 0.00043292,\n",
       "           0.00017718, 0.00017845],\n",
       "          [0.00032167, 0.16078234, 0.00022718, ..., 0.00052802,\n",
       "           0.00021978, 0.00022131],\n",
       "          ...,\n",
       "          [0.0003283 , 0.15093873, 0.00021811, ..., 0.00044357,\n",
       "           0.00021063, 0.00021226],\n",
       "          [0.00031746, 0.16498904, 0.00025356, ..., 0.00054208,\n",
       "           0.0002442 , 0.00024628],\n",
       "          [0.00041486, 0.16426212, 0.00035574, ..., 0.00073811,\n",
       "           0.00034445, 0.00034644]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(tf.constant(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod 2/3 Prod i Prod e Prod gamma alpha_2 alpha_0 alpha_1 Prod A^(*) i_2 alpha_2 (p_3) Prod tt i_0 alpha_1 (p_1)_u tt^(*) i_1 alpha_0 (p_2)_u'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4adc2ea131058d4ca334736eaf83f8a99f586a60b7e02773f5921bb39d3dbeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

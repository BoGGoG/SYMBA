{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model QED\n",
    "This is the base setup for working on QED data.\n",
    "It shows how to import the data and how to convert the expressions into different formats.\n",
    "\n",
    "amplitdues: prefix  \n",
    "squared amplitdues: hybrid prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    # Install the most re version of TensorFlow to use the improved\n",
    "    # masking support for `tf.keras.layers.MultiHeadAttention`.\n",
    "    !apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
    "    !pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
    "    !pip install -q tensorflow_datasets\n",
    "    !pip install -q -U tensorflow-text tensorflow\n",
    "    !pip install -q icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/SYMBA/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:49:42.753478: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 20:49:42.841313: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-30 20:49:42.860712: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-30 20:49:43.273737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-11-30 20:49:43.273805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/boggog/Documents/marty-public/marty/lib:/usr/local/lib::/home/boggog/anaconda3/lib/:/usr/local/lib:/home/boggog/anaconda3/lib/:/home/boggog/anaconda3/lib/\n",
      "2022-11-30 20:49:43.273809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "import sympy as sp\n",
    "from itertools import (takewhile,repeat)\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:49:43.969461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:49:43.973401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:49:43.973538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocessing.tree.sympy_to_tree as sp2tree\n",
    "from data_preprocessing.sympy_prefix.source.SympyPrefix import prefix_to_sympy, sympy_to_prefix, sympy_to_hybrid_prefix, hybrid_prefix_to_sympy\n",
    "from data_preprocessing.ampl_tree.source.ampl_to_tree import ampl_to_tree, raw_ampl_to_tree, expand_tree, contract_tree, subscripts_to_subtree, rename_indices, get_tree, tree_to_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preprocessing.expressions_shortener.expressions_shortener as es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This only needs to be run once, then the data is cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_i(expr_str):\n",
    "    reg_ex = \"[^a-z]i[^a-z,^\\d]\"\n",
    "    replaced = re.sub(reg_ex, fix_i_match, expr_str)\n",
    "    return replaced\n",
    "    \n",
    "def fix_i_match(matchobj):\n",
    "    \"\"\"\n",
    "    i --> I\n",
    "    \"\"\"\n",
    "    match = matchobj.group(0)\n",
    "    return match.replace(\"i\", \"I\")\n",
    "\n",
    "\n",
    "def rawincount(filename):\n",
    "    \"\"\"count numer of lines in a file. \n",
    "    From https://stackoverflow.com/questions/845058/how-to-get-line-count-of-a-large-file-cheaply-in-python\n",
    "    \"\"\"\n",
    "    f = open(filename, 'rb')\n",
    "    bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))\n",
    "    return sum( buf.count(b'\\n') for buf in bufgen )\n",
    "\n",
    "def load_raw_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading raw amplitudes from filename.\n",
    "    \n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "    \"\"\"\n",
    "    print(\"Loading amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "        ic(number_of_lines)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        ctr = 0\n",
    "        data[ctr] = line.replace(\"\\n\", \"\").split(\";\")\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                data[ctr] = line.replace(\"\\n\", \"\").split(\";\")\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_squared_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading squared amplitudes from filename and parsing into sympy.\n",
    "    All squared amplitudes should be exportet from sympy and thus be readable\n",
    "    without any preprocessing.\n",
    "\n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "\n",
    "    Returns:\n",
    "        list of squared amplitudes, each as a sympy expression\n",
    "    \"\"\"\n",
    "    print(\"Loading squared amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "        ic(number_of_lines)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "       line = f.readline()\n",
    "       line_sp = sp.sympify(line.strip())\n",
    "       ctr = 0\n",
    "       data[ctr] = line_sp\n",
    "       while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                line = line.strip()\n",
    "                line = fix_i(line)\n",
    "                line_sp = sp.sympify(line.strip())\n",
    "                data[ctr] = line_sp\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data.nosync/\"\n",
    "amplitudes_filename_start = \"QED_amplitudes_TreeLevel_\"\n",
    "sqamplitudes_filename_start = \"QED_sqamplitudes_TreeLevel_\"\n",
    "processes = [\"1to2\", \"2to1\", \"2to2\", \"2to3\", \"3to2\"]\n",
    "max_lines = -1\n",
    "\n",
    "amplitudes = []\n",
    "sqamplitudes = []\n",
    "for process in processes:\n",
    "    ampl_f = data_folder + amplitudes_filename_start + process + \"_raw\"+ \".txt\"\n",
    "    sqampl_f = data_folder + sqamplitudes_filename_start + process + \".txt\"\n",
    "    amplitudes_process = load_raw_amplitudes(ampl_f, max_lines=max_lines)\n",
    "    sqamplitudes_process = load_squared_amplitudes(sqampl_f, max_lines=max_lines)\n",
    "    amplitudes.append(amplitudes_process)\n",
    "    sqamplitudes.append(sqamplitudes_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the different amplitudes separated for now, so `amplitudes` has the form\n",
    "`[multiplicity, i]` where `multiplicity = [\"1to2\", \"2to1\", ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prod', '(', '2/3', 'i', 'e', 'gamma_{%\\\\lambda_169,%eta_137,%del_161}', 'A_{l_3,+%\\\\lambda_169}(p_3)', 'c_{i_3,%eta_137}(p_1)_u^(*)', 'c_{k_3,%del_161}(p_2)_u', ')']\n"
     ]
    }
   ],
   "source": [
    "print(amplitudes[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8*e**2*(2*m_c**2 - s_12)/9\n"
     ]
    }
   ],
   "source": [
    "print(sqamplitudes[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, sqa in zip(amplitudes, sqamplitudes):\n",
    "    assert len(a) == len(sqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(a): 431\n",
      "ic| len(sqa): 431\n",
      "ic| len(a): 431\n",
      "ic| len(sqa): 431\n",
      "ic| len(a): 10943\n",
      "ic| len(sqa): 10943\n",
      "ic| len(a): 129023\n",
      "ic| len(sqa): 129023\n",
      "ic| len(a): 129023\n",
      "ic| len(sqa): 129023\n"
     ]
    }
   ],
   "source": [
    "# the amplitudes are in prefix format\n",
    "for a, sqa in zip(amplitudes, sqamplitudes):\n",
    "    ic(len(a))\n",
    "    ic(len(sqa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only unique amplitudes\n",
    "We only want unique amplitudes, others are thrown away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_indices(amps):\n",
    "    amps = [\" \".join(a) for a in amps]\n",
    "    tmp = np.sort(np.unique(amps, return_index=True, axis=0)[1])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices = [get_unique_indices(a) for a in amplitudes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_unique_a = [[amplitudes[j][ind] for ind in unique_indices[j]] for j in range(len(amplitudes))]\n",
    "sqamplitudes_corresponding_a = [[sqamplitudes[j][ind] for ind in unique_indices[j]] for j in range(len(amplitudes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes.pickle\", \"bw\") as f:\n",
    "    pickle.dump(amplitudes_unique_a, f)\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"bw\") as f:\n",
    "    pickle.dump(sqamplitudes_corresponding_a, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Format Conversion\n",
    "We need to convert the squared amplitudes, which are sympy expressions now, into something. In this notebook we will use the prefix notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes.pickle\", \"rb\") as f:\n",
    "    amplitudes_unique = pickle.load(f)\n",
    "    # amplitudes_unique = [[a.split(\",\") for a in amps] for amps in amplitudes_unique]\n",
    "\n",
    "with open(export_folder+\"sqamplitudes.pickle\", \"rb\") as f:\n",
    "    sqamplitudes_corresponding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986683db0053428884316d67bb4917a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870e0db07f9d47a1be8681c7d1ab73ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46033fdec8c4bb685a00e7105d5c85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6d4a7597064597bd697a91a1dcb4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783f1de011ba4fa5b69c13240add9fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_mu', '2', ')'], dtype='<U4')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorten expressions with expressions_shortener\n",
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_hybrid_prefix(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sympy_to_hybrid_prefix(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_hybrid_prefix = [[try_sympy_to_hybrid_prefix(a) for a in tqdm(sq)] for sq in sqamplitudes_corresponding]\n",
    "np.array(sqampl_hybrid_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320eed7aeefc411182f25dc24c42ed72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f921f6dfc9045a5afa2faedaa132a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b649cfa200140648a1d14a545abc4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb7ca98604d4d0caad649bcb352e6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210e62557fff496f802a2e334421f3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_mu', '2', ')'], dtype='<U4')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorten expressions with expressions_shortener\n",
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_hybrid_prefix_short(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        expr_shortened = es.shorten_expression(expr)\n",
    "        return sympy_to_hybrid_prefix(expr_shortened)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_hybrid_prefix_short = [[try_sympy_to_hybrid_prefix_short(a) for a in tqdm(sq)] for sq in sqamplitudes_corresponding]\n",
    "np.array(sqampl_hybrid_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqampls_lengths = [[len(a) for a in sqampls] for sqampls in sqampl_hybrid_prefix]\n",
    "sqampls_lengths_short = [[len(a) for a in sqampls] for sqampls in sqampl_hybrid_prefix_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEGCAYAAACgt3iRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeTUlEQVR4nO3de7hWdZ338fdH8KyYCnohoGAxKlpTssdoMsfGGumI86QTVgNOToyGmTmH4GmuTs/DNamdhqfUmHREM43sIOVYOqhj5oG2pgIiSWJKMsKUKWWS6Pf54/e7ZbG5983ae+37JJ/Xda3rXut7r8N3LTb7u9f6rfVbigjMzMyq2KndCZiZWfdzMTEzs8pcTMzMrDIXEzMzq8zFxMzMKhve7gRabeTIkTF+/Ph2p2Fm1lXuvvvu/4mIUf19v8MVk/Hjx9Pb29vuNMzMuoqkXzT63pe5zMysMhcTMzOrzMXEzMwqczExM7PKXEzMzKwyFxMzM6vMxcTMzCpzMTEzs8pcTMzMrDIXk5ewlYcf0e4UzGwH4WJiZmaVuZiYmVllLiZmZlaZi4mZmVXWtGIi6VJJ6yUtL8QukPSgpPslfUfSywrfzZW0WtIqSScW4pMlLcvfzZekHN9V0jdy/C5J45u1L2Zm1lgzz0wuA6b2id0IHBURrwJ+BswFkDQJmA4cmZe5UNKwvMxFwCxgYh5q6zwdeDIiXgF8ATivaXtiZmYNNa2YRMStwK/7xG6IiM158k5gbB6fBlwdEZsiYg2wGjhG0mhgRETcEREBXA6cVFhmYR6/BjihdtZiZmat1c42k/cD1+fxMcBjhe/W5tiYPN43vtUyuUA9Bexfb0OSZknqldS7YcOGIdsBMzNL2lJMJH0M2AxcWQvVmS0axBsts20wYkFE9EREz6hR/b7C2MzMBqnlxUTSTODtwHvzpStIZxzjCrONBR7P8bF14lstI2k4sA99LquZmVlrtLSYSJoKfBR4Z0Q8U/hqMTA936E1gdTQvjQi1gEbJU3J7SEzgGsLy8zM4ycDNxWKk5mZtdDwZq1Y0lXA8cBISWuBT5Du3toVuDG3ld8ZEWdExApJi4AHSJe/ZkfE83lVZ5LuDNud1MZSa2e5BLhC0mrSGcn0Zu2LmZk11rRiEhGn1glf0mD+ecC8OvFe4Kg68WeBU6rkaGZmQ8NPwJuZWWUuJmZmVpmLiZmZVeZiYmZmlbmYmJlZZS4mZmZWmYuJmZlV5mJiZmaVuZiYmVllLiZmZlaZi4mZmVXmYmJmZpW5mJiZWWUuJmZmVpmLiZmZVeZiYmZmlbmYmJlZZS4mZmZWmYuJmZlV5mJiZmaVuZiYmVllLiZmZlaZi4mZmVXmYmJmZpU1rZhIulTSeknLC7H9JN0o6aH8uW/hu7mSVktaJenEQnyypGX5u/mSlOO7SvpGjt8laXyz9sXMzBpr5pnJZcDUPrE5wJKImAgsydNImgRMB47My1woaVhe5iJgFjAxD7V1ng48GRGvAL4AnNe0PTEzs4aaVkwi4lbg133C04CFeXwhcFIhfnVEbIqINcBq4BhJo4EREXFHRARweZ9lauu6BjihdtZiZmat1eo2kwMjYh1A/jwgx8cAjxXmW5tjY/J43/hWy0TEZuApYP+mZW5mZv3qlAb4emcU0SDeaJltVy7NktQrqXfDhg2DTNHMzPrT6mLyRL50Rf5cn+NrgXGF+cYCj+f42DrxrZaRNBzYh20vqwEQEQsioiciekaNGjVEu2JmZjUDKiaSdpI0osL2FgMz8/hM4NpCfHq+Q2sCqaF9ab4UtlHSlNweMqPPMrV1nQzclNtVrIQvn3FTu1Mws5eQ7RYTSV+XNELSnsADwCpJ/1hiuauAO4DDJK2VdDrwGeDNkh4C3pyniYgVwKK8/h8AsyPi+byqM4Gvkhrlfw5cn+OXAPtLWg2cS74zzMzMWm94iXkmRcTTkt4L/AfwUeBu4IJGC0XEqf18dUI/888D5tWJ9wJH1Yk/C5zSOHUzM2uFMpe5dpa0M+mW3Gsj4jn6aeg2M7MdU5li8hXgEWBP4FZJhwBPNzMpMzPrLtu9zBUR84H5hdAvJL2xeSmZmVm3KdMAf6CkSyRdn6cnseUuKjMzs1KXuS4DfggclKd/BpzTpHzMzKwLlSkmIyNiEfACvNh1yfONFzEzsx1JmWLyO0n7k+/gkjSF1A+WmZkZUO45k3NJT5u/XNKPgVGkJ87NzMyAcndz3SPpz4DDSJ0rrsrPmpiZmQHl7uaaDewVESsiYjmwl6QPNj81MzPrFmXaTD4QEb+pTUTEk8AHmpaRmZl1nTLFZKfiGwzz63R3aV5KZmbWbco0wP8QWCTpYtIdXWeQevY1MzMDyhWTjwJ/R+oKXsANpC7hzczMgHJ3c70AXJQHMzOzbWy3mEh6PfBJ4JA8v4CIiEObm5qZmXWLMpe5LgE+QnohlrtRMTOzbZQpJk9FxPXbn83MzHZUZYrJzZIuAL4NbKoFI+KepmVlZmZdpUwxeW3+7CnEAvjzoU/HzMy6UZm7ufxWRTMza6jMmQmS3gYcCexWi0XEp5uVlJmZdZcyHT1eDLwb+BDptuBTSLcJm5mZAeX65vrTiJgBPBkRnwJeB4xrblpmZtZNyhSTZ/PnM5IOAp4DJlTZqKSPSFohabmkqyTtJmk/STdKeih/7luYf66k1ZJWSTqxEJ8saVn+bn6xQ0ozM2udMsXke5JeBlwA3AM8Alw12A1KGgOcDfRExFHAMGA6MAdYEhETgSV5GkmT8vdHAlOBC3PPxZC6eJkFTMzD1MHmZWZmg9ewmEjaifQL/jcR8S1SW8nhEfHxitsdDuwuaTiwB/A4MA1YmL9fCJyUx6cBV0fEpohYA6wGjpE0GhgREXdERACXF5YxM7MWalhMciePnytMb4qIp6psMCJ+CXwWeBRYR3rC/gbgwIhYl+dZBxyQFxkDPFZYxdocG5PH+8bNzKzFylzmukHSu4aqPSK3hUwjtbscBOwp6X2NFqkTiwbxetucJalXUu+GDRsGmrKZmW1HmWJyLvBNYJOkpyVtlPR0hW2+CVgTERsi4jlSNy1/CjyRL12RP9fn+dey9d1jY0mXxdbm8b7xbUTEgojoiYieUaNGVUjdzMzq2W4xiYi9I2KniNglIkbk6REVtvkoMEXSHvls5wRgJbAYmJnnmQlcm8cXA9Ml7SppAqmhfWm+FLZR0pS8nhmFZczMrIXKvM/kuHrxiLh1MBuMiLskXUO6M2wz8FNgAbAX6fXAp5MKzil5/hWSFgEP5PlnR0StK/wzgcuA3YHr82BmZi1WpjuVfyyM7wYcQ3q3yaA7eoyITwCf6BPeRDpLqTf/PGBenXgvcNRg8zAzs6FRpqPHdxSnJY0Dzm9aRmZm1nXKNMD3tRafDZiZWUGZNpP/x5ZbbncCXg3c18SczMysy5RpM+ktjG8GroqIHzcpHzMz60Jlisk1wLO1O6gkDZO0R0Q809zUzMysW5RpM1lCuvW2ZnfgP5uTjpmZdaMyxWS3iPhtbSKP79G8lMzMrNuUKSa/k3R0bULSZOD3zUvJzMy6TZk2k3OAb0qq9Xs1mvQaXzMzM6DcQ4s/kXQ4cBipp94HcweNZmZmQInLXJJmA3tGxPKIWAbsJemDzU/NzMy6RZk2kw9ExG9qExHxJPCBpmVkZmZdp0wx2an4Yqz8/vVdmpeSmZl1mzIN8D8kdQ1/MalblTOAHzQ1KzMz6yplislHgb8jvTtEwA3AV5uZlJmZdZcyd3O9IOkS4DbSmcmqwsuprMOsPPwIjnhwZbvTMLMdTJleg48HFgKPkM5MxkmaOdg3LZqZ2UtPmctcnwP+IiJWAUj6I+AqYHIzEzMzs+5R5m6unWuFBCAifgbs3LyUzMys25R6n0luM7kiT7+X9A54MzMzoFwxOROYDZxNajO5FbiwmUmZmVl3KXM31ybg83kwMzPbRpk2EzMzs4ZcTMzMrLJ+i4mkK/Lnh4d6o5JeJukaSQ9KWinpdZL2k3SjpIfy576F+edKWi1plaQTC/HJkpbl7+YX+xAzM7PWaXRmMlnSIcD7Je2bf9m/OFTc7r8CP4iIw4E/BlYCc4AlETGR9N75OQCSJgHTgSOBqcCFubNJgIuAWcDEPEytmJeZmQ1Cowb4i0kdOh5KuhW4+Fd/5PiASRoBHAecBhARfwD+IGkacHyebSFwC6lfsGnA1flGgDWSVgPHSHoEGBERd+T1Xg6cBFw/mLzMzGzw+j0ziYj5EXEEcGlEHBoREwrDoApJdiiwAfh3ST+V9FVJewIHRsS6vO11wAF5/jHAY4Xl1+bYmDzeN25mZi223Qb4iDhT0h9LOisPr6q4zeHA0cBFEfEa4HfkS1r9qNcOEg3i265AmiWpV1Lvhg0bBpqvmZltR5nX9p4NXEk6UzgAuFLShypscy2wNiLuytPXkIrLE5JG522OBtYX5h9XWH4s8HiOj60T30ZELIiInojoGTVqVIXUzcysnjK3Bv8t8NqI+HhEfByYQoXX9kbEfwOPSTosh04AHgAWAzNzbCZwbR5fDEyXtKukCaSG9qX5UthGSVPyXVwzCsuYmVkLlelORUDx/SXPU/8S00B8iHSGswvwMPA3pMK2SNLpwKPAKQARsULSIlLB2QzMLrxP5UzgMmB3UsO7G9/NzNqgTDH5d+AuSd/J0ycBl1TZaETcC/TU+eqEfuafB8yrE+8FjqqSi5mZVVemb67PS7oFOJZ0RvI3EfHTZidmZmbdo8yZCRFxD3BPk3MxM7Mu5b65zMysMhcTMzOrrGExkTRM0n+2KhkzM+tODYtJvgX3GUn7tCgfa2Dl4Ue0OwUzs7rKNMA/CyyTdCOp6xMAIuLspmVlZmZdpUwxuS4PZmZmdZV5zmShpN2BgyNiVQtyMjOzLlOmo8d3APeS3m2CpFdLWtzkvMzMrIuUuTX4k8AxwG/gxa5QJjQtIzMz6zplisnmiHiqT6zue0PMzGzHVKYBfrmk9wDDJE0EzgZub25aZmbWTcqcmXwIOBLYBFwFPA2c08SczMysy5S5m+sZ4GOSzkuTsbH5aZmZWTcpczfXn0haBtxPenjxPkmTm5/ajsVPt5tZNyvTZnIJ8MGI+BGApGNJL8x6VTMTMzOz7lGmzWRjrZAARMRtgC91NZHPUsys2/R7ZiLp6Dy6VNJXSI3vAbwbuKX5qZmZWbdodJnrc32mP1EY93MmZmb2on6LSUS8sZWJmJlZ99puA7yklwEzgPHF+d0FvZmZ1ZS5m+s/gDuBZcALzU3HzMy6UZlisltEnNv0TMzMrGuVuTX4CkkfkDRa0n61oemZmZlZ1yhTTP4AXADcAdydh96qG5Y0TNJPJX0/T+8n6UZJD+XPfQvzzpW0WtIqSScW4pMlLcvfzZekqnmZmdnAlSkm5wKviIjxETEhD4cOwbY/DKwsTM8BlkTERGBJnkbSJGA6qbPJqcCFkoblZS4CZgET8zB1CPIyM7MBKlNMVgDPDOVGJY0F3gZ8tRCeBizM4wuBkwrxqyNiU0SsAVYDx0gaDYyIiDsiIoDLC8uYmVkLlWmAfx64V9LNpG7ogcq3Bn8R+Cdg70LswIhYl9e9TtIBOT6GdDdZzdocey6P941vQ9Is0hkMBx98cIW0zcysnjLF5Lt5GBKS3g6sj4i7JR1fZpE6sWgQ3zYYsQBYANDT0+On983MhliZ95ks3N48A/R64J2S3grsBoyQ9DXgCUmj81nJaGB9nn8tMK6w/Fjg8RwfWyduZmYtVuZ9JmskPdx3GOwGI2JuRIyNiPGkhvWbIuJ9wGJgZp5tJnBtHl8MTJe0q6QJpIb2pfmS2EZJU/JdXDMKy5iZWQuVuczVUxjfDTgFaMZzJp8BFkk6HXg0b4eIWCFpEfAAsBmYHRHP52XOBC4Ddgeuz4OZmbVYmctcv+oT+qKk24CPV914RNxC7s4+b+eEfuabB8yrE+8Fjqqah5mZVVOmo8ejC5M7kc5U9u5ndjMz2wGVec7kc4XhX4DJwF81MynbohVvXfzyGTc1fRtm9tJW5jKX32tiZmYNlbnMtSvwLrZ9n8mnm5eWmZl1kzJ3c10LPEXq4HHTduY1M7MdUJliMjYi3IFiB1t5+BEc8eDK7c9oZtYkZRrgb5f0yqZnYmZmXavMmcmxwGmS1pAucwmIiHhVUzMzM7OuUaaYvKXpWVhH+vIZNzH74j9vdxpm1gXK3Br8i1YkYmZm3atMm4mZmVlDLiYVvHLhwO9L8NPmZvZS5GJiZmaVuZiYmVllLiZmZlaZi4mZmVXmYmJmZpW5mJiZWWUuJmZmVpmLiZmZVeZiYmZmlbmYmJlZZS4mZmZWmYuJmZlV1vJiImmcpJslrZS0QtKHc3w/STdKeih/7ltYZq6k1ZJWSTqxEJ8saVn+br4ktXp/zMysPWcmm4G/j4gjgCnAbEmTgDnAkoiYCCzJ0+TvpgNHAlOBCyUNy+u6CJgFTMyD31VvZtYGLS8mEbEuIu7J4xuBlcAYYBqwMM+2EDgpj08Dro6ITRGxBlgNHCNpNDAiIu6IiAAuLyxjZmYt1NY2E0njgdcAdwEHRsQ6SAUHOCDPNgZ4rLDY2hwbk8f7xuttZ5akXkm9GzZsGNJ9MDOzNhYTSXsB3wLOiYinG81aJxYN4tsGIxZERE9E9IwaNWrgyZqZWUNtKSaSdiYVkisj4ts5/ES+dEX+XJ/ja4FxhcXHAo/n+Ng6cTMza7F23M0l4BJgZUR8vvDVYmBmHp8JXFuIT5e0q6QJpIb2pflS2EZJU/I6ZxSWMTOzFhrehm2+HvhrYJmke3PsfwOfARZJOh14FDgFICJWSFoEPEC6E2x2RDyflzsTuAzYHbg+D2Zm1mItLyYRcRv12zsATuhnmXnAvDrxXuCoocvOzMwGw0/Am5lZZS4mXWrl4Ue0OwUzsxe5mJiZWWUuJmZmVpmLiZmZVeZi0gJfPuOmdqdgZtZULiZt1ImN6C58ZjYYLiZmZlaZi4mZmVXmYmJmZpW5mJiZWWUuJmZmVpmLiZmZVeZiYmZmlbmYmJlZZS4mZmZWmYuJmZlV5mIyRF658JXtTsHMrG1cTMzMrDIXEzMzq8zFxIaMexw223G5mDSB20/MbEfjYmJmZpW5mFgpvoRlZo10fTGRNFXSKkmrJc1pdz47GhcZM4MuLyaShgFfBt4CTAJOlTSpWdsbP+e6Zq3azKyrdXUxAY4BVkfEwxHxB+BqYFqbczIz2+EoItqdw6BJOhmYGhF/m6f/GnhtRJzVZ75ZwKw8eRiwaoCbGgn8T8V0W6nb8oXuy7nb8oXuy9n5Nt9Acj4kIkb19+XwocmnbVQntk11jIgFwIJBb0TqjYiewS7fat2WL3Rfzt2WL3Rfzs63+YYy526/zLUWGFeYHgs83qZczMx2WN1eTH4CTJQ0QdIuwHRgcZtzMjPb4XT1Za6I2CzpLOCHwDDg0ohY0YRNDfoSWZt0W77QfTl3W77QfTk73+Ybspy7ugHezMw6Q7df5jIzsw7gYmJmZpW5mDTQqV21SBon6WZJKyWtkPThHP+kpF9KujcPby0sMzfvxypJJ7Yh50ckLct59ebYfpJulPRQ/ty3E/KVdFjhGN4r6WlJ53Ta8ZV0qaT1kpYXYgM+ppIm53+b1ZLmS6p3y32z8r1A0oOS7pf0HUkvy/Hxkn5fONYXtzrfBjkP+Oegzcf4G4VcH5F0b44P7TGOCA91BlKD/s+BQ4FdgPuASe3OK+c2Gjg6j+8N/IzUncwngX+oM/+knP+uwIS8X8NanPMjwMg+sfOBOXl8DnBep+Tb5+fgv4FDOu34AscBRwPLqxxTYCnwOtJzW9cDb2lhvn8BDM/j5xXyHV+cr896WpJvg5wH/HPQzmPc5/vPAR9vxjH2mUn/OrarlohYFxH35PGNwEpgTINFpgFXR8SmiFgDrCbtX7tNAxbm8YXASYV4p+R7AvDziPhFg3nakm9E3Ar8uk4upY+ppNHAiIi4I9JvkcsLyzQ934i4ISI258k7Sc+K9auV+eb86h3j/nTkMa7JZxd/BVzVaB2DzdfFpH9jgMcK02tp/Au7LSSNB14D3JVDZ+VLBpcWLnF0wr4EcIOku5W6twE4MCLWQSqQwAE53gn51kxn6/98nXp8awZ6TMfk8b7xdng/6a/gmgmSfirpvyS9Icc6Jd+B/Bx0Ss5vAJ6IiIcKsSE7xi4m/SvVVUs7SdoL+BZwTkQ8DVwEvBx4NbCOdEoLnbEvr4+Io0k9PM+WdFyDeTshX5QehH0n8M0c6uTjuz395dgRuUv6GLAZuDKH1gEHR8RrgHOBr0saQWfkO9Cfg07IGeBUtv7DaEiPsYtJ/zq6qxZJO5MKyZUR8W2AiHgiIp6PiBeAf2PLpZa270tEPJ4/1wPfybk9kU+pa6fW6/Psbc83ewtwT0Q8AZ19fAsGekzXsvWlpZbnLmkm8HbgvfmyCvlS0a/y+N2k9oc/6oR8B/Fz0PacJQ0H/hfwjVpsqI+xi0n/Orarlnzt8xJgZUR8vhAfXZjtL4HaHR2LgemSdpU0AZhIamBrVb57Stq7Nk5qdF2e85qZZ5sJXNsJ+RZs9Zdcpx7fPgZ0TPOlsI2SpuSfqxmFZZpO0lTgo8A7I+KZQnyU0vuKkHRozvfhdueb8xnQz0En5Ay8CXgwIl68fDXkx7gZdxS8VAbgraQ7pX4OfKzd+RTyOpZ02nk/cG8e3gpcASzL8cXA6MIyH8v7sYom3v3ST76Hku5yuQ9YUTuWwP7AEuCh/LlfJ+Sbt78H8Ctgn0Kso44vqdCtA54j/TV5+mCOKdBD+oX4c+BL5J4xWpTvalI7Q+3n+OI877vyz8p9wD3AO1qdb4OcB/xz0M5jnOOXAWf0mXdIj7G7UzEzs8p8mcvMzCpzMTEzs8pcTMzMrDIXEzMzq8zFxMzMKnMxMetD0mmSvpTHz5A0oxA/aBDre0TSyAHMf46kPUrM99uB5lJinQPKteQ6x0t6T2H6xeNrLx0uJmYNRMTFEXF5njwNGHAxGYRzSM+5vFSMB96zvZmsu7mYWMfIT8pfJ+k+ScslvTvHpyq98+K2/G6F7+f4MZJuzx3V3S7psBw/TdJ3JX1P0hpJZ0k6N893p6T98ny3SPpiXna5pG16+lV6d8U/SDqZ9CDXlUrvfti9+Fe8pB5Jt+Tx/SXdkLf3FQp9HUl6n6SleR1fqT2BXPj+bFLBulnSzTl2qtK7JZZLOq9OjiMl3SHpbfmp5m9J+kkeXl/Yj0vzPj+ct7O9f4+6uUr6raR5+d/pTkkH5vjL8/RPJH26cOb0GeANeT0fybGDJP1A6b0r528vF+sCrXhS14OHMgPpidx/K0zvA+xGekJ6IumX8iLg+/n7EWx5F8abgG/l8dNIT1bvDYwCniI//Qt8gdQxJsAtte2R3gOxvLD8l/L4J8nvrsjz9xTye4T8jhZSobklj89nyzsj3kbqrWAkcATwPWDn/N2FwIw6x6G43oOAR/N+DAduAk7K3/0WOJDUY/Sbc+zrwLF5/GBSlzu1/bid9K6NkaSn+3fub9uNcs378448fj7wz3n8+8CpefwM4Ld5/Pjav1nh+D5c+Pf9BTCu3T9/HqoNwzHrHMuAz+a/vr8fET+S9GpgTeRusyV9Dah1Yb8PsFDSRNIvuJ0L67o50rteNkp6ivSLsbaNVxXmuwrSeyAkjVB+019Fx5E61SMirpP0ZI6fAEwGfpK6PGJ3tnTE2J8/IRWpDQCSrszr/y5pf5cAsyPiv/L8bwImacuL8UYo94sGXBcRm4BNktaTClGxq/GiRrn+gVQ4AO4G3pzHX8eW9158Hfhsg/1aEhFP5X16gPTysccazG8dzsXEOkZE/EzSZFI/Y/8i6QZS30f99fnzf0hF4y+V3utyS+G7TYXxFwrTL7D1z33fdQ+kf6HNbLlUvFuJ9QhYGBFzB7CNRq9L3Uz6ZX4iUCsmOwGvi4jfb7WSVBCKx+R5Gv//b5TrcxFR27/trac/A8nFuoDbTKxj5DulnomIr5H+qj0aeJD0Ap+X59lOLSyyD/DLPH7aIDdba5c5Fniq9tdyPzaSLp3VPEL66x3SJbqaW4H35vW+Bai9PGkJcLKkA/J3+0k6ZDvbuQv4s9wuMoy0/7XCEaQXSh0uaU6O3QCcVVtRPrMbjLK5Ft3JluMwvRDve9zsJcjFxDrJK4Glku4l9b76fyPiWdJlresk3Ua6vl5zPukM5sekd7UPxpOSbgcuJvUI28hlwMW1BnjgU8C/SvoR6a/rmk8Bx0m6h9Td/qMAEfEA8M+kN07eD9wIFLszr1kAXC/p5kjdgc8Fbib37hoRL3YHHhHPk35xv1HSB4GzgR6ltwA+QGq7GLAB5Fp0DnCupKV53lphvh/YnBvsP9Lfwtbd3GuwdRVJx5MaxN8+BOu6Ja+rt+q6DJSejfl9RISk6aTG+Gntzstaw9cpzWyoTAa+pNRA8xvSJTjbQfjMxMzMKnObiZmZVeZiYmZmlbmYmJlZZS4mZmZWmYuJmZlV9v8B6iZNWKjLxN4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths_short, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f47bb70b78464fae36cb81def6d995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3b9b066cc44f23815132dd73a942fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0b94c4607d421d8a6513f793fb4958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe60067ef86640a9b10fd8f938b1af98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3e2a01749845e5a4393fc43aba44e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert amplitudes to prefix\n",
    "amplitudes_tree = [[raw_ampl_to_tree(a, needs_split=False) for a in tqdm(aa)] for aa in amplitudes_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Prod                                                 \n",
      " ┌───┬───┬─────────────────┬────────────────────────┼────────────────────┬───────────────────┐           \n",
      " │   │   │               gamma                    A^(*)                 mu_u              mu_u^(*)      \n",
      " │   │   │       ┌─────────┼────────┐      ┌────────┼────────┐    ┌──────┼───────┐    ┌──────┼───────┐   \n",
      " -1  i   e  %lambda_167 %eta_137 %gam_155 %l_3 %lambda_167 (p_3) %i_3 %gam_155 (p_1) %k_3 %eta_137 (p_2)\n",
      "\n",
      "                                               Prod                                                \n",
      " ┌────┬───┬──────────────┬──────────────────────┼───────────────────┬───────────────────┐           \n",
      " │    │   │            gamma                  A^(*)                b_u               b_u^(*)       \n",
      " │    │   │     ┌────────┼────────┐      ┌──────┼───────┐    ┌──────┼───────┐    ┌──────┼───────┐   \n",
      "-1/3  i   e  %tau_111 %del_171 %del_172 %l_3 %tau_111 (p_3) %i_3 %del_172 (p_1) %k_3 %del_171 (p_2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amplitudes_tree[0][0].pretty_print(unicodelines=True)\n",
    "amplitudes_tree[0][-10].pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_prefix = [[tree_to_prefix(t, hybrid=False) for t in tqdm(tt)] for tt in amplitudes_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(export_folder+\"amplitudes_prefix.pickle\", \"bw\") as f:\n",
    "#     pickle.dump(amplitudes_prefix, f)\n",
    "with open(export_folder+\"sqampl_hybrid_prefix_short.pickle\", \"bw\") as f:\n",
    "    pickle.dump(sqampl_hybrid_prefix_short, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reloading converted amplitudes and squared amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"amplitudes_prefix.pickle\", \"br\") as f:\n",
    "    amplitudes_prefix = pickle.load(f)\n",
    "with open(export_folder+\"sqampl_hybrid_prefix_short.pickle\", \"br\") as f:\n",
    "    sqampl_hybrid_prefix_short = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prod', '-1', 'Prod', 'i', 'Prod', 'e', 'Prod', 'gamma', '%lambda_167', '%eta_137', '%gam_155', 'Prod', 'A^(*)', '%l_3', '%lambda_167', '(p_3)', 'Prod', 'mu_u', '%i_3', '%gam_155', '(p_1)', 'mu_u^(*)', '%k_3', '%eta_137', '(p_2)']\n",
      "['Prod', '-1/3', 'Prod', 'i', 'Prod', 'e', 'Prod', 'gamma', '%tau_111', '%del_171', '%del_172', 'Prod', 'A^(*)', '%l_3', '%tau_111', '(p_3)', 'Prod', 'b_u', '%i_3', '%del_172', '(p_1)', 'b_u^(*)', '%k_3', '%del_171', '(p_2)']\n"
     ]
    }
   ],
   "source": [
    "print(amplitudes_prefix[0][0])\n",
    "print(amplitudes_prefix[0][-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mul(', 's-', '4', 'pow', 'e', '2', 'add', 'mul', 's-', '1', 's_12', 'mul', '2', 'm2mu', ')']\n",
      "['mul(', 'mul', 's-', '4', 'pow', '9', 's-', '1', 'pow', 'e', '2', 'add', 'mul', 's-', '1', 's_12', 'mul', '2', 'm2b', ')']\n"
     ]
    }
   ],
   "source": [
    "print(sqampl_hybrid_prefix_short[0][0])\n",
    "print(sqampl_hybrid_prefix_short[0][-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampls_lengths = [[len(a) for a in ampls] for ampls in amplitudes_prefix]\n",
    "sqampls_lengths_short = [[len(a) for a in sqampls] for sqampls in sqampl_hybrid_prefix_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ampls_lengths, bins=100,);\n",
    "plt.xlabel(\"amplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of occurances')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sqampls_lengths_short, bins=100,);\n",
    "plt.xlabel(\"sqamplitude token length\")\n",
    "plt.ylabel(\"number of occurances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have a maximal sequence length of 350.\n",
    "Let's do a train-test split and then filter out the too long amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(len(amplitudes_prefix)):\n",
    "    X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(amplitudes_prefix[i], sqampl_hybrid_prefix_short[i],\n",
    "        test_size=0.1, random_state=42)\n",
    "    X_train.append(X_train_tmp)\n",
    "    y_train.append(y_train_tmp)\n",
    "    X_test.append(X_test_tmp)\n",
    "    y_test.append(y_test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(export_folder+\"X_train_a_prefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(export_folder+\"y_train_a_prefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open(export_folder+\"X_test_a_prefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open(export_folder+\"y_test_a_prefix_sqa_hprefix.pickle\", \"bw\") as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "with open(export_folder+\"X_train_a_prefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(export_folder+\"y_train_a_prefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(export_folder+\"X_test_a_prefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(export_folder+\"y_test_a_prefix_sqa_hprefix.pickle\", \"br\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use those X,y where both are at most `sequence_length` long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_long(X, y, idxs_okay_export, max_seq_len=350, idxs_okay=None):\n",
    "    \"\"\"\n",
    "    find indices where X and y are less than `max_seq_len` long.\n",
    "    Append to `idxs_okay_export`.\n",
    "    \"\"\"\n",
    "    if idxs_okay is None:\n",
    "        X_idxs_ok = np.where([len(x) < max_seq_len for x in X])[0]\n",
    "        y_idxs_ok = np.where([len(y) < max_seq_len for y in y])[0]\n",
    "        idxs_okay = np.intersect1d(X_idxs_ok, y_idxs_ok) \n",
    "    idxs_okay_export.append(idxs_okay)\n",
    "    X_new = [X[i] for i in idxs_okay]\n",
    "    y_new = [y[i] for i in idxs_okay]\n",
    "    return X_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "max_seq_len = 350\n",
    "batch_size = 1\n",
    "\n",
    "idxs_train_okay_export = []\n",
    "X_train_filtered, y_train_filtered = [], []\n",
    "for i in range(len(X_train)):\n",
    "    X_train_filtered_tmp, y_train_filtered_tmp = remove_too_long(\n",
    "        X_train[i], y_train[i], idxs_train_okay_export, max_seq_len=max_seq_len)\n",
    "    X_train_filtered.append(X_train_filtered_tmp)\n",
    "    y_train_filtered.append(y_train_filtered_tmp)\n",
    "\n",
    "idxs_test_okay_export = []\n",
    "X_test_filtered, y_test_filtered = [], []\n",
    "for i in range(len(X_test)):\n",
    "    X_test_filtered_tmp, y_test_filtered_tmp = remove_too_long(\n",
    "        X_test[i], y_test[i], idxs_test_okay_export, max_seq_len=max_seq_len)\n",
    "    X_test_filtered.append(X_test_filtered_tmp)\n",
    "    y_test_filtered.append(y_test_filtered_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.91396124, 0.91325172])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of amplitudes kept depending on process (1to1, 1to2, ...)\n",
    "np.array([len(idx) for idx in idxs_train_okay_export]) / np.array([len(idx) for idx in X_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9159737613232385"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of all amplitudes that are kept (not too long)\n",
    "np.sum([len(idx) for idx in idxs_train_okay_export]) / np.sum([len(idx) for idx in X_train]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_filtered)):\n",
    "    assert len(X_train_filtered[i]) == len(y_train_filtered[i])\n",
    "\n",
    "for i in range(len(X_test_filtered)):\n",
    "    assert len(X_test_filtered[i]) == len(y_test_filtered[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = [[\" \".join(x) for x in X] for X in X_train_filtered]\n",
    "y_train_final = [[\" \".join(yy) for yy in y] for y in y_train_filtered]\n",
    "\n",
    "X_test_final = [[\" \".join(x) for x in X] for X in X_test_filtered]\n",
    "y_test_final = [[\" \".join(yy) for yy in y] for y in y_test_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prod', '-1', 'Prod', 'i', 'Prod', 'e', 'Prod', 'gamma', '%lambda_167', '%eta_137', '%del_155', 'Prod', 'A', '%l_3', '%lambda_167', '(p_3)', 'Prod', 'mu_u^(*)', '%i_3', '%eta_137', '(p_1)', 'mu_u', '%k_3', '%del_155', '(p_2)']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mul(', 's-', '2', 'pow', 'e', '2', 'add', 'mul', 's-', '1', 's_12', 'mul', '2', 'm2mu', ')']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset, Data Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_folder = \"../data.nosync/BaseModelDataCache/\"\n",
    "\n",
    "vocab_size = 500\n",
    "max_seq_len = 350\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "# reading to sympy takes quite long.\n",
    "# We're here caching the alreaday converted amplitudes\n",
    "X_train_cache_file = export_folder+\"X_train_final_Xp_yhp.pickle\"\n",
    "y_train_cache_file = export_folder+\"y_train_final_Xp_yhp.pickle\"\n",
    "X_test_cache_file = export_folder+\"X_test_final_Xp_yhp.pickle\"\n",
    "y_test_cache_file = export_folder+\"y_test_final_Xp_yhp.pickle\"\n",
    "\n",
    "if os.path.exists(X_train_cache_file) & os.path.exists(y_train_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        X_train_final = pickle.load(f)\n",
    "    with open(y_train_cache_file, \"rb\") as f:\n",
    "        y_train_final = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_train_final, f)\n",
    "    with open(y_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_train_final, f)\n",
    "\n",
    "if os.path.exists(X_test_cache_file) & os.path.exists(y_test_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        X_test_final = pickle.load(f)\n",
    "    with open(y_test_cache_file, \"rb\") as f:\n",
    "        y_test_final = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_test_final, f)\n",
    "    with open(y_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_test_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod -1/3 Prod i Prod e Prod gamma %nu_92 %gam_161 %del_167 Prod A %l_3 %nu_92 (p_3) Prod d_u^(*) %i_3 %gam_161 (p_1) d_v %k_3 %del_167 (p_2)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mul( mul 4 pow 9 s- 1 pow e 2 add s_12 mul 2 m2d )'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "X_train_all = flatten(X_train_final)\n",
    "y_train_all = flatten(y_train_final) \n",
    "\n",
    "X_test_all = flatten(X_test_final)\n",
    "y_test_all = flatten(y_test_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ds, ds_size, train_split=0.9, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split>=0) & (train_split<=1)\n",
    "    # test_split = 1 - train_split\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    train_ds = ds.take(train_size)    \n",
    "    test_ds = ds.skip(train_size)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 15:49:35.050526: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 15:49:35.051317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 15:49:35.051492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 15:49:35.051558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 15:49:35.516411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 15:49:35.517500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 15:49:35.517653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 15:49:35.517767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6019 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "df_train = tf.data.Dataset.from_tensor_slices((X_train_all, y_train_all)).prefetch(2)\n",
    "df_test = tf.data.Dataset.from_tensor_slices((X_test_all, y_test_all)).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train, df_train.cardinality().numpy(), train_split=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| df_val.cardinality().numpy(): 2110\n",
      "ic| df_train.cardinality().numpy(): 103384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9795906523253115>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(df_val.cardinality().numpy())\n",
    "ic(df_train.cardinality().numpy())\n",
    "1 - df_val.cardinality() / df_train.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplitudes:\n",
      "b'Prod -1 Prod i Prod Pow e 3 Prod Pow Sum Pow m_mu 2 Sum s_11 Sum Prod -2 s_14 reg_prop -1 Prod Pow Sum s_11 Sum Prod 2 s_12 Sum Prod -2 s_14 Sum s_22 Sum Prod -2 s_24 reg_prop -1 Sum Prod m_mu Prod gamma %lambda_364 %eta_591 %eta_479 Prod gamma %lambda_366 %eta_478 %eta_591 Prod gamma %lambda_366 %eta_481 %eps_106 Prod A^(*) %l_3 %lambda_364 (p_3) Prod mu_u^(*) %i_3 %eta_481 (p_1) Prod mu_u^(*) %k_3 %eta_478 (p_2) Prod mu_u %j_5 %eps_106 (p_4) mu_u %k_5 %eta_479 (p_5) Sum Prod p_1 %nu_165 Prod gamma %nu_165 %eta_592 %eta_593 Prod gamma %lambda_364 %eta_593 %eta_493 Prod gamma %lambda_366 %eta_492 %eta_592 Prod gamma %lambda_366 %eta_496 %eps_109 Prod A^(*) %l_3 %lambda_364 (p_3) Prod mu_u^(*) %i_3 %eta_496 (p_1) Prod mu_u^(*) %k_3 %eta_492 (p_2) Prod mu_u %j_5 %eps_109 (p_4) mu_u %k_5 %eta_493 (p_5) Sum Prod p_2 %nu_165 Prod gamma %nu_165 %eta_594 %eta_595 Prod gamma %lambda_364 %eta_595 %eta_498 Prod gamma %lambda_366 %eta_497 %eta_594 Prod gamma %lambda_366 %eta_501 %eps_110 Prod A^(*) %l_3 %lambda_364 (p_3) Prod mu_u^(*) %i_3 %eta_501 (p_1) Prod mu_u^(*) %k_3 %eta_497 (p_2) Prod mu_u %j_5 %eps_110 (p_4) mu_u %k_5 %eta_498 (p_5) Prod -1 Prod p_4 %nu_165 Prod gamma %nu_165 %eta_596 %eta_597 Prod gamma %lambda_364 %eta_597 %eta_503 Prod gamma %lambda_366 %eta_502 %eta_596 Prod gamma %lambda_366 %eta_506 %eps_111 Prod A^(*) %l_3 %lambda_364 (p_3) Prod mu_u^(*) %i_3 %eta_506 (p_1) Prod mu_u^(*) %k_3 %eta_502 (p_2) Prod mu_u %j_5 %eps_111 (p_4) mu_u %k_5 %eta_503 (p_5)'\n",
      "b'Prod -1/27 Prod i Prod Pow e 3 Prod Pow Sum s_22 Sum Prod 2 s_23 Sum Prod -2 s_24 Sum s_33 Sum Prod -2 s_34 Sum s_44 reg_prop -1 Prod Pow Sum Pow m_s 2 Sum Prod -1 s_22 Sum Prod -2 s_23 Sum Prod -1 s_33 Prod -1 reg_prop -1 Sum Prod m_s Prod gamma %rho_579 %eta_1340 %eta_1341 Prod gamma %rho_579 %eta_1447 %eps_210 Prod gamma %lambda_480 %eta_1342 %eta_1447 Prod A^(*) %l_3 %lambda_480 (p_3) Prod s_u^(*) %i_3 %eta_1340 (p_1) Prod s_u^(*) %k_3 %eta_1342 (p_2) Prod s_u %j_5 %eps_210 (p_4) s_u %k_5 %eta_1341 (p_5) Sum Prod p_2 %nu_265 Prod gamma %nu_265 %eta_1448 %eta_1449 Prod gamma %rho_579 %eta_1357 %eta_1358 Prod gamma %rho_579 %eta_1449 %eps_213 Prod gamma %lambda_480 %eta_1354 %eta_1448 Prod A^(*) %l_3 %lambda_480 (p_3) Prod s_u^(*) %i_3 %eta_1357 (p_1) Prod s_u^(*) %k_3 %eta_1354 (p_2) Prod s_u %j_5 %eps_213 (p_4) s_u %k_5 %eta_1358 (p_5) Prod p_3 %nu_265 Prod gamma %nu_265 %eta_1450 %eta_1451 Prod gamma %rho_579 %eta_1362 %eta_1363 Prod gamma %rho_579 %eta_1451 %eps_214 Prod gamma %lambda_480 %eta_1359 %eta_1450 Prod A^(*) %l_3 %lambda_480 (p_3) Prod s_u^(*) %i_3 %eta_1362 (p_1) Prod s_u^(*) %k_3 %eta_1359 (p_2) Prod s_u %j_5 %eps_214 (p_4) s_u %k_5 %eta_1363 (p_5)'\n",
      "b'Prod -1 Prod i Prod Pow e 3 Prod Pow Sum Pow m_e 2 Sum Prod 2 s_12 Sum s_22 reg_prop -1 Prod Pow Sum Pow m_e 2 Sum Prod -1 Pow m_t 2 Sum Prod 2 s_12 Sum Prod -2 s_14 Sum s_22 Sum Prod -2 s_24 Sum s_44 reg_prop -1 Sum Prod m_t Prod gamma %tau_280 %eps_166 %eps_235 Prod gamma %tau_282 %gam_489 %del_416 Prod gamma %tau_282 %eps_235 %eta_263 Prod A %k_5 %tau_280 (p_5) Prod e_u^(*) %i_3 %gam_489 (p_1) Prod e_v %k_3 %del_416 (p_2) Prod t_u^(*) %l_3 %eps_166 (p_3) t_u %j_5 %eta_263 (p_4) Sum Prod -1 Prod p_1 %sigma_222 Prod gamma %sigma_222 %eps_236 %eps_237 Prod gamma %tau_280 %eps_168 %eps_236 Prod gamma %tau_282 %gam_490 %del_417 Prod gamma %tau_282 %eps_237 %eta_264 Prod A %k_5 %tau_280 (p_5) Prod e_u^(*) %i_3 %gam_490 (p_1) Prod e_v %k_3 %del_417 (p_2) Prod t_u^(*) %l_3 %eps_168 (p_3) t_u %j_5 %eta_264 (p_4) Sum Prod -1 Prod p_2 %sigma_222 Prod gamma %sigma_222 %eps_238 %eps_239 Prod gamma %tau_280 %eps_177 %eps_238 Prod gamma %tau_282 %gam_493 %del_420 Prod gamma %tau_282 %eps_239 %eta_267 Prod A %k_5 %tau_280 (p_5) Prod e_u^(*) %i_3 %gam_493 (p_1) Prod e_v %k_3 %del_420 (p_2) Prod t_u^(*) %l_3 %eps_177 (p_3) t_u %j_5 %eta_267 (p_4) Prod p_4 %sigma_222 Prod gamma %sigma_222 %eps_240 %eps_241 Prod gamma %tau_280 %eps_180 %eps_240 Prod gamma %tau_282 %gam_494 %del_421 Prod gamma %tau_282 %eps_241 %eta_268 Prod A %k_5 %tau_280 (p_5) Prod e_u^(*) %i_3 %gam_494 (p_1) Prod e_v %k_3 %del_421 (p_2) Prod t_u^(*) %l_3 %eps_180 (p_3) t_u %j_5 %eta_268 (p_4)'\n",
      "squared amplitudes:\n",
      "b'mul s- 8 mul pow e 6 mul pow add m2mu add reg_prop add s_11 mul s- 2 s_14 s- 2 mul pow add reg_prop add s_11 add s_22 add mul s- 2 s_14 add mul s- 2 s_24 mul 2 s_12 s- 2 add mul s- 12 m4muxs_14 add mul s- 4 m4muxs_15 add mul s- 4 m4muxs_24 add mul s- 4 m4muxs_25 add mul 4 m4muxs_11 add mul 4 m4muxs_45 add mul 4 pow m2muxs_14 2 add mul 8 m6mu add mul m2muxs_22 s_25 add mul s- 1 mul m2muxs_11 s_25 add mul s- 4 mul m2muxs_12 s_45 add mul s- 2 mul m2muxs_11 s_14 add mul s- 2 mul m2muxs_14 s_22 add mul s- 2 mul m2muxs_14 s_45 add mul s- 2 mul m2muxs_15 s_24 add mul s- 2 mul m2muxs_22 s_45 add mul s- 2 mul s_15 pow s_24 2 add mul 2 mul m2muxs_12 s_25 add mul 2 mul m2muxs_14 s_15 add mul 2 mul m2muxs_15 s_22 add mul 2 mul m2muxs_24 s_45 add mul 2 mul s_45 pow s_12 2 add mul 4 mul m2muxs_11 s_24 add mul 4 mul m2muxs_12 s_15 add mul 4 mul m2muxs_14 s_25 add mul 8 mul m2muxs_12 s_24 add mul s_11 mul s_12 s_45 add mul s_12 mul s_22 s_45 add mul s_15 mul s_22 s_24 add mul s- 1 mul s_11 mul s_15 s_24 add mul s- 4 mul s_12 mul s_24 s_25 add mul s- 2 mul s_11 mul s_24 s_25 add mul s- 2 mul s_12 mul s_14 s_15 add mul s- 2 mul s_12 mul s_14 s_25 add mul s- 2 mul s_12 mul s_15 s_24 add mul s- 2 mul s_14 mul s_24 s_45 add mul 2 mul s_11 mul s_24 s_45 add mul 2 mul s_12 mul s_24 s_45 mul 2 mul s_14 mul s_24 s_25'\n",
      "b'mul mul s- 8 pow 729 s- 1 mul pow e 6 mul pow add m2s add mul s- 1 reg_prop add mul s- 1 s_22 add mul s- 1 s_33 mul s- 2 s_23 s- 2 mul pow add reg_prop add s_22 add s_33 add s_44 add mul s- 2 s_24 add mul s- 2 s_34 mul 2 s_23 s- 2 add mul 4 m6s add mul m2s add mul s_22 s_24 add mul s- 1 mul s_24 s_33 add mul s- 2 mul s_15 s_23 add mul s- 2 mul s_15 s_33 add mul 2 mul s_22 s_34 add mul 2 mul s_23 s_34 add mul 3 mul s_12 s_45 add mul 3 mul s_14 s_25 add mul 4 mul s_13 s_45 mul 4 mul s_14 s_35 add mul m4s add mul s- 4 s_34 add mul s- 3 s_24 add mul s- 2 s_15 add mul 4 s_23 mul 4 s_33 add mul s_12 mul s_33 s_45 add mul s_14 mul s_25 s_33 add mul s- 1 mul s_12 mul s_22 s_45 add mul s- 1 mul s_14 mul s_22 s_25 add mul s- 2 mul s_13 mul s_22 s_45 add mul s- 2 mul s_13 mul s_23 s_45 add mul s- 2 mul s_14 mul s_22 s_35 mul s- 2 mul s_14 mul s_23 s_35'\n",
      "b'mul 16 mul pow e 6 mul pow add m2e add reg_prop add s_22 mul 2 s_12 s- 2 mul pow add m2e add reg_prop add s_22 add s_44 add mul s- 1 m2t add mul s- 2 s_14 add mul s- 2 s_24 mul 2 s_12 s- 2 add mul s- 1 m4exs_34 add mul 2 m4txs_12 add mul m2e add mul s_14 s_23 add mul s_34 s_44 add mul s- 1 mul s_22 s_34 add mul s- 2 mul s_12 s_34 add mul s- 2 mul s_13 s_44 add mul s- 2 mul s_23 s_44 add mul s- 2 mul s_24 s_34 add mul 2 mul s_13 s_14 add mul 3 mul s_13 s_24 mul 4 mul s_23 s_24 add mul m2t add mul 4 pow s_12 2 add mul s_13 s_24 add mul s_14 s_23 add mul s- 8 mul s_14 s_24 add mul s- 2 mul s_12 s_34 add mul 2 mul s_12 s_13 add mul 2 mul s_12 s_22 add mul 2 mul s_12 s_23 add mul 2 mul s_12 s_44 mul 4 mul s_14 s_22 add mul 2 mul s_13 pow s_24 2 add mul 2 mul s_23 pow s_14 2 add mul 4 mul m2e m4t add mul 4 mul m2t m4e add mul m2e mul m2t add mul s- 4 s_14 add mul s- 3 s_34 add mul 4 s_13 add mul 4 s_22 add mul 4 s_23 mul 10 s_12 add mul s_14 mul s_22 s_23 add mul s- 1 mul s_13 mul s_22 s_24 add mul s- 1 mul s_13 mul s_24 s_44 add mul s- 1 mul s_14 mul s_23 s_44 add mul s- 2 mul s_12 mul s_14 s_34 add mul s- 2 mul s_12 mul s_24 s_34 add mul s- 2 mul s_13 mul s_14 s_24 add mul s- 2 mul s_14 mul s_22 s_34 add mul s- 2 mul s_14 mul s_23 s_24 add mul 2 mul s_12 mul s_13 s_14 add mul 2 mul s_12 mul s_23 s_24 add mul 2 mul s_13 mul s_14 s_22 mul 4 mul s_14 mul s_24 s_34'\n"
     ]
    }
   ],
   "source": [
    "for x_examples, y_examples in df_train.batch(3).take(1):\n",
    "    print(\"amplitudes:\")\n",
    "    for xx in x_examples.numpy():\n",
    "        print(xx)\n",
    "    print(\"squared amplitudes:\")\n",
    "    for yy in y_examples.numpy():\n",
    "        print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| bogoTokenizer.tokenize([\"hello world\", \"this is a test\"]): <tf.RaggedTensor [[2, 8, 4, 3], [2, 5, 7, 9, 6, 3]]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup\n",
      "<tf.RaggedTensor [[b'[START]', b'hello', b'world', b'[END]'],\n",
      " [b'[START]', b'this', b'is', b'a', b'test', b'[END]']]>\n",
      "detokenize\n",
      "tf.Tensor([b'hello world' b'this is a test'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "class BogoTokenizer(tf_text.Tokenizer, tf_text.Detokenizer):\n",
    "    \"\"\"\n",
    "    My implementation of a tf_text.Tokenizer.\n",
    "    It's actually just a wrapper around TextVectorization,\n",
    "    but so that it works for my case.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=None,\n",
    "            standardize=None, ragged=False,):\n",
    "        super(BogoTokenizer, self).__init__()\n",
    "        self.vectorizer = TextVectorization(max_tokens=max_tokens, output_mode=output_mode,\n",
    "            output_sequence_length=output_sequence_length, ragged=ragged, standardize=None)\n",
    "        self.start = \"[START]\"\n",
    "        self.end = \"[END]\"\n",
    "\n",
    "    def tokenize(self, input):\n",
    "        input_with_start_end = [self.start+\" \"+inp+\" \"+self.end for inp in input]\n",
    "        return self.vectorizer(input_with_start_end)\n",
    "\n",
    "    def encode(self, input):\n",
    "        return self.vectorizer(input)\n",
    "\n",
    "    def adapt(self, input):\n",
    "        input_with_start_end = [self.start+\" \"+inp+\" \"+self.end for inp in input]\n",
    "        self.vectorizer.adapt(input_with_start_end)\n",
    "\n",
    "    def detokenize(self, tokens):\n",
    "        vocab = tf.constant(self.vectorizer.get_vocabulary())\n",
    "        sentences = tf.gather(vocab, tokens)\n",
    "        sentences = sentences[:, 1:-1]\n",
    "        signature = tf.type_spec_from_value(tf.strings.join(sentences[0]))\n",
    "        sentences = tf.map_fn(fn=lambda s: tf.strings.join(s, separator=\" \"), elems=sentences,\n",
    "            fn_output_signature=signature)\n",
    "        return sentences\n",
    "\n",
    "    def lookup(self, tokens):\n",
    "        vocab = tf.constant(self.vectorizer.get_vocabulary())\n",
    "        return tf.gather(vocab, tokens)\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vectorizer.get_vocabulary()\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vectorizer.get_vocabulary())\n",
    "\n",
    "bogoTokenizer = BogoTokenizer(output_sequence_length=None, ragged=True)\n",
    "bogoTokenizer.adapt([\"hello world\", \"this is a test\"])\n",
    "tokens = ic(bogoTokenizer.tokenize([\"hello world\", \"this is a test\"]))\n",
    "print(\"lookup\")\n",
    "print(bogoTokenizer.lookup(tokens))\n",
    "print(\"detokenize\")\n",
    "print(bogoTokenizer.detokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod -1 Prod i Prod e Prod gamma alpha_2 alpha_1 alpha_0 Prod A^(*) i_2 alpha_2 (p_2) Prod ee^(*) i_0 alpha_1 (p_1)_u ee i_1 alpha_0 (p_3)_u'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_X = BogoTokenizer(ragged=True)\n",
    "tokenizer_y = BogoTokenizer(ragged=True)\n",
    "\n",
    "tokenizer_X.adapt(X_train_all)\n",
    "tokenizer_y.adapt(y_train_all)\n",
    "\n",
    "tokenizers = {\"X\": tokenizer_X, \"y\": tokenizer_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[50, 1, 2, 3, 1, 51]]>\n",
      "tf.Tensor([b'[UNK] Prod gamma [UNK]'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer_X.tokenize([\"banana Prod gamma banananana\"])\n",
    "print(enc)\n",
    "round_trip = tokenizer_X.detokenize(enc)\n",
    "print(round_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'(p_5)_v [UNK] Prod gamma'], dtype=object)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_X.detokenize([[45, 42, 1, 2, 3, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=string, numpy=\n",
       "array([[b'(p_3)', b'(p_5)_v', b'[UNK]', b'Prod', b'gamma', b'(p_5)']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_X.lookup([[45, 42, 1, 2, 3, 46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Prod 1/2 Prod i Prod Pow e 3 Prod Pow Sum Pow m_mu 2 Sum Prod 2 s_23 Prod -2 s_24 s_33 Prod -2 s_34 s_44 reg_prop -1 Prod Pow Sum s_23 Sum Prod 1/2 s_33 Prod 1/2 reg_prop -1 Sum Prod m_mu Prod gamma alpha_23 alpha_18 alpha_0 Prod gamma alpha_24 alpha_10 alpha_18 Prod gamma alpha_24 alpha_11 alpha_19 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_19 (p_1)_v Prod mu i_2 alpha_0 (p_2)_v Prod mu^(*) i_1 alpha_10 (p_4)_v mu^(*) i_3 alpha_11 (p_5)_v Sum Prod p_1 alpha_25 Prod gamma alpha_25 alpha_4 alpha_5 Prod gamma alpha_23 alpha_5 alpha_1 Prod gamma alpha_24 alpha_12 alpha_4 Prod gamma alpha_24 alpha_13 alpha_20 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_20 (p_1)_v Prod mu i_2 alpha_1 (p_2)_v Prod mu^(*) i_1 alpha_12 (p_4)_v mu^(*) i_3 alpha_13 (p_5)_v Prod -1 Prod p_4 alpha_25 Prod gamma alpha_25 alpha_6 alpha_7 Prod gamma alpha_23 alpha_7 alpha_2 Prod gamma alpha_24 alpha_14 alpha_6 Prod gamma alpha_24 alpha_15 alpha_21 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_21 (p_1)_v Prod mu i_2 alpha_2 (p_2)_v Prod mu^(*) i_1 alpha_14 (p_4)_v mu^(*) i_3 alpha_15 (p_5)_v Prod -1 Prod p_5 alpha_25 Prod gamma alpha_25 alpha_8 alpha_9 Prod gamma alpha_23 alpha_9 alpha_3 Prod gamma alpha_24 alpha_16 alpha_8 Prod gamma alpha_24 alpha_17 alpha_22 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_22 (p_1)_v Prod mu i_2 alpha_3 (p_2)_v Prod mu^(*) i_1 alpha_16 (p_4)_v mu^(*) i_3 alpha_17 (p_5)_v'\n",
      " b'Prod -1/9 Prod i Prod Pow e 3 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 reg_prop -1 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 reg_prop -1 Sum Prod p_1 alpha_16 Prod gamma alpha_16 alpha_3 alpha_4 Prod gamma alpha_17 alpha_0 alpha_3 Prod gamma alpha_18 alpha_13 alpha_7 Prod gamma alpha_18 alpha_4 alpha_10 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_0 (p_2)_v Prod b i_2 alpha_10 (p_4)_v Prod t^(*) i_0 alpha_13 (p_1)_v t i_1 alpha_7 (p_3)_v Sum Prod -1 Prod p_3 alpha_16 Prod gamma alpha_16 alpha_5 alpha_6 Prod gamma alpha_17 alpha_1 alpha_5 Prod gamma alpha_18 alpha_14 alpha_8 Prod gamma alpha_18 alpha_6 alpha_11 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_1 (p_2)_v Prod b i_2 alpha_11 (p_4)_v Prod t^(*) i_0 alpha_14 (p_1)_v t i_1 alpha_8 (p_3)_v Prod -2 Prod p_4 alpha_18 Prod gamma alpha_17 alpha_2 alpha_12 Prod gamma alpha_18 alpha_15 alpha_9 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_2 (p_2)_v Prod b i_2 alpha_12 (p_4)_v Prod t^(*) i_0 alpha_15 (p_1)_v t i_1 alpha_9 (p_3)_v'\n",
      " b'Prod -8/27 Prod i Prod Pow e 3 Prod Pow Sum s_11 Sum Prod 2 s_12 Prod 2 s_13 s_22 Prod 2 s_23 s_33 reg_prop -1 Prod Pow Sum Pow m_u 2 Sum Prod -1 s_22 Prod -2 s_23 Prod -1 s_33 Prod -1 reg_prop -1 Sum Prod m_u Prod gamma alpha_18 alpha_6 alpha_12 Prod gamma alpha_18 alpha_7 alpha_3 Prod gamma alpha_17 alpha_12 alpha_0 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_6 (p_1)_u Prod u i_2 alpha_0 (p_2)_v Prod tt i_1 alpha_3 (p_4)_u tt^(*) i_4 alpha_7 (p_5)_v Sum Prod -1 Prod p_2 alpha_19 Prod gamma alpha_18 alpha_8 alpha_13 Prod gamma alpha_18 alpha_9 alpha_4 Prod gamma alpha_17 alpha_14 alpha_1 Prod gamma alpha_19 alpha_13 alpha_14 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_8 (p_1)_u Prod u i_2 alpha_1 (p_2)_v Prod tt i_1 alpha_4 (p_4)_u tt^(*) i_4 alpha_9 (p_5)_v Prod -1 Prod p_3 alpha_19 Prod gamma alpha_18 alpha_10 alpha_15 Prod gamma alpha_18 alpha_11 alpha_5 Prod gamma alpha_17 alpha_16 alpha_2 Prod gamma alpha_19 alpha_15 alpha_16 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_10 (p_1)_u Prod u i_2 alpha_2 (p_2)_v Prod tt i_1 alpha_5 (p_4)_u tt^(*) i_4 alpha_11 (p_5)_v'], shape=(3,), dtype=string)\n",
      "encoded batch:\n",
      "[50, 2, 54, 2, 48, 2, 5, 49, 53, 2, 5, 4, 5, 104, 15, 4, 2, 15, 81, 2, 32, 91, 77, 2, 32, 78, 84, 28, 6, 2, 5, 4, 81, 4, 2, 54, 77, 2, 54, 28, 6, 4, 2, 104, 2, 3, 38, 8, 20, 2, 3, 39, 16, 8, 2, 3, 39, 17, 44, 2, 34, 14, 38, 45, 2, 86, 11, 44, 52, 2, 86, 9, 20, 40, 2, 85, 10, 16, 41, 85, 12, 17, 42, 4, 2, 58, 43, 2, 3, 43, 24, 29, 2, 3, 38, 29, 18, 2, 3, 39, 22, 24, 2, 3, 39, 30, 90, 2, 34, 14, 38, 45, 2, 86, 11, 90, 52, 2, 86, 9, 18, 40, 2, 85, 10, 22, 41, 85, 12, 30, 42, 2, 6, 2, 59, 43, 2, 3, 43, 27, 26, 2, 3, 38, 26, 19, 2, 3, 39, 37, 27, 2, 3, 39, 36, 94, 2, 34, 14, 38, 45, 2, 86, 11, 94, 52, 2, 86, 9, 19, 40, 2, 85, 10, 37, 41, 85, 12, 36, 42, 2, 6, 2, 96, 43, 2, 3, 43, 25, 23, 2, 3, 38, 23, 21, 2, 3, 39, 13, 25, 2, 3, 39, 7, 93, 2, 34, 14, 38, 45, 2, 86, 11, 93, 52, 2, 86, 9, 21, 40, 2, 85, 10, 13, 41, 85, 12, 7, 42, 51]\n",
      "[50, 2, 125, 2, 48, 2, 5, 49, 53, 2, 5, 4, 5, 97, 15, 4, 79, 2, 32, 57, 28, 6, 2, 5, 4, 5, 97, 15, 4, 79, 2, 32, 57, 2, 32, 80, 2, 15, 78, 28, 6, 4, 2, 58, 13, 2, 3, 13, 21, 24, 2, 3, 7, 20, 21, 2, 3, 8, 30, 26, 2, 3, 8, 24, 16, 2, 34, 14, 7, 46, 2, 60, 12, 20, 40, 2, 61, 9, 16, 41, 2, 73, 11, 30, 52, 74, 10, 26, 64, 4, 2, 6, 2, 76, 13, 2, 3, 13, 29, 27, 2, 3, 7, 18, 29, 2, 3, 8, 37, 25, 2, 3, 8, 27, 17, 2, 34, 14, 7, 46, 2, 60, 12, 18, 40, 2, 61, 9, 17, 41, 2, 73, 11, 37, 52, 74, 10, 25, 64, 2, 32, 2, 59, 8, 2, 3, 7, 19, 22, 2, 3, 8, 36, 23, 2, 34, 14, 7, 46, 2, 60, 12, 19, 40, 2, 61, 9, 22, 41, 2, 73, 11, 36, 52, 74, 10, 23, 64, 51]\n",
      "[50, 2, 115, 2, 48, 2, 5, 49, 53, 2, 5, 4, 79, 4, 2, 15, 82, 2, 15, 57, 83, 2, 15, 81, 77, 28, 6, 2, 5, 4, 5, 98, 15, 4, 2, 6, 83, 2, 32, 81, 2, 6, 77, 2, 6, 28, 6, 4, 2, 98, 2, 3, 8, 27, 22, 2, 3, 8, 26, 21, 2, 3, 7, 22, 20, 2, 34, 12, 7, 45, 2, 71, 11, 27, 31, 2, 72, 9, 20, 40, 2, 88, 10, 21, 35, 87, 14, 26, 42, 4, 2, 6, 2, 75, 44, 2, 3, 8, 25, 30, 2, 3, 8, 23, 24, 2, 3, 7, 37, 18, 2, 3, 44, 30, 37, 2, 34, 12, 7, 45, 2, 71, 11, 25, 31, 2, 72, 9, 18, 40, 2, 88, 10, 24, 35, 87, 14, 23, 42, 2, 6, 2, 76, 44, 2, 3, 8, 16, 36, 2, 3, 8, 17, 29, 2, 3, 7, 13, 19, 2, 3, 44, 36, 13, 2, 34, 12, 7, 45, 2, 71, 11, 16, 31, 2, 72, 9, 19, 40, 2, 88, 10, 29, 35, 87, 14, 17, 42, 51]\n",
      "tf.Tensor(\n",
      "[b'Prod 1/2 Prod i Prod Pow e 3 Prod Pow Sum Pow m_mu 2 Sum Prod 2 s_23 Prod -2 s_24 s_33 Prod -2 s_34 s_44 reg_prop -1 Prod Pow Sum s_23 Sum Prod 1/2 s_33 Prod 1/2 reg_prop -1 Sum Prod m_mu Prod gamma alpha_23 alpha_18 alpha_0 Prod gamma alpha_24 alpha_10 alpha_18 Prod gamma alpha_24 alpha_11 alpha_19 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_19 (p_1)_v Prod mu i_2 alpha_0 (p_2)_v Prod mu^(*) i_1 alpha_10 (p_4)_v mu^(*) i_3 alpha_11 (p_5)_v Sum Prod p_1 alpha_25 Prod gamma alpha_25 alpha_4 alpha_5 Prod gamma alpha_23 alpha_5 alpha_1 Prod gamma alpha_24 alpha_12 alpha_4 Prod gamma alpha_24 alpha_13 alpha_20 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_20 (p_1)_v Prod mu i_2 alpha_1 (p_2)_v Prod mu^(*) i_1 alpha_12 (p_4)_v mu^(*) i_3 alpha_13 (p_5)_v Prod -1 Prod p_4 alpha_25 Prod gamma alpha_25 alpha_6 alpha_7 Prod gamma alpha_23 alpha_7 alpha_2 Prod gamma alpha_24 alpha_14 alpha_6 Prod gamma alpha_24 alpha_15 alpha_21 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_21 (p_1)_v Prod mu i_2 alpha_2 (p_2)_v Prod mu^(*) i_1 alpha_14 (p_4)_v mu^(*) i_3 alpha_15 (p_5)_v Prod -1 Prod p_5 alpha_25 Prod gamma alpha_25 alpha_8 alpha_9 Prod gamma alpha_23 alpha_9 alpha_3 Prod gamma alpha_24 alpha_16 alpha_8 Prod gamma alpha_24 alpha_17 alpha_22 Prod A^(*) i_4 alpha_23 (p_3) Prod mu i_0 alpha_22 (p_1)_v Prod mu i_2 alpha_3 (p_2)_v Prod mu^(*) i_1 alpha_16 (p_4)_v mu^(*) i_3 alpha_17 (p_5)_v'\n",
      " b'Prod -1/9 Prod i Prod Pow e 3 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 reg_prop -1 Prod Pow Sum Pow m_t 2 Sum s_11 Prod -2 s_13 Prod -2 s_14 Prod 2 s_34 reg_prop -1 Sum Prod p_1 alpha_16 Prod gamma alpha_16 alpha_3 alpha_4 Prod gamma alpha_17 alpha_0 alpha_3 Prod gamma alpha_18 alpha_13 alpha_7 Prod gamma alpha_18 alpha_4 alpha_10 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_0 (p_2)_v Prod b i_2 alpha_10 (p_4)_v Prod t^(*) i_0 alpha_13 (p_1)_v t i_1 alpha_7 (p_3)_v Sum Prod -1 Prod p_3 alpha_16 Prod gamma alpha_16 alpha_5 alpha_6 Prod gamma alpha_17 alpha_1 alpha_5 Prod gamma alpha_18 alpha_14 alpha_8 Prod gamma alpha_18 alpha_6 alpha_11 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_1 (p_2)_v Prod b i_2 alpha_11 (p_4)_v Prod t^(*) i_0 alpha_14 (p_1)_v t i_1 alpha_8 (p_3)_v Prod -2 Prod p_4 alpha_18 Prod gamma alpha_17 alpha_2 alpha_12 Prod gamma alpha_18 alpha_15 alpha_9 Prod A^(*) i_4 alpha_17 (p_5) Prod b^(*) i_3 alpha_2 (p_2)_v Prod b i_2 alpha_12 (p_4)_v Prod t^(*) i_0 alpha_15 (p_1)_v t i_1 alpha_9 (p_3)_v'\n",
      " b'Prod -8/27 Prod i Prod Pow e 3 Prod Pow Sum s_11 Sum Prod 2 s_12 Prod 2 s_13 s_22 Prod 2 s_23 s_33 reg_prop -1 Prod Pow Sum Pow m_u 2 Sum Prod -1 s_22 Prod -2 s_23 Prod -1 s_33 Prod -1 reg_prop -1 Sum Prod m_u Prod gamma alpha_18 alpha_6 alpha_12 Prod gamma alpha_18 alpha_7 alpha_3 Prod gamma alpha_17 alpha_12 alpha_0 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_6 (p_1)_u Prod u i_2 alpha_0 (p_2)_v Prod tt i_1 alpha_3 (p_4)_u tt^(*) i_4 alpha_7 (p_5)_v Sum Prod -1 Prod p_2 alpha_19 Prod gamma alpha_18 alpha_8 alpha_13 Prod gamma alpha_18 alpha_9 alpha_4 Prod gamma alpha_17 alpha_14 alpha_1 Prod gamma alpha_19 alpha_13 alpha_14 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_8 (p_1)_u Prod u i_2 alpha_1 (p_2)_v Prod tt i_1 alpha_4 (p_4)_u tt^(*) i_4 alpha_9 (p_5)_v Prod -1 Prod p_3 alpha_19 Prod gamma alpha_18 alpha_10 alpha_15 Prod gamma alpha_18 alpha_11 alpha_5 Prod gamma alpha_17 alpha_16 alpha_2 Prod gamma alpha_19 alpha_15 alpha_16 Prod A^(*) i_3 alpha_17 (p_3) Prod u^(*) i_0 alpha_10 (p_1)_u Prod u i_2 alpha_2 (p_2)_v Prod tt i_1 alpha_5 (p_4)_u tt^(*) i_4 alpha_11 (p_5)_v'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(x_examples)\n",
    "encoded = tokenizer_X.tokenize(x_examples)\n",
    "print(\"encoded batch:\")\n",
    "for row in encoded.to_list():\n",
    "    print(row)\n",
    "\n",
    "round_trip = tokenizer_X.detokenize(encoded)\n",
    "print(round_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=350\n",
    "def prepare_batch(X, y):\n",
    "    X = tokenizers[\"X\"].encode(X)      # Output is ragged.\n",
    "    X = X[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    X = X.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    y = tokenizers[\"y\"].encode(y)\n",
    "    y = y[:, :(MAX_TOKENS+1)]\n",
    "    y_inputs = y[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    y_labels = y[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (X, y_inputs), y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches(df_train)\n",
    "val_batches = make_batches(df_val)\n",
    "test_batches = make_batches(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None)), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215)\n",
      "(8, 343)\n",
      "(8, 343)\n"
     ]
    }
   ],
   "source": [
    "for (xx, yy), yy_labels in train_batches.take(1):\n",
    "    print(xx.shape)\n",
    "    print(yy.shape)\n",
    "    print(yy_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  2 134   2  48   2   5  49  15   2   5], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 4  7 29  6 48  5 14  6 31  8], shape=(10,), dtype=int64)\n",
      "tf.Tensor([ 7 29  6 48  5 14  6 31  8  6], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(xx[0][:10])\n",
    "print(yy[0][:10])\n",
    "print(yy_labels[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  \"\"\"embedding + positional encoding\"\"\"\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_X = PositionalEmbedding(vocab_size=tokenizers[\"X\"].get_vocab_size(), d_model=512)\n",
    "embed_y = PositionalEmbedding(vocab_size=tokenizers[\"y\"].get_vocab_size(), d_model=512)\n",
    "\n",
    "X_emb = embed_X(xx)\n",
    "y_emb = embed_X(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 215), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([  2, 134,   2,  48,   2])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 512), dtype=float32, numpy=\n",
       "array([[ 0.52374196, -0.12326486,  0.55464196, ...,  0.8183378 ,\n",
       "         1.4762123 ,  1.9976285 ],\n",
       "       [-0.26832962, -0.08011383,  1.1411189 , ...,  1.6695035 ,\n",
       "         1.2573043 ,  1.7414477 ],\n",
       "       [ 1.4330394 ,  0.81314987,  1.5127864 , ...,  0.8183378 ,\n",
       "         1.4762123 ,  1.9976285 ],\n",
       "       [-0.06931508,  0.8698441 , -0.78390396, ...,  0.54399264,\n",
       "         0.5348301 ,  0.50692177],\n",
       "       [-0.23306054, -0.7804317 ,  0.0060364 , ...,  0.8183377 ,\n",
       "         1.4762121 ,  1.9976285 ]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.2573043>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0][1][-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the actual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215, 512)\n",
      "(8, 343, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:29:41.285816: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:29:41.808376: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    }
   ],
   "source": [
    "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(X_emb.shape)\n",
    "print(y_emb.shape)\n",
    "print(sample_ca(X_emb, y_emb).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 215, 512)\n",
      "(8, 215, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(X_emb.shape)\n",
    "print(sample_gsa(X_emb).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers[\"X\"].get_vocab_size(),\n",
    "    target_vocab_size=tokenizers[\"y\"].get_vocab_size(),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512, 59)\n"
     ]
    }
   ],
   "source": [
    "print(transformer((X_emb[0][0:10], y_emb[0][0:10]), training=False).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 215, 512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  2658432   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  4757376   \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  7611      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,423,419\n",
      "Trainable params: 7,423,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=6),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='saved_models/2022-12-01-ap-sqahp-checkpoint.h5',\n",
    "        save_weights_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        ),\n",
    "    tf.keras.callbacks.CSVLogger('csv_logs/2022-12-01-ap-sqahp.csv', separator=\",\", append=False),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='tensorboard_logs/2022-12-01-ap-sqahp/'),\n",
    "    tf.keras.callbacks.BackupAndRestore(\n",
    "        'training_backup/2022-12-01-ap-sqahp_backup/', save_freq=\"epoch\", delete_checkpoint=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  167/10887 [..............................] - ETA: 15:46 - loss: 3.1921 - masked_accuracy: 0.2187"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb Cell 90\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# actually second epoch start, had one epoch where I then restarted\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m transformer\u001b[39m.\u001b[39;49mfit(train_batches,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel_hybrid_prefix.ipynb#Y211sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 validation_data\u001b[39m=\u001b[39;49mval_batches)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=10,\n",
    "                validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-11-09-Transformer_2to2.index',\n",
       " '2022-11-09-Transformer_2to2.data-00000-of-00001',\n",
       " '2022-11-14-Transformer_upto3to3_unique_augmented.index',\n",
       " '2022-11-09-Transformer_all_except_3to3.data-00000-of-00001',\n",
       " '2022-11-09-Transformer_all_except_3to3.index',\n",
       " '2022-11-14-Transformer_upto3to3_unique_augmented.data-00000-of-00001',\n",
       " 'checkpoint']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights(\"models/2022-12-01-BaseModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers[\"X\"].tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = self.tokenizers[\"y\"].tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    text = tokenizers[\"y\"].detokenize(output)[0]  # Shape: `()`.\n",
    "\n",
    "    tokens = tokenizers[\"y\"].lookup(output)[0]\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(tokenizers, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod 2/3 Prod i Prod e Prod gamma alpha_2 alpha_0 alpha_1 Prod A^(*) i_2 alpha_2 (p_3) Prod tt i_0 alpha_1 (p_1)_u tt^(*) i_1 alpha_0 (p_2)_u'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = X_test_final[0][0]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = tf.constant(sentence)[tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 2, 133, 2, 43, 2, 44, 2, 3, 18, 20, 19, 2, 34, 10, 18, 40, 2, 90,\n",
       "  12, 19, 31, 89, 11, 20, 72, 46]]>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers[\"X\"].tokenize(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[45, 46]]>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers[\"X\"].tokenize([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'e 4 e e 4 s_23 e 4 s_23 s_23 e 4 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s_23 s- 2 s_23 s_24 s- 2 s_23 pow m_tt 2 mul s- 2 pow m_tt 2 mul s- 2 pow s_23 2 mul 2 pow m_tt 2 mul 2 mul s_13 pow m_tt 2 add mul s- 1 mul s_23 pow m_tt 2 mul s- 2 mul s_24 pow m_tt 2 add mul s- 2 mul s_34 pow m_tt 2 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_12 pow m_tt 4 add mul s- 2 mul s_14 mul s_24 s_34 add mul s- 2 mul s_12 mul 2 mul s_13 mul s_23 pow m_tt 2 add mul s- 2 mul s_14 mul s_23 pow m_tt 2 add mul s- 2 mul s_24 mul s_34 pow m_tt 2 add mul 2 mul s_12 mul s_13 pow m_tt 2 add mul 4 mul s_13 mul s_24 pow m_tt 2 add mul 4 mul s_23 mul s_24 pow m_tt 2 mul s- 2 mul s_12 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s- 2 mul s_23 mul pow m_tt 2 pow m_tt 2 mul s- 2 mul s_14 mul s_24 s_34 mul 2 mul s_13 mul s_23 pow m_tt 2 add mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul 2 mul s_23 mul s_24 pow m_tt 2 add mul 4 mul s_24 mul pow m_tt 2 mul 8 mul s_13 mul s_24 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul s- 2 mul s_23 mul s_34 pow m_tt 2 add mul s- 2 mul s_23 mul s_24 pow m_tt 2 mul mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul mul mul s_24 mul pow m_tt 2 mul mul s- 2 mul s_23 mul s_34 pow m_tt 2 mul mul'>,\n",
       " <tf.Tensor: shape=(351,), dtype=string, numpy=\n",
       " array([b'[START]', b'e', b'4', b'e', b'e', b'4', b's_23', b'e', b'4',\n",
       "        b's_23', b's_23', b'e', b'4', b's_23', b's_23', b's_23', b's_23',\n",
       "        b's_23', b's_23', b's_23', b's_23', b's_23', b's-', b'2', b's_23',\n",
       "        b's_24', b's-', b'2', b's_23', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'pow', b'm_tt', b'2', b'mul', b's-', b'2', b'pow',\n",
       "        b's_23', b'2', b'mul', b'2', b'pow', b'm_tt', b'2', b'mul', b'2',\n",
       "        b'mul', b's_13', b'pow', b'm_tt', b'2', b'add', b'mul', b's-',\n",
       "        b'1', b'mul', b's_23', b'pow', b'm_tt', b'2', b'mul', b's-', b'2',\n",
       "        b'mul', b's_24', b'pow', b'm_tt', b'2', b'add', b'mul', b's-',\n",
       "        b'2', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add', b'mul',\n",
       "        b's-', b'2', b'mul', b's_12', b'pow', b'm_tt', b'4', b'add',\n",
       "        b'mul', b's-', b'2', b'mul', b's_12', b'pow', b'm_tt', b'4',\n",
       "        b'add', b'mul', b's-', b'2', b'mul', b's_12', b'pow', b'm_tt',\n",
       "        b'4', b'add', b'mul', b's-', b'2', b'mul', b's_14', b'mul',\n",
       "        b's_24', b's_34', b'add', b'mul', b's-', b'2', b'mul', b's_12',\n",
       "        b'mul', b'2', b'mul', b's_13', b'mul', b's_23', b'pow', b'm_tt',\n",
       "        b'2', b'add', b'mul', b's-', b'2', b'mul', b's_14', b'mul',\n",
       "        b's_23', b'pow', b'm_tt', b'2', b'add', b'mul', b's-', b'2',\n",
       "        b'mul', b's_24', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add',\n",
       "        b'mul', b'2', b'mul', b's_12', b'mul', b's_13', b'pow', b'm_tt',\n",
       "        b'2', b'add', b'mul', b'4', b'mul', b's_13', b'mul', b's_24',\n",
       "        b'pow', b'm_tt', b'2', b'add', b'mul', b'4', b'mul', b's_23',\n",
       "        b'mul', b's_24', b'pow', b'm_tt', b'2', b'mul', b's-', b'2',\n",
       "        b'mul', b's_12', b'mul', b's_34', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'mul', b's_23', b'mul', b's-', b'2', b'mul', b's_23',\n",
       "        b'mul', b'pow', b'm_tt', b'2', b'pow', b'm_tt', b'2', b'mul',\n",
       "        b's-', b'2', b'mul', b's_14', b'mul', b's_24', b's_34', b'mul',\n",
       "        b'2', b'mul', b's_13', b'mul', b's_23', b'pow', b'm_tt', b'2',\n",
       "        b'add', b'mul', b's-', b'2', b'mul', b's_23', b'mul', b's_34',\n",
       "        b'pow', b'm_tt', b'2', b'mul', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_24', b'pow', b'm_tt', b'2', b'add', b'mul', b'4', b'mul',\n",
       "        b's_24', b'mul', b'pow', b'm_tt', b'2', b'mul', b'8', b'mul',\n",
       "        b's_13', b'mul', b's_24', b'pow', b'm_tt', b'2', b'mul', b's-',\n",
       "        b'2', b'mul', b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2',\n",
       "        b'mul', b's-', b'2', b'mul', b's_23', b'mul', b's_34', b'pow',\n",
       "        b'm_tt', b'2', b'mul', b's-', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_34', b'pow', b'm_tt', b'2', b'mul', b's-', b'2', b'mul',\n",
       "        b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2', b'add', b'mul',\n",
       "        b's-', b'2', b'mul', b's_23', b'mul', b's_24', b'pow', b'm_tt',\n",
       "        b'2', b'mul', b'mul', b's-', b'2', b'mul', b's_23', b'mul',\n",
       "        b's_34', b'pow', b'm_tt', b'2', b'mul', b'mul', b'mul', b's_24',\n",
       "        b'mul', b'pow', b'm_tt', b'2', b'mul', b'mul', b's-', b'2', b'mul',\n",
       "        b's_23', b'mul', b's_34', b'pow', b'm_tt', b'2', b'mul', b'mul',\n",
       "        b'mul'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1, 8, 350, 27), dtype=float32, numpy=\n",
       " array([[[[0.00609642, 0.15153041, 0.00274909, ..., 0.00150047,\n",
       "           0.00264707, 0.00269867],\n",
       "          [0.0052967 , 0.15357839, 0.00263177, ..., 0.00150018,\n",
       "           0.0025359 , 0.00258117],\n",
       "          [0.00583117, 0.15227929, 0.00294052, ..., 0.00172064,\n",
       "           0.00283237, 0.00288254],\n",
       "          ...,\n",
       "          [0.00071198, 0.16413519, 0.0008504 , ..., 0.00032842,\n",
       "           0.0008713 , 0.00086429],\n",
       "          [0.00367211, 0.15637067, 0.00249051, ..., 0.00096584,\n",
       "           0.00251631, 0.00252367],\n",
       "          [0.00371149, 0.15633078, 0.00247816, ..., 0.00087514,\n",
       "           0.00250369, 0.00251316]],\n",
       " \n",
       "         [[0.01689322, 0.04564391, 0.01104816, ..., 0.01507656,\n",
       "           0.01080301, 0.01081656],\n",
       "          [0.01653329, 0.0433283 , 0.01073942, ..., 0.01477481,\n",
       "           0.01052687, 0.01050784],\n",
       "          [0.01472505, 0.04195366, 0.00932383, ..., 0.01332293,\n",
       "           0.00910951, 0.00910464],\n",
       "          ...,\n",
       "          [0.02407413, 0.07379293, 0.02735358, ..., 0.02006663,\n",
       "           0.02821435, 0.02769257],\n",
       "          [0.03513052, 0.06600828, 0.02997538, ..., 0.02389245,\n",
       "           0.03023542, 0.03009939],\n",
       "          [0.03540717, 0.0706565 , 0.02732649, ..., 0.02055297,\n",
       "           0.02740923, 0.02735479]],\n",
       " \n",
       "         [[0.03156018, 0.03908681, 0.04538356, ..., 0.02548607,\n",
       "           0.04657719, 0.04594937],\n",
       "          [0.03203427, 0.04030607, 0.04423797, ..., 0.02376057,\n",
       "           0.04535729, 0.04479996],\n",
       "          [0.03138492, 0.04089653, 0.04405596, ..., 0.02368526,\n",
       "           0.04533069, 0.04470651],\n",
       "          ...,\n",
       "          [0.00200637, 0.15030089, 0.00340025, ..., 0.00345178,\n",
       "           0.00361168, 0.00348481],\n",
       "          [0.00241347, 0.14895354, 0.00466538, ..., 0.00517503,\n",
       "           0.00494219, 0.00476482],\n",
       "          [0.00305121, 0.14478232, 0.0066317 , ..., 0.00660914,\n",
       "           0.0070062 , 0.00676694]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.02800317, 0.06161228, 0.03855311, ..., 0.00879904,\n",
       "           0.04001163, 0.03925679],\n",
       "          [0.02902667, 0.0549776 , 0.04152768, ..., 0.00959343,\n",
       "           0.04312503, 0.04227211],\n",
       "          [0.02846494, 0.05563181, 0.04138827, ..., 0.00941592,\n",
       "           0.04301919, 0.04215685],\n",
       "          ...,\n",
       "          [0.0305258 , 0.10159979, 0.0169348 , ..., 0.01563822,\n",
       "           0.01658178, 0.01664403],\n",
       "          [0.03337456, 0.08090247, 0.02553204, ..., 0.01159193,\n",
       "           0.02564672, 0.02551835],\n",
       "          [0.03171662, 0.08374719, 0.02504459, ..., 0.01158537,\n",
       "           0.02522526, 0.02504516]],\n",
       " \n",
       "         [[0.0065423 , 0.12380715, 0.01084948, ..., 0.00715502,\n",
       "           0.0112474 , 0.01110107],\n",
       "          [0.00600183, 0.12429012, 0.01007851, ..., 0.00755378,\n",
       "           0.01041984, 0.0102808 ],\n",
       "          [0.00637528, 0.12283031, 0.0103468 , ..., 0.00792537,\n",
       "           0.01067144, 0.01053841],\n",
       "          ...,\n",
       "          [0.01100498, 0.11200484, 0.01588698, ..., 0.0079219 ,\n",
       "           0.01651807, 0.01633325],\n",
       "          [0.01936618, 0.04839056, 0.04065802, ..., 0.01538224,\n",
       "           0.04371664, 0.04267323],\n",
       "          [0.01987411, 0.0563297 , 0.03739638, ..., 0.01594159,\n",
       "           0.03978336, 0.03898437]],\n",
       " \n",
       "         [[0.00026868, 0.16225778, 0.00019936, ..., 0.0004288 ,\n",
       "           0.00019345, 0.00019469],\n",
       "          [0.00026069, 0.1609932 , 0.00018337, ..., 0.00043292,\n",
       "           0.00017718, 0.00017845],\n",
       "          [0.00032167, 0.16078234, 0.00022718, ..., 0.00052802,\n",
       "           0.00021978, 0.00022131],\n",
       "          ...,\n",
       "          [0.0003283 , 0.15093873, 0.00021811, ..., 0.00044357,\n",
       "           0.00021063, 0.00021226],\n",
       "          [0.00031746, 0.16498904, 0.00025356, ..., 0.00054208,\n",
       "           0.0002442 , 0.00024628],\n",
       "          [0.00041486, 0.16426212, 0.00035574, ..., 0.00073811,\n",
       "           0.00034445, 0.00034644]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(tf.constant(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod 2/3 Prod i Prod e Prod gamma alpha_2 alpha_0 alpha_1 Prod A^(*) i_2 alpha_2 (p_3) Prod tt i_0 alpha_1 (p_1)_u tt^(*) i_1 alpha_0 (p_2)_u'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4adc2ea131058d4ca334736eaf83f8a99f586a60b7e02773f5921bb39d3dbeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
